{"id":"synesthetica-00b","title":"Implement BeatDetectionStabilizer","description":"Detect tempo and beat phase from onset patterns. Independent stabilizer (no dependencies). Outputs BeatState with phase (0-1), tempo (BPM), and confidence. See SPEC_008 for stabilizer DAG architecture.","status":"closed","priority":2,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-19T15:15:53.846128Z","created_by":"Nic Young","updated_at":"2026-01-19T15:44:31.560732Z","closed_at":"2026-01-19T15:44:31.560732Z","close_reason":"Implemented BeatDetectionStabilizer with IOI-based tempo detection, beat phase tracking, and bar position (beatInBar, isDownbeat). Extended BeatState contract and updated MusicalVisualRuleset to use new structure."}
{"id":"synesthetica-0dm","title":"Write concrete acceptance scenarios for Phase 0","description":"## Problem\n\nPhase 0 epic says \"can connect a MIDI keyboard and see colored particles\" — but that's vague. What colors? What behavior? How do we know it's correct?\n\n## Deliverable\n\nWrite 5-10 concrete scenarios with expected outcomes. Examples:\n\n### Scenario 1: Single note color mapping\n- Input: Play C4 (MIDI note 60)\n- Expected: Particle appears at hue=90° (per pcToHue with A=0°, clockwise)\n- Verify: Visual inspection or screenshot test\n\n### Scenario 2: Velocity affects brightness\n- Input: Play C4 at velocity 127, then velocity 32\n- Expected: First particle brighter than second\n- Verify: Measurable brightness difference\n\n### Scenario 3: Note decay\n- Input: Play and release C4\n- Expected: Particle fades over ~500ms after release\n- Verify: Particle gone within 1 second\n\n### Scenario 4: Chord visualization\n- Input: Play C major chord (C4, E4, G4 simultaneously)\n- Expected: Three particles with hues 90°, 150°, 210°\n- Verify: Three distinct colors visible\n\n## Why This Matters\n\nWithout concrete acceptance criteria, \"done\" is subjective. These scenarios become the definition of success and can drive test fixtures.\n\nSource: Session critique — \"not defining what success looks like for the user\"","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-17T13:16:57.995383Z","created_by":"Nic Young","updated_at":"2026-01-17T13:16:57.995383Z"}
{"id":"synesthetica-0f2","title":"Expand beat detection to full Dixon/BeatRoot algorithm (optional)","description":"Current implementation uses simplified Dixon IOI clustering:\n- Consecutive IOIs only (not all pairs)\n- Cluster scoring with harmonic bonuses\n- Throttled updates for performance\n\nFull Dixon/BeatRoot adds multi-agent beat tracking:\n- Multiple 'agents' track competing tempo hypotheses\n- Agents score points when predicted beats align with onsets\n- Finds actual beat positions, not just tempo\n\n**PROS of expanding:**\n- Beat positions align with actual note onsets (useful for quantization)\n- Better handling of tempo changes mid-performance\n- More robust to irregular playing patterns\n- Required if we ever need score following or beat-synchronous effects\n\n**CONS of expanding:**\n- O(n²) IOI computation vs current O(n)\n- Multi-agent tracking adds memory and CPU overhead\n- Current approach is sufficient for tempo-based visualization\n- Complexity may not be justified for Phase 0 goals\n\n**RECOMMENDATION:** Keep current simplified approach unless we need beat-aligned features. The harmonic scoring handles subdivision detection well enough for visualization purposes.\n\n**Reference:** Dixon, S. (2001). Automatic extraction of tempo and beat from expressive performances. Journal of New Music Research, 30(1), 39-58.","status":"open","priority":2,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-19T16:47:23.338521Z","created_by":"Nic Young","updated_at":"2026-01-19T16:47:23.338521Z","labels":["beat-detection","enhancement","optional"]}
{"id":"synesthetica-0jg","title":"P0: Web app shell","description":"Minimal web app that hosts the pipeline.\n\n- HTML page with canvas\n- MIDI device selection\n- Start/stop session\n- No UI beyond essentials","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-17T12:33:48.42405Z","created_by":"Nic Young","updated_at":"2026-01-18T12:20:10.336752Z","closed_at":"2026-01-18T12:20:10.336752Z","close_reason":"Closed","dependencies":[{"issue_id":"synesthetica-0jg","depends_on_id":"synesthetica-uky","type":"blocks","created_at":"2026-01-17T12:36:01.800816Z","created_by":"Nic Young"},{"issue_id":"synesthetica-0jg","depends_on_id":"synesthetica-2d5","type":"blocks","created_at":"2026-01-17T12:36:01.916107Z","created_by":"Nic Young"}]}
{"id":"synesthetica-0la","title":"KeyDetectionStabilizer: Infer key/mode from note patterns","description":"## Context\n\nThe system currently maps pitch classes to hues but has no awareness of musical key or mode. Knowing the key enables:\n- More musically coherent color choices (tonic feels \"home\", dominant feels \"tension\")\n- Better chord quality detection (is this chord diatonic?)\n- Richer ruleset semantics (in-key vs chromatic notes)\n\n## Approach\n\nImplement a KeyDetectionStabilizer that:\n1. Maintains a histogram of pitch classes over a sliding window\n2. Correlates against major/minor key profiles (Krumhansl-Kessler or similar)\n3. Outputs the most likely key with confidence\n\n## Output\n\nExtends MusicalFrame with:\n```ts\nkey: {\n  tonic: PitchClass;      // 0-11\n  mode: \"major\" | \"minor\" | \"unknown\";\n  confidence: Confidence;\n} | null\n```\n\n## Dependencies\n\n- Depends on NoteTrackingStabilizer (needs active notes)\n- Should be a derived stabilizer in the DAG\n\n## Implementation Notes\n\n- Use a decay window (recent notes weighted more)\n- Consider harmonic vs melodic context\n- May need hysteresis to avoid rapid key changes\n- Start simple (major/minor only), extend to modes later","status":"open","priority":3,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-20T11:34:11.94109Z","created_by":"Nic Young","updated_at":"2026-01-20T11:34:11.94109Z"}
{"id":"synesthetica-10s","title":"Update IVisualGrammar interface docs for entity ownership","description":"## Context\n\nSPEC_009 clarifies that grammars own entity lifecycle. The interface documentation should reflect this.\n\n## Implementation\n\nUpdate `packages/contracts/pipeline/interfaces.ts` IVisualGrammar documentation:\n\n```ts\n/**\n * Visual grammar that transforms VisualIntentFrame into SceneFrame.\n *\n * Grammars:\n * - Decide visual form, not meaning\n * - See only visual intents, never musical events\n * - OWN entity lifecycle (TTL, decay, removal)\n * - Are NOT obligated to tie entity lifetime to intent lifetime\n *\n * Entity lifecycle model:\n * - Intent appears → Grammar may spawn entity with its own TTL\n * - Intent continues → Grammar may reinforce or ignore\n * - Intent disappears → Grammar may spawn release effect or do nothing\n * - Entity TTL expires → Entity is removed (grammar's decision)\n */\nexport interface IVisualGrammar {\n  // ...\n}\n```\n\n## Relates To\n\n- SPEC_009 (Entity Lifecycle is Grammar's Domain)\n- synesthetica-ray (Entity lifecycle resolution)","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-19T10:44:10.882358Z","created_by":"Nic Young","updated_at":"2026-01-19T10:44:10.882358Z"}
{"id":"synesthetica-135","title":"Macro: Time horizon scale (independent of visible windows)","description":"Add a time horizon macro that controls the overall time-to-screen mapping scale, independent of the visible window filters.\n\nCurrently the visible window scale changes with horizon, causing drift visualization to scale incorrectly at compressed horizons.\n\nDesign:\n- Time horizon scale: fixed mapping from time to screen position (max bound = stabilizer analysis window)\n- Visible windows: filter what's shown (grid, notes, drift streaks) with fading at edges\n- The horizon macro controls visible windows, not the underlying scale\n\nDefault value: 8000ms (current MAX_HISTORY_WINDOW_MS)\n\nRelated: synesthetica-o1v (RhythmGrammar implementation)","status":"open","priority":3,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-22T16:00:12.57918Z","created_by":"Nic Young","updated_at":"2026-01-22T16:00:12.57918Z"}
{"id":"synesthetica-15c","title":"Golden tests: End-to-end pipeline (RawInputFrame → SceneFrame)","description":"## Purpose\n\nEnd-to-end golden tests verifying the full pipeline: `RawInputFrame → MusicalFrame → VisualIntentFrame → SceneFrame`.\n\n**Deferred until component boundaries are stable.** This is integration-level testing that builds on stable component behavior.\n\n## When to Implement\n\nAfter all component golden tests are passing:\n- Stabilizer boundary tests (synesthetica-eh6)\n- Ruleset invariant tests (synesthetica-i60)\n- Grammar boundary tests (synesthetica-c7t)\n\n## Test Scenarios (Draft)\n\n### 1. Single note through pipeline\n- Input: note_on C4 at t=0, note_off at t=200ms\n- Expected: Note → PaletteIntent (hue ~90°) → Particle entity with correct color\n\n### 2. Chord through pipeline\n- Input: C major chord (C4, E4, G4)\n- Expected: Three notes → Three PaletteIntents → Three entities with distinct hues\n\n### 3. Phase propagation\n- Input: note_on → hold → note_off sequence\n- Expected: attack → sustain → release phases propagate through all layers\n\n### 4. Dynamics through pipeline\n- Input: Loud note (velocity 127) vs soft note (velocity 32)\n- Expected: Different brightness in entities\n\n## Why Deferred (P4)\n\nEnd-to-end tests are valuable but:\n- They're brittle if any component changes\n- Component-level tests catch most issues earlier\n- We need stable component behavior first\n\n## Location\n\n`packages/engine/test/golden/e2e/`\n\n## Depends On\n\n- synesthetica-eh6 (Stabilizer boundary tests)\n- synesthetica-i60 (Ruleset invariant tests)  \n- synesthetica-c7t (Grammar boundary tests)","status":"open","priority":4,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-19T11:05:40.572761Z","created_by":"Nic Young","updated_at":"2026-01-19T11:05:40.572761Z","dependencies":[{"issue_id":"synesthetica-15c","depends_on_id":"synesthetica-eh6","type":"blocks","created_at":"2026-01-19T11:05:48.84726Z","created_by":"Nic Young"},{"issue_id":"synesthetica-15c","depends_on_id":"synesthetica-i60","type":"blocks","created_at":"2026-01-19T11:05:48.950402Z","created_by":"Nic Young"},{"issue_id":"synesthetica-15c","depends_on_id":"synesthetica-c7t","type":"blocks","created_at":"2026-01-19T11:05:49.051647Z","created_by":"Nic Young"}]}
{"id":"synesthetica-1av","title":"Control op: Override BPM (disable beat detection)","description":"## Context\n\nFor timing practice, users may want to specify a target BPM rather than have the system infer it. This provides a stable reference beat for practice against.\n\n## User Intent\n\n- \"Set tempo to 120 BPM\" → Disable BeatDetectionStabilizer, supply fixed beat\n- \"Clear tempo override\" → Re-enable BeatDetectionStabilizer\n\n## Control Op Design\n\n```ts\n// Set fixed tempo\n{ op: \"setTempo\", bpm: 120, beatsPerBar?: 4 }\n\n// Clear override, resume detection\n{ op: \"clearTempo\" }\n```\n\nAlternative naming options:\n- `setTempo` / `clearTempo` (user-friendly)\n- `overrideBpm` / `clearBpmOverride` (explicit)\n- `fixTempo` / `detectTempo` (describes behavior)\n\n## Implementation\n\n1. ControlOpProcessor receives op\n2. Disables BeatDetectionStabilizer output\n3. Injects synthetic beat into MusicalFrame at fixed interval\n4. On clear, re-enables stabilizer\n\n## Relates To\n\n- SPEC_XXX (control ops, when defined)\n- BeatDetectionStabilizer\n- Timing practice use case","status":"open","priority":3,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-20T11:34:45.96969Z","created_by":"Nic Young","updated_at":"2026-01-20T11:34:45.96969Z"}
{"id":"synesthetica-1g0","title":"Execute RFC 005 migration: Pipeline frame types","description":"## Summary\n\nExecute the migration plan defined in RFC 005 to introduce distinct frame types for each pipeline boundary:\n- `RawInputFrame` (adapter output)\n- `MusicalFrame` (stabilizer output, ruleset input)  \n- `VisualIntentFrame` (ruleset output, grammar input)\n\n## Migration Phases\n\n### Phase 1: Introduce New Types\n- Add new types to @synesthetica/contracts\n- Keep existing CMSFrame temporarily\n\n### Phase 2: Create/Update Specs\n- Create SPEC_009 for new frame type contracts\n- Update SPEC_008 (Pipeline Orchestration)\n- Update SPEC_006 (Stabilizer Statefulness)\n\n### Phase 3: Update Adapters\n- Change MidiAdapter to emit RawInputFrame\n- Update adapter tests\n- Ensure tests pass\n\n### Phase 4: Implement Note-Tracking Stabilizer\n- Create NoteTrackingStabilizer\n- Implement note lifecycle (attack → sustain → release)\n- Add comprehensive tests\n\n### Phase 5: Update Ruleset\n- Change MinimalRuleset to consume MusicalFrame\n- Remove events from VisualIntentFrame\n- Update tests\n\n### Phase 6: Update Grammar\n- Change ParticleGrammar to respond to intents only\n- Remove references to input.events\n- Update tests\n\n### Phase 7: Update Pipeline\n- Update Pipeline class for new frame types\n- Update tests\n\n### Phase 8: Rebuild Web App\n- Update web app for new pipeline\n- Manual testing of note visualization with release behavior\n\n### Phase 9: Cleanup\n- Remove CMSFrame and legacy types\n- Final test pass\n- Update documentation\n\n## Related\n\n- RFC 005: rfcs/rfc_005_pipeline_frame_types.md\n- Depends on: synesthetica-723 (rename Intent to VisualIntent)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-18T15:11:07.491925Z","created_by":"Nic Young","updated_at":"2026-01-19T08:53:09.18912Z","closed_at":"2026-01-19T08:53:09.18912Z","close_reason":"RFC 005 migration complete. All legacy types removed, new pipeline implemented."}
{"id":"synesthetica-1ii","title":"Visual tone: dusty palette for music, neon for system feedback","description":"Establish distinct colour tones for different content types:\n\n- **Musical content**: Dusty, muted tones - warm but subdued\n- **System feedback**: Bright, neon, lit-up appearance - high contrast, attention-grabbing\n\nThis separation helps users distinguish between what they're playing (music) and what the system is communicating (feedback, guides, markers).\n\nExamples:\n- Notes, chords, sustained tones → dusty palette\n- Beat grid, NOW line, reference markers → neon/bright palette","status":"open","priority":3,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-22T15:40:14.368673Z","created_by":"Nic Young","updated_at":"2026-01-22T15:40:14.368673Z"}
{"id":"synesthetica-1wq","title":"SPEC: Macro-to-grammar parameter binding","description":"## The Gap\n\nMacros (articulation, persistence, emphasis.*) are 0–1 continuous values that \"adjust high-level characteristics\", but no contract specifies how these map to individual grammar parameters.\n\n## Why It Matters\n\n- SPEC_004 provides macro annotations with directionality descriptions (for LLM)\n- But grammars have paramsSchema — how do macro changes translate to param changes?\n- Implementation teams must reverse-engineer intent from prose annotations\n- Different grammars may interpret the same macro delta differently\n\n## Current State\n\n- `Preset.macros` defines articulation, persistence, emphasis.{melody,harmony,rhythm,timbre}\n- `GrammarAnnotation.macroResponses` indicates responsiveness (strong/moderate/weak/none)\n- `IGrammar.paramsSchema` exists but linkage to macros is undefined\n\n## Questions to Answer\n\n1. Is there a binding layer between macros and grammar params?\n2. Do grammars receive macro values directly, or do they receive transformed params?\n3. How does `macroResponses.responsiveness` translate to actual behavior?\n4. Are sensitivity curves (linear, exponential) per-grammar or global?\n\n## Relates To\n\n- SPEC_004 (macro annotations)\n- RFC_002 (Preset interface)\n- synesthetica-30r (macro interpolation curves)\n\n## Output\n\nEither extend SPEC_004 or create a new spec defining the macro → grammar param binding contract.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-17T13:02:49.038531Z","created_by":"Nic Young","updated_at":"2026-01-17T13:02:49.038531Z"}
{"id":"synesthetica-2d5","title":"P0: Canvas2D renderer","description":"Minimal renderer that draws SceneFrame entities to canvas.\n\n- Canvas2D (not WebGL)\n- Draw particles as circles\n- Handle color, size, opacity from entity style\n- No effects or post-processing","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-17T12:33:41.163358Z","created_by":"Nic Young","updated_at":"2026-01-18T12:20:01.97557Z","closed_at":"2026-01-18T12:20:01.97557Z","close_reason":"Closed","dependencies":[{"issue_id":"synesthetica-2d5","depends_on_id":"synesthetica-c79","type":"blocks","created_at":"2026-01-17T12:37:00.038581Z","created_by":"Nic Young"}]}
{"id":"synesthetica-2uv","title":"Should Style be called VisualGrammar?","status":"closed","priority":2,"issue_type":"task","owner":"nic@o1labs.org","created_at":"2026-01-14T19:18:59.937246Z","created_by":"Nic Young","updated_at":"2026-01-14T20:14:30.051662Z","closed_at":"2026-01-14T20:14:30.051662Z","close_reason":"Resolved. Renamed Style → Grammar throughout codebase. Annotations include aliases field for user-facing synonyms (style, look, effect). See SPEC_004."}
{"id":"synesthetica-30r","title":"Define macro interpolation curves","description":"Macros are 0-1 continuous values but how they map to internal parameters (linear, exponential, stepped) is not defined. Low priority for v0.","status":"open","priority":4,"issue_type":"task","created_at":"2026-01-16T09:39:03.344196Z","created_by":"Nic Young","updated_at":"2026-01-16T09:39:25.569156Z"}
{"id":"synesthetica-39e","title":"Vocabulary: Add harmonic mappings to MusicalVisualVocabulary","description":"Implement MusicalVisualVocabulary.annotate() for chords.\n\n## Scope\n\nWire up buildChordShape() to the vocabulary's annotate() method so that AnnotatedChord.shape is populated.\n\n## Current State\n\n- ChordDetectionStabilizer provides MusicalChord with root, quality, voicing\n- Contracts define ChordShapeGeometry, ChordShapeElement\n- buildChordShape() (synesthetica-hyz) computes geometry from chord\n\n## Implementation\n\nIn MusicalVisualVocabulary.annotate():\n```ts\nfor (const chord of frame.chords) {\n  const shape = buildChordShape(chord, this.pitchHueInvariant);\n  annotatedChords.push({\n    chord,\n    visual: this.computeChordVisual(chord),\n    noteIds: chord.noteIds,\n    shape,\n  });\n}\n```\n\n## Location\n\npackages/engine/src/vocabulary/MusicalVisualVocabulary.ts\n\n## Depends on\n\n- synesthetica-hyz (buildChordShape)\n\n## Enables\n\n- synesthetica-sn4 (HarmonyGrammar)","status":"closed","priority":3,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-23T15:07:21.095079Z","created_by":"Nic Young","updated_at":"2026-01-28T12:07:29.439225Z","closed_at":"2026-01-28T12:07:29.439225Z","close_reason":"MusicalVisualVocabulary now uses buildChordShape() from utils to populate AnnotatedChord.shape","dependencies":[{"issue_id":"synesthetica-39e","depends_on_id":"synesthetica-hyz","type":"blocks","created_at":"2026-01-28T11:38:39.618744Z","created_by":"Nic Young"}]}
{"id":"synesthetica-3th","title":"Chord detection: split at bar boundaries","description":"When beat/bar detection is implemented, chord detection should optionally split chord accumulation at bar boundaries. Currently chords accumulate within an onset window regardless of bar position. Deferred from initial ChordDetectionStabilizer implementation.","status":"open","priority":3,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-19T12:01:36.942135Z","created_by":"Nic Young","updated_at":"2026-01-19T12:01:36.942135Z"}
{"id":"synesthetica-49n","title":"Implement KeyDetectionStabilizer","description":"Detect the current musical key/mode from chord progressions.\n\n## Purpose\n\nKeyDetectionStabilizer infers the tonal center (key) from chord patterns. This enables:\n- Key-relative chord function analysis (I, IV, V, etc.)\n- Modal brightness adjustments in vocabulary\n- Modulation detection\n\n## Architecture\n\nDerived stabilizer in the DAG:\n```\nChordDetectionStabilizer → KeyDetectionStabilizer → ProgressionStabilizer\n```\n\n## Key Detection Approach\n\n**SUGGESTION**: Use Krumhansl-Kessler key-finding algorithm:\n1. Accumulate pitch-class distribution from recent notes/chords\n2. Correlate against major and minor key profiles\n3. Select best-matching key with confidence score\n\nAlternative: Temperley profiles (similar approach, different weights).\n\n## Output\n\n```typescript\ninterface KeyState {\n  key: PitchClass | null;        // 0-11 (C=0, C#=1, etc.), null if disabled/unknown\n  mode: \"major\" | \"minor\" | null;\n  confidence: Confidence;        // 0-1, 0 when disabled\n  stability: number;             // How long key has been stable\n  source: \"detected\" | \"override\" | \"disabled\";\n}\n```\n\nWhen `source` is `\"disabled\"`, downstream stabilizers know key detection is intentionally off (not just uncertain).\n\n## Control Ops\n\n### SetKeyOp: Override with specific key\nUsers can specify the intended key, which:\n- Disables automatic key detection when set\n- Provides ground truth for visualizations\n- Can be cleared to resume detection\n\n```typescript\ninterface SetKeyOp extends ControlOp {\n  type: \"set_key\";\n  key: PitchClass;               // 0-11\n  mode: \"major\" | \"minor\";\n}\n```\n\n### ClearKeyOp: Resume detection\n```typescript\ninterface ClearKeyOp extends ControlOp {\n  type: \"clear_key\";\n}\n```\n\n### DisableKeyOp: Practice without key context\nUsers can explicitly disable key detection for atonal/modal practice:\n- Key detection stops running\n- Downstream stabilizers receive `source: \"disabled\"`\n- No key-relative analysis (function, tension components)\n- Useful for: atonal music, modal exploration, free improvisation\n\n```typescript\ninterface DisableKeyOp extends ControlOp {\n  type: \"disable_key\";\n}\n```\n\nThis is different from ClearKeyOp:\n- `clear_key`: Resume automatic detection\n- `disable_key`: Explicitly turn off key awareness\n\n## State Machine\n\n```\n            SetKeyOp                 ClearKeyOp\n    ┌─────────────────────────┐    ┌───────────┐\n    │                         │    │           │\n    ▼                         │    ▼           │\n┌─────────┐  DisableKeyOp  ┌──┴────────┐  SetKeyOp  ┌──────────┐\n│ DETECT  │ ─────────────► │ DISABLED  │ ◄───────── │ OVERRIDE │\n└─────────┘                └───────────┘            └──────────┘\n    ▲                         │                         │\n    │      ClearKeyOp         │                         │\n    └─────────────────────────┴─────────────────────────┘\n```\n\n## Parameters\n\n- `windowMs`: How much history to consider (default: 8000ms)\n- `minConfidence`: Threshold for reporting key (default: 0.6)\n- `hysteresis`: Stability requirement before changing key (default: 2000ms)\n\n## Acceptance Criteria\n\n- [ ] Key detection from chord patterns\n- [ ] SetKeyOp control op for manual override\n- [ ] ClearKeyOp control op to resume detection\n- [ ] DisableKeyOp control op to turn off key awareness\n- [ ] Confidence scores for detected keys\n- [ ] Hysteresis to prevent rapid key changes\n- [ ] KeyState.source field indicates detection mode\n- [ ] Unit tests with known progressions\n- [ ] Integration with ProgressionStabilizer\n\n## Research References\n\n- Krumhansl, C. (1990). Cognitive Foundations of Musical Pitch\n- Temperley, D. (1999). What's Key for Key?\n- Music21 library key detection implementation\n\n## Dependencies\n\n- ChordDetectionStabilizer (provides chord data)\n- ControlOp infrastructure (for SetKeyOp, ClearKeyOp, DisableKeyOp)","status":"open","priority":3,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-23T15:08:06.377324Z","created_by":"Nic Young","updated_at":"2026-01-23T15:13:05.012253Z"}
{"id":"synesthetica-4f0","title":"Drift rings should be subdivision-aware","description":"If playing 16th notes against a quarter-note tempo, drift should be measured against the nearest subdivision, not the beat. Currently all off-beat notes show as drifting even if perfectly on the subdivision.\n\nRFC: rfcs/rfc_008_per_onset_subdivision_drift.md","status":"closed","priority":3,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-20T17:52:47.356522Z","created_by":"Nic Young","updated_at":"2026-01-21T14:13:32.897284Z","closed_at":"2026-01-21T14:13:32.897284Z","close_reason":"Implemented RFC 008: Per-onset subdivision drift analysis"}
{"id":"synesthetica-589","title":"Decide platform and rendering target for v0","description":"The PRD defers platform assumptions, but practical development requires a decision.\n\nOptions:\n1. Browser-first: Web Audio API + Web MIDI API + Canvas/WebGL\n2. Native-first: Electron + Node MIDI libraries + native rendering\n3. Hybrid: Core logic portable, adapters platform-specific\n\nConsiderations:\n- Browser has better MIDI support than commonly assumed (Web MIDI API)\n- Audio input in browser requires user permission flow\n- WebGL gives good rendering performance\n- Native gives lower latency but more setup friction\n\nOutput: Document platform decision in PRD.md under 'Platform assumptions'. This unblocks adapter and renderer implementation.","status":"closed","priority":1,"issue_type":"feature","owner":"nic@o1labs.org","created_at":"2026-01-14T13:11:23.362362Z","created_by":"Nic Young","updated_at":"2026-01-14T13:24:47.978068Z","closed_at":"2026-01-14T13:24:47.978068Z","close_reason":"Platform decision documented in PRD.md: Browser-first (Web MIDI + Web Audio + WebGL), with audio file input for testing. Native deferred to post-v0."}
{"id":"synesthetica-5cq","title":"SPEC: Audio adapter contract","description":"## The Gap\n\nAudio adapter is referenced in PRD and planned for Phase 2, but no interface specifies how audio evidence maps to RawInputFrame and MusicalFrame fields.\n\n## Why It Matters\n\n- Can't implement audio support without this contract\n- Invariants assume audio adapters produce uncertain musical state\n- Audio is a gating requirement for LLM-mediation (synesthetica-8f4)\n- synesthetica-y7q (Meyda evaluation) needs target contract to evaluate against\n\n## Current State\n\n- IRawSourceAdapter.nextFrame(): RawInputFrame is generic\n- MusicalFrame types support confidence/provenance for uncertainty\n- No spec for pitch-class distribution format from audio\n- No spec for beat detection output or chord inference confidence\n\n## Questions to Answer\n\n1. How are pitch-class distributions represented in RawInputFrame?\n2. What confidence thresholds distinguish \"heard C\" from \"maybe C\"?\n3. How does beat detection produce BeatState in MusicalFrame?\n4. What's the expected latency profile for audio analysis?\n\n## Relates To\n\n- synesthetica-8f4 (Audio gates LLM-mediation)\n- synesthetica-y7q (Meyda evaluation)\n- SPEC_009 (Pipeline frame types)\n\n## Output\n\nNew spec (SPEC_010) defining AudioAdapter contract and RawInputFrame/MusicalFrame output format for audio.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-17T13:04:25.16537Z","created_by":"Nic Young","updated_at":"2026-01-19T10:33:55.599755Z"}
{"id":"synesthetica-5hb","title":"Add swing support to rhythmic analysis","description":"Add ability to analyze and visualize swing timing.\n\nRequires:\n- Explicit musician input on intention to swing (like BPM, never inferred)\n- Update BeatDetectionStabilizer to account for swing ratio\n- Grammar visualization of swing feel\n\nDiscovered during RFC 008 subdivision drift simulation - swung notes (290ms vs 250ms straight 8th) currently show as 'bad' 32nd timing because we have no concept of intentional swing.","status":"open","priority":4,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-21T14:44:00.043267Z","created_by":"Nic Young","updated_at":"2026-01-21T14:44:00.043267Z","dependencies":[{"issue_id":"synesthetica-5hb","depends_on_id":"synesthetica-o1v","type":"blocks","created_at":"2026-01-21T15:54:27.733418Z","created_by":"Nic Young"}]}
{"id":"synesthetica-5l9","title":"P0: Build-time annotation validation","description":"## Context\n\nValidate annotations at build time per SPEC_004. This is part of the LLM mediation layer.\n\n**Note:** This is deferred until LLM mediation development begins. See synesthetica-8f4 (audio gates LLM) and synesthetica-gyj (LLM threshold criteria).\n\n## Checks\n- Grammar `id` must be unique\n- Grammar `aliases` should not conflict across grammars  \n- `illustrates` values must be valid MusicalConcept\n- `traits` values must be valid VisualTrait\n- Macro annotations must exist for all macros in Preset.macros schema\n\n## Implementation\n- TypeScript compiler plugin, or\n- Build script that validates annotation files\n- CI integration\n\n## On failure\n- Build fails with clear error message identifying the violation\n\n## Relates To\n- SPEC_004 (LLM mediation and annotations)\n- synesthetica-gyj (LLM threshold criteria)","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-17T12:56:08.512782Z","created_by":"Nic Young","updated_at":"2026-01-19T10:44:35.681604Z","dependencies":[{"issue_id":"synesthetica-5l9","depends_on_id":"synesthetica-c79","type":"blocks","created_at":"2026-01-17T12:56:15.559076Z","created_by":"Nic Young"},{"issue_id":"synesthetica-5l9","depends_on_id":"synesthetica-gyj","type":"blocks","created_at":"2026-01-19T10:45:18.508906Z","created_by":"Nic Young"}]}
{"id":"synesthetica-5nl","title":"Grammar: Ambient Harmony","description":"Ambient/background variant of Basic Harmony grammar.\n\nAtmospheric harmonic wash rather than precise chord feedback:\n- Colour fields that shift with harmony\n- Blended, flowing transitions\n- Suitable for background/screensaver mode\n\nSee also: synesthetica-sn4 (Basic Harmony grammar)","status":"open","priority":4,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-22T15:41:49.473499Z","created_by":"Nic Young","updated_at":"2026-01-22T15:41:49.473499Z"}
{"id":"synesthetica-6lf","title":"P0: First grammar (particles on note_on)","description":"First grammar implementation. Spawn particles on note events.\n\n- Spawn particle at note_on\n- Color from PaletteIntent\n- Fade/decay over time\n- Simple physics (gravity or drift)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-17T12:33:32.015124Z","created_by":"Nic Young","updated_at":"2026-01-18T10:50:31.446084Z","closed_at":"2026-01-18T10:50:31.446084Z","close_reason":"Implemented as ParticleGrammar with unit tests. Golden tests deferred.","dependencies":[{"issue_id":"synesthetica-6lf","depends_on_id":"synesthetica-c79","type":"blocks","created_at":"2026-01-17T12:36:59.808993Z","created_by":"Nic Young"},{"issue_id":"synesthetica-6lf","depends_on_id":"synesthetica-901","type":"blocks","created_at":"2026-01-17T12:40:24.178195Z","created_by":"Nic Young"}]}
{"id":"synesthetica-6t2","title":"Define Phase 1 exit criteria and time budget","description":"## Problem\n\nPhase 1 (ruleset/grammar exploration) is where the \"magic\" happens — but it's the least specified part of the plan. Currently just two vague issues: \"Ruleset iteration\" and \"Grammar iteration\".\n\n## Questions to Answer\n\n1. **Time budget**: How long do you want to spend in Phase 1? Weeks? Months?\n\n2. **Exit criteria for rulesets**:\n   - What makes a ruleset \"feel right\"?\n   - How many musical scenarios should it handle well?\n   - What's the golden test coverage target?\n\n3. **Exit criteria for grammars**:\n   - How many grammars constitute a \"vocabulary\"?\n   - What visual diversity is needed?\n   - How do you know when to stop iterating?\n\n4. **Confidence threshold**:\n   - What would make you confident to move to Phase 2?\n   - What discoveries would force a return to specs?\n\n## Why This Matters\n\nDiscovery work without bounds tends to expand indefinitely. Defining \"done\" for exploration keeps it productive.\n\nSource: Session critique — \"budgeting for the 'magic' work\"","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-17T13:17:17.88231Z","created_by":"Nic Young","updated_at":"2026-01-17T13:17:17.88231Z"}
{"id":"synesthetica-6zz","title":"SPEC: Router/stabilizer interaction and per-part state","description":"## The Gap\n\nRFC_003 introduces routing by PartId, SPEC_006 defines stateful stabilizers, but their interaction is ambiguous.\n\n## Why It Matters\n\n- Should stabilizers run before or after routing?\n- Do stabilizers maintain per-part state or global state?\n- Can stabilizers aggregate across parts (ensemble tension)?\n- Some signals (global activity) conceptually span parts\n\n## Current State\n\n- IRouter.route(frame) → Map\u003cPartId, CMSFrame\u003e\n- IStabilizer has init/dispose/apply/reset lifecycle\n- SPEC_008 shows \"for each part, run stabilizers\" but doesn't clarify instantiation\n- CMS events have part: PartId but control signals may be global\n\n## Questions to Answer\n\n1. Are stabilizers instantiated per-part or singleton?\n2. If per-part, when are new stabilizer instances created?\n3. Can a stabilizer read signals from other parts?\n4. What's the ordering: route then stabilize, or stabilize then route?\n\n## Relates To\n\n- RFC_003 (parts and routing)\n- SPEC_006 (stabilizer lifecycle)\n- SPEC_008 (pipeline orchestration)\n\n## Output\n\nAdditions to SPEC_006 or SPEC_008 clarifying stabilizer instantiation and data access scope.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-17T13:03:48.312521Z","created_by":"Nic Young","updated_at":"2026-01-17T13:03:48.312521Z"}
{"id":"synesthetica-723","title":"Rename Intent to VisualIntent throughout codebase","description":"## Summary\n\nRename `Intent` to `VisualIntent` throughout the codebase for clarity. This includes derivative names:\n- `Intent` → `VisualIntent`\n- `IntentFrame` → `VisualIntentFrame`\n- Any other derived names\n\n## Why\n\nThe term \"Intent\" is ambiguous - we have visual intents (what grammars consume) and could have other intent types. Making this explicit improves code clarity and aligns with RFC 005.\n\n## Scope\n\n- packages/contracts/intents/intents.ts\n- All consumers of these types across packages\n- Update specs and RFCs that reference these types\n\n## Related\n\n- RFC 005: Pipeline Frame Types and Musical Abstraction","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-18T15:10:35.39742Z","created_by":"Nic Young","updated_at":"2026-01-19T08:53:20.455624Z","closed_at":"2026-01-19T08:53:20.455624Z","close_reason":"VisualIntent naming is now used throughout codebase."}
{"id":"synesthetica-78e","title":"Implement DynamicsStabilizer","description":"Analyze velocity patterns to produce DynamicsState. Independent stabilizer (no dependencies). Outputs level (0-1) and trend (rising/falling/stable). See SPEC_008 for stabilizer DAG architecture.","status":"open","priority":2,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-19T15:15:56.948678Z","created_by":"Nic Young","updated_at":"2026-01-19T15:16:17.324315Z"}
{"id":"synesthetica-830","title":"Rubato visualization grammar","description":"Specialized grammar for visualizing expressive timing (rubato, tempo fluctuation).\n\n## Purpose\n\nWhile RhythmGrammar shows individual onset drift from a grid, RubatoRhythmGrammar reveals the *shape* of expressive timing over time. It serves a different pedagogical purpose: understanding how a performer uses tempo flexibility as an expressive tool.\n\n## Core Visual Elements\n\n1. **Onset trails**: Each note leaves a trace showing timing relative to beat\n   - Multiple notes reveal patterns (consistently early? drifting?)\n   - Trail shape shows timing evolution\n\n2. **\"Personal beat\" ghost grid**: If player is consistently offset from the beat\n   - Shows the difference between \"off the grid\" and \"on your own grid\"\n   - Requires pattern detection beyond single-onset drift\n\n3. **Phase visualization**: Overall drift curve over time\n   - Horizontal S-shape dissected by zero (perfect rhythm)\n   - Reveals rubato patterns: push-pull, gradual drift, anchor points\n\n4. **Bar anchor emphasis**: First beat of bar with tighter drift tolerance\n   - Many performers anchor on downbeats while playing rubato between\n\n## Data Requirements\n\nUses same OnsetDrift data as RhythmGrammar, but interprets it differently:\n- Looks for patterns across multiple onsets\n- May require prescribed tempo/meter to establish reference grid\n- Mathematically, rubato surfaces as 'nearest=32nd' or 'nearest=16th' which is correct but doesn't capture expressive intent\n\n## Design Questions (deferred)\n\n- What additional data structure might help? (drift history, trend detection)\n- How to distinguish intentional rubato from rhythmic inconsistency?\n- Should this require Tier 2/3 data, or work with detected tempo?\n\n## Architecture Note\n\nThis grammar tests the architecture: should be achievable with no pipeline or downstream component changes, only a new grammar using existing OnsetDrift data.\n\n## Depends On\n- synesthetica-o1v: RhythmGrammar (core rhythm visualization)","status":"open","priority":4,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-21T14:44:53.172184Z","created_by":"Nic Young","updated_at":"2026-01-21T16:16:50.841714Z","dependencies":[{"issue_id":"synesthetica-830","depends_on_id":"synesthetica-o1v","type":"blocks","created_at":"2026-01-21T15:54:27.844318Z","created_by":"Nic Young"}]}
{"id":"synesthetica-89i","title":"Grammar: Pitch Accuracy","description":"Visualize pitch accuracy for instruments with continuous pitch (voice, violin, fretless bass, etc.).\n\nShow:\n- Target pitch vs actual pitch\n- Drift from equal temperament\n- Vibrato patterns\n- Pitch bends and slides\n\nRequires actual pitch data (Hz) from audio analysis, not just MIDI note numbers.\n\nRelated: synesthetica-w5z (include actual pitch for continuous-pitch instruments)","status":"open","priority":3,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-22T15:40:58.517545Z","created_by":"Nic Young","updated_at":"2026-01-22T15:40:58.517545Z"}
{"id":"synesthetica-8do","title":"Define Preset storage and lifecycle","description":"Preset lifecycle is unspecified:\n- How are presets created, saved, edited?\n- Where are they stored? (localStorage, JSON files, DB)\n- Who validates them against the schema?\n- How do built-in vs user presets coexist?\n\nOutput:\n1. Document preset storage format and location\n2. Add validation helpers or schema to packages/contracts\n3. Define the distinction between builtin/user presets\n4. Amend RFC 002 or create SPEC for preset management","status":"closed","priority":2,"issue_type":"feature","owner":"nic@o1labs.org","created_at":"2026-01-14T13:11:23.74087Z","created_by":"Nic Young","updated_at":"2026-01-14T14:06:18.77741Z","closed_at":"2026-01-14T14:06:18.77741Z","close_reason":"Preset storage defined in SPEC_001_preset_storage.md. Contracts added to packages/contracts/config/preset.ts: PresetSource, PresetMeta, ValidationResult, IPresetCatalog. localStorage for v0, interface abstracts for future migration."}
{"id":"synesthetica-8f4","title":"Audio adapter gates LLM-mediation development","description":"## Decision\n\nAudio input is a gating requirement for LLM-mediation development.\n\n## Rationale\n\n1. **Primary use case**: Ear training (learning guitar by ear) requires audio input, not just MIDI\n2. **Architectural validation**: Audio introduces confidence/uncertainty as first-class — the pipeline must handle probabilistic input\n3. **Source diversity**: Proves the RawInputFrame abstraction works for both MIDI and audio\n\n## Implication\n\nLLM-mediation development should not begin until audio adapter is functional and integrated.\n\n## Relates To\n\n- synesthetica-5cq (Audio adapter CMS contract spec)\n- synesthetica-y7q (Evaluate Meyda.js for audio adapter)\n- synesthetica-jes (Phase 2: Full System epic)","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-19T10:27:32.55917Z","created_by":"Nic Young","updated_at":"2026-01-19T10:27:32.55917Z","dependencies":[{"issue_id":"synesthetica-8f4","depends_on_id":"synesthetica-5cq","type":"blocks","created_at":"2026-01-19T10:35:27.04408Z","created_by":"Nic Young"},{"issue_id":"synesthetica-8f4","depends_on_id":"synesthetica-y7q","type":"blocks","created_at":"2026-01-19T10:35:38.279605Z","created_by":"Nic Young"}]}
{"id":"synesthetica-8kf","title":"SPEC: Grammar registration and discovery mechanism","description":"## The Gap\n\nGrammars are referenced by ID in presets, but no contract specifies how grammars are discovered, registered, or validated at runtime.\n\n## Why It Matters\n\n- How does the engine know which grammars are available?\n- What happens when a preset references a non-existent grammar?\n- How do contributors add grammars without modifying core code?\n- Open/closed principle requires a discovery mechanism\n\n## Current State\n\n- Preset.grammars references grammarId strings\n- IGrammar interface exists but no IGrammarRegistry\n- synesthetica-d53 calls for contribution guide but not the registry contract\n- synesthetica-5l9 validates annotations but not grammar existence\n\n## Questions to Answer\n\n1. Is there an IGrammarRegistry interface?\n2. How are grammars discovered (import map? directory scan? explicit registration?)\n3. What validation runs at grammar load time?\n4. What diagnostic is emitted for missing grammar references?\n\n## Relates To\n\n- RFC_002 (grammar API)\n- synesthetica-d53 (contribution guide)\n- synesthetica-5l9 (annotation validation)\n\n## Output\n\nNew interface (IGrammarRegistry) and additions to SPEC_008 or a new spec.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-17T13:03:38.688006Z","created_by":"Nic Young","updated_at":"2026-01-17T13:03:38.688006Z"}
{"id":"synesthetica-901","title":"P0: Golden test infrastructure","description":"Test harness for rulesets and grammars.\n\n- CMS fixtures (JSON) → expected IntentFrame\n- IntentFrame sequences → expected entity snapshots\n- Deterministic via rngSeed\n- Snapshot comparison utilities","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-17T12:33:53.102177Z","created_by":"Nic Young","updated_at":"2026-01-19T11:03:50.634862Z","closed_at":"2026-01-19T11:03:50.634862Z","close_reason":"Split into focused issues:\n- synesthetica-h06: Test harness and fixture utilities\n- synesthetica-eh6: Stabilizer boundary tests (RawInputFrame → MusicalFrame)\n- synesthetica-i60: Ruleset invariant tests (pitch→hue, velocity→brightness)\n\nGrammar/scene boundary tests deferred until grammar behavior stabilizes.","dependencies":[{"issue_id":"synesthetica-901","depends_on_id":"synesthetica-c79","type":"blocks","created_at":"2026-01-17T12:40:23.954325Z","created_by":"Nic Young"}]}
{"id":"synesthetica-9dl","title":"Grammar: Ambient Dynamics","description":"Ambient/background variant of Dynamics grammar.\n\nAtmospheric intensity field rather than precise dynamic feedback:\n- Breathing, pulsing intensity\n- Organic volume visualization\n- Suitable for background/screensaver mode\n\nSee also: synesthetica-s97 (Dynamics grammar)","status":"open","priority":4,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-22T15:42:03.435454Z","created_by":"Nic Young","updated_at":"2026-01-22T15:42:03.435454Z"}
{"id":"synesthetica-9eb","title":"Define frame timing and clock semantics","description":"The timing model is underspecified.\n\nQuestions to resolve:\n- What drives the frame clock? Pull-based (renderer requests) or push-based (adapters emit)?\n- What happens when audio and MIDI have different latencies?\n- What epoch are Ms timestamps relative to?\n- How is frame synchronization handled across multiple sources?\n\nOutput: Add timing/clock types to packages/contracts/core. Document frame semantics in a new SPEC or amend RFC 002.","status":"closed","priority":2,"issue_type":"feature","owner":"nic@o1labs.org","created_at":"2026-01-14T13:11:22.799033Z","created_by":"Nic Young","updated_at":"2026-01-15T12:32:57.153332Z","closed_at":"2026-01-15T12:32:57.153332Z","close_reason":"Resolved in SPEC_005_frame_timing_and_clock.md. Decisions: pull-based clock, session-relative timestamps, accept differing latencies for v0, per-part CMS (not consolidated). Ensemble mode deferred to synesthetica-h09."}
{"id":"synesthetica-9f3","title":"Define entity budget and performance constraints","description":"PRD mentions 60fps target / 30fps fallback but no entity limits or constraint system is specified. Need to define what limits entity count and how grammars handle overload.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-16T09:39:03.494771Z","created_by":"Nic Young","updated_at":"2026-01-16T09:39:25.71426Z","dependencies":[{"issue_id":"synesthetica-9f3","depends_on_id":"synesthetica-ray","type":"blocks","created_at":"2026-01-19T10:35:26.646082Z","created_by":"Nic Young"}]}
{"id":"synesthetica-a3q","title":"Clarify Ruleset statefulness requirements","description":"IRuleset.map(frame: CMSFrame): IntentFrame is currently stateless, but some mappings need history:\n- 'Tension' might depend on harmonic trajectory over several beats\n- Beat phase detection might need memory\n- Phrase-level dynamics require lookback\n\nQuestions to resolve:\n- Should rulesets be allowed internal state?\n- Or should history be a stabilizer concern (stabilizers build up state, rulesets remain pure)?\n- If stateful, what's the reset/init contract?\n\nOutput: Amend IRuleset interface in packages/contracts/pipeline/interfaces.ts if needed. Document the decision in RFC 002 or a new ADR.","status":"closed","priority":2,"issue_type":"feature","owner":"nic@o1labs.org","created_at":"2026-01-14T13:11:22.985862Z","created_by":"Nic Young","updated_at":"2026-01-15T14:53:33.491396Z","closed_at":"2026-01-15T14:53:33.491396Z","close_reason":"Resolved in SPEC_006. Decision: Rulesets remain pure/stateless. Stabilizers are explicitly stateful with init/dispose/reset lifecycle. Temporal reasoning (tension, beat phase, phrase position) belongs in stabilizers as derived signals."}
{"id":"synesthetica-al3","title":"SPIKE: Visual Vocabulary Design Decisions","status":"open","priority":2,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-23T15:06:48.576552Z","created_by":"Nic Young","updated_at":"2026-01-23T15:06:48.576552Z"}
{"id":"synesthetica-apy","title":"Implement RFC 007: Beat detection redesign","description":"Replace BeatDetectionStabilizer with purely descriptive rhythmic analysis per RFC 007.\n\n## Summary\n- Remove tempo inference (category error: inferring future intent from historic data)\n- Output RhythmicAnalysis: detectedDivision, recentOnsets, stability, confidence, referenceOnset\n- Add prescribedTempo and prescribedMeter to MusicalFrame (set via control ops, not stabilizer)\n- Update grammars to use new model\n\n## Implementation tasks\n1. Add types to contracts: RhythmicAnalysis, TimeSignature\n2. Update MusicalFrame: remove BeatState, add rhythmicAnalysis/prescribedTempo/prescribedMeter\n3. Rewrite BeatDetectionStabilizer (simpler: collect onsets, cluster IOIs, output analysis)\n4. Update existing tests to use new interface\n5. Add new tests for:\n   - Division detection at various tempos\n   - Stability measurement (steady vs rubato)\n   - Confidence with varying sample counts\n   - Subdivision handling (no longer a problem since no tempo locking)\n6. Update grammars to check prescribedTempo/prescribedMeter before intent-relative visuals\n\n## Reference\n- RFC: rfcs/rfc_007_beat_detection_redesign.md\n- Current impl: packages/engine/src/stabilizers/BeatDetectionStabilizer.ts","status":"closed","priority":2,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-20T15:21:33.328576Z","created_by":"Nic Young","updated_at":"2026-01-20T15:49:29.128654Z","closed_at":"2026-01-20T15:49:29.128654Z","close_reason":"Implemented in commit 9fb3458: replaced BeatState with RhythmicAnalysis, added prescribedTempo/prescribedMeter, rewrote BeatDetectionStabilizer for purely descriptive analysis"}
{"id":"synesthetica-b50","title":"SPEC: Ruleset fallback behavior and confidence gating","description":"## The Gap\n\nIRuleset.map(frame: CMSFrame): IntentFrame is minimal. No guidance on how rulesets handle incomplete/uncertain musical data.\n\n## Why It Matters\n\n- What if CMS has no chord info (audio inference failed)?\n- How should ruleset weight intents when signals are missing?\n- Should rulesets emit all intent types every frame, or only meaningful ones?\n- No confidence thresholds or gating rules are specified\n\n## Current State\n\n- CMSFrame has events, controls, distributions — all optional/sparse\n- IntentFrame has intents array and uncertainty scalar\n- Invariant I5: \"Confidence affects rendering stability, not meaning\"\n- But no guidance on how rulesets should implement this\n\n## Questions to Answer\n\n1. What's the fallback behavior when expected CMS signals are absent?\n2. Are there confidence thresholds below which signals are ignored?\n3. Must rulesets emit all four intent types (palette, motion, texture, shape)?\n4. How does the ruleset compute IntentFrame.uncertainty?\n\n## Relates To\n\n- SPEC_003 (invariants I1-I5)\n- RFC_002 (ruleset role)\n- SPEC_007 (graceful degradation)\n\n## Output\n\nAdditions to RFC_002 or a new spec documenting ruleset semantics for edge cases.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-17T13:02:59.418382Z","created_by":"Nic Young","updated_at":"2026-01-17T13:02:59.418382Z"}
{"id":"synesthetica-b5n","title":"Grammar: Ambient Pitch","description":"Ambient/background variant of Pitch Accuracy grammar.\n\nAtmospheric pitch landscape rather than precise accuracy feedback:\n- Flowing pitch contours\n- Gentle intonation visualization\n- Suitable for background/screensaver mode\n\nSee also: synesthetica-89i (Pitch Accuracy grammar)","status":"open","priority":4,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-22T15:41:58.629746Z","created_by":"Nic Young","updated_at":"2026-01-22T15:41:58.629746Z"}
{"id":"synesthetica-bad","title":"Implement ProgressionStabilizer","description":"Track chord progressions and compute harmonic tension.\n\n## Purpose\n\nProgressionStabilizer tracks chord sequences over time and computes harmonic tension. This enables grammars to visualize harmonic movement, resolution, and surprise.\n\n## Architecture\n\nDerived stabilizer in the DAG:\n```\nChordDetectionStabilizer → KeyDetectionStabilizer → ProgressionStabilizer\n                                                  ↗\n                        (can operate without key detection at reduced capability)\n```\n\n## Operating Modes\n\nProgressionStabilizer adapts based on KeyDetectionStabilizer output:\n\n### 1. Key Available (`source: \"detected\"` or `\"override\"`)\nFull capability:\n- Function analysis (I, ii, IV, V, etc.)\n- Key-relative tension (hierarchical + key distance components)\n- Cadence detection\n- Secondary dominant identification\n\n### 2. Key Uncertain (low confidence)\nPartial capability:\n- Surface dissonance and voice leading still computed\n- Hierarchical tension uses best-guess key with high uncertainty\n- Function analysis marked as uncertain\n\n### 3. Key Disabled (`source: \"disabled\"`)\nKey-agnostic mode:\n- No function analysis (field omitted, not uncertain)\n- No key-distance tension component\n- Surface dissonance and voice leading still computed\n- Suitable for atonal/modal music\n\nThis distinction matters for grammars: uncertain key means \"we're guessing\"; disabled key means \"intentionally not using key context\".\n\n## Core Responsibilities\n\n### 1. Progression Tracking\n- Maintain rolling window of recent chords\n- Track chord timing and duration\n- Detect chord changes vs. sustained harmony\n\n### 2. Harmonic Tension Computation\n\n**SUGGESTION**: Use Lerdahl-Jackendoff tonal tension model components:\n\n| Component | Weight (key available) | Weight (key disabled) |\n|-----------|------------------------|----------------------|\n| Surface dissonance | 40% | 60% |\n| Hierarchical tension | 25% | — |\n| Key distance | 20% | — |\n| Voice leading | 15% | 40% |\n\nOutput: Combined tension value (0-1) plus dominant contributing factor.\n\nWhen key is disabled, tension is computed from key-agnostic components only.\n\n### 3. Function Analysis (when key is available)\n- Identify I, ii, IV, V, vi, etc. relative to key\n- Detect secondary dominants (V/V, etc.)\n- Track cadential patterns (V-I, IV-I, deceptive)\n\nWhen key is disabled, function field is omitted (not set to null with uncertainty).\n\n## Output\n\nExtends MusicalFrame with:\n```typescript\ninterface ProgressionContext {\n  recentChords: ChordId[];        // References to chords in frame\n  tension: number;                 // 0-1 combined tension\n  tensionComponents: {             // Components vary by mode\n    dissonance: number;\n    hierarchical?: number;         // Only when key available\n    keyDistance?: number;          // Only when key available\n    voiceLeading: number;\n  };\n  dominantFactor: \"dissonance\" | \"hierarchical\" | \"keyDistance\" | \"voiceLeading\";\n  \n  // Only present when key is available (detected or override)\n  function?: ChordFunction;\n  cadenceApproaching?: CadenceType;\n  \n  // Indicates operating mode\n  keyContext: \"available\" | \"uncertain\" | \"disabled\";\n}\n```\n\n## Parameters\n\n- `windowSize`: Number of chords to track (default: 8)\n- `windowMs`: Time window for progression (default: 10000ms)\n- `tensionDecay`: How quickly tension fades without new input\n\n## Acceptance Criteria\n\n- [ ] Track recent chord progression\n- [ ] Compute harmonic tension (combined value)\n- [ ] Expose tension components appropriate to mode\n- [ ] Function analysis when key is available\n- [ ] Key-agnostic fallback when key is disabled\n- [ ] Handle uncertain key with appropriate confidence\n- [ ] Include keyContext field indicating operating mode\n- [ ] Unit tests with standard progressions\n- [ ] Unit tests for key-disabled mode\n\n## Dependencies\n\n- ChordDetectionStabilizer (required, provides chords)\n- KeyDetectionStabilizer (optional, provides key context with source field)\n\n## See Also\n\n- synesthetica-xc0 (Harmonic Tension Grammar) - consumes this data\n- synesthetica-49n (KeyDetectionStabilizer) - provides key context with disable capability\n- docs/vocabulary/semantic-mappings-v1.md - tension mapping proposals\n\n---\n\n## Previous Description (preserved for reference)\n\nTrack chord progressions over time. Derived stabilizer (depends on ChordDetectionStabilizer). Maintains a window of recent chords and their timing. Enables grammars to visualize harmonic movement. See SPEC_008 for stabilizer DAG architecture.","status":"open","priority":3,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-19T15:16:05.106892Z","created_by":"Nic Young","updated_at":"2026-01-23T15:13:31.130806Z"}
{"id":"synesthetica-c79","title":"P0: Project structure and build setup","status":"closed","priority":1,"issue_type":"feature","owner":"nic@o1labs.org","created_at":"2026-01-14T12:13:31.177452Z","created_by":"Nic Young","updated_at":"2026-01-18T10:38:45.135903Z","closed_at":"2026-01-18T10:38:45.135903Z","close_reason":"Project structure established with npm workspaces, TypeScript, and vitest for testing","dependencies":[{"issue_id":"synesthetica-c79","depends_on_id":"synesthetica-589","type":"blocks","created_at":"2026-01-14T13:12:08.083641Z","created_by":"Nic Young"}]}
{"id":"synesthetica-c7t","title":"Golden tests: Grammar boundary (VisualIntentFrame → SceneFrame)","description":"## Purpose\n\nGolden tests for the grammar boundary: `VisualIntentFrame → SceneFrame`.\n\n**Deferred until grammar behavior stabilizes.** Grammar iteration is ongoing and we don't want to lock down exact output prematurely.\n\n## When to Implement\n\nAfter Phase 1 grammar exploration yields stable patterns:\n- Entity spawning behavior is understood\n- TTL-based lifecycle is implemented\n- At least 2-3 grammars with distinct characters exist\n\n## Test Scenarios (Draft)\n\n### 1. Entity spawning on intent appearance\n- Input: PaletteIntent with id=X appears\n- Expected: Entity spawned with correct color, position, TTL\n\n### 2. Entity lifecycle independent of intent\n- Input: PaletteIntent appears then disappears after 100ms\n- Expected: Entity persists for its TTL (e.g., 2000ms), not tied to intent presence\n\n### 3. Intent phase affects entity properties\n- Input: PaletteIntent in attack phase vs sustain phase\n- Expected: Different visual treatment (e.g., brighter during attack)\n\n### 4. Multiple intents spawn multiple entities\n- Input: Three PaletteIntents with different IDs\n- Expected: Three distinct entities\n\n### 5. Reinforcement on intent continuation (if grammar supports it)\n- Input: Same intent ID across multiple frames\n- Expected: Entity TTL reset or intensity boosted (grammar-dependent)\n\n## Why Deferred\n\nGrammars own entity lifecycle. We're still exploring what visual behaviors feel right. Locking down fixtures now would constrain creative exploration.\n\n## Location\n\n`packages/engine/test/golden/grammar/`\n\n## Depends On\n\n- synesthetica-h06 (Test harness infrastructure)\n- synesthetica-fom (TTL-based grammar lifecycle)\n- Phase 1 grammar exploration","status":"closed","priority":3,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-19T11:05:14.98597Z","created_by":"Nic Young","updated_at":"2026-01-20T11:00:46.793278Z","closed_at":"2026-01-20T11:00:46.793278Z","close_reason":"Added golden tests for grammar boundaries - TestRhythmGrammar and TestChordProgressionGrammar. Tests validate entity types, counts, filtering behavior, and palette respect.","dependencies":[{"issue_id":"synesthetica-c7t","depends_on_id":"synesthetica-h06","type":"blocks","created_at":"2026-01-19T11:05:48.617571Z","created_by":"Nic Young"}]}
{"id":"synesthetica-c9t","title":"Implement renderChordShape() utility for grammars","description":"Implement a shared utility that renders ChordShapeGeometry to SVG/Canvas paths.\n\n## Function\n\n```ts\ninterface ChordShapeRenderOptions {\n  scale: number;\n  center: { x: number; y: number };\n  strokeWidth?: number;\n}\n\nfunction renderChordShape(\n  geometry: ChordShapeGeometry,\n  options: ChordShapeRenderOptions\n): {\n  fillPath: string;      // SVG path for filled shape\n  strokePath: string;    // SVG path for outline\n  linePaths?: string[];  // SVG paths for chromatic lines\n  elements: { path: string; color: ColorHSVA }[];  // Per-element paths with colors\n}\n```\n\n## Responsibilities\n\n- Generate hub arcs based on margin style (straight, wavy, concave, convex, dashed)\n- Generate arm paths from elements\n- Scale all coordinates to specified scale/center\n- Provide per-element paths so grammars can apply individual colors\n\n## Location\n\npackages/engine/src/vocabulary/renderChordShape.ts\n\n## Design Note\n\nThis utility is called BY grammars, not the vocabulary. The vocabulary computes geometry; grammars use this utility to render it. Grammars can also ignore this utility and implement their own rendering.\n\n## Depends on\n\n- synesthetica-rtr (ChordShapeElement with color)\n- buildChordShape (synesthetica-XXX)","status":"closed","priority":2,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-28T11:38:34.329933Z","created_by":"Nic Young","updated_at":"2026-01-28T12:07:12.142972Z","closed_at":"2026-01-28T12:07:12.142972Z","close_reason":"Implemented renderChordShape utility with SVG path generation and helpers","dependencies":[{"issue_id":"synesthetica-c9t","depends_on_id":"synesthetica-rtr","type":"blocks","created_at":"2026-01-28T11:38:39.408836Z","created_by":"Nic Young"},{"issue_id":"synesthetica-c9t","depends_on_id":"synesthetica-hyz","type":"blocks","created_at":"2026-01-28T11:38:39.514065Z","created_by":"Nic Young"}]}
{"id":"synesthetica-cfk","title":"Update Canvas2DRenderer for RhythmGrammar entity types","description":"Update the production Canvas2DRenderer to support entity types produced by RhythmGrammar.\n\n## Entity types to support\n\n1. **Horizontal lines spanning full width** (beat-line, bar-line, now-line)\n   - Currently renderer may assume vertical or point-based entities\n   - Need to render horizontal lines at y position, spanning canvas width\n   - Different visual weight for beat vs bar vs now lines\n\n2. **Trail entities with direction** (streak lines)\n   - Grammar encodes direction in velocity field\n   - Streaks should be rendered as tapered lines pointing in velocity direction\n   - Cartoony/gestural style (slight variation, not rigid)\n\n3. **Reference lines through notes** (-o- style)\n   - Faint horizontal line segment centered on note position\n   - Indicates \"tight\" timing (note close to beat)\n\n4. **Guitar-hero style vertical layout**\n   - Time flows bottom-to-top\n   - NOW line at y=0.85 (15% from bottom)\n   - Notes scroll upward as they age\n\n## Current state\n\nThe SVG snapshot renderer shows the grammar output correctly for development purposes.\nCanvas2DRenderer needs to be updated to match for production use.\n\n## Approach\n\n1. Review current Canvas2DRenderer implementation\n2. Identify gaps for each entity type\n3. Add rendering logic for new types\n4. Test with RhythmGrammar in the app\n\n## Depends on\n\nValidation of RhythmGrammar output via SVG snapshots (in progress).","status":"open","priority":2,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-21T17:54:53.887878Z","created_by":"Nic Young","updated_at":"2026-01-21T17:54:53.887878Z"}
{"id":"synesthetica-d41","title":"P0: Identity compositor","description":"Single-part compositor that passes through the scene unchanged.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-17T12:33:44.661556Z","created_by":"Nic Young","updated_at":"2026-01-18T10:50:21.994075Z","closed_at":"2026-01-18T10:50:21.994075Z","close_reason":"Implemented as IdentityCompositor in packages/engine/src/stubs","dependencies":[{"issue_id":"synesthetica-d41","depends_on_id":"synesthetica-c79","type":"blocks","created_at":"2026-01-17T12:36:59.914887Z","created_by":"Nic Young"}]}
{"id":"synesthetica-d53","title":"Document grammar contribution guide (open/closed pattern)","description":"Define how contributors (human or LLM) add new grammars to the system while adhering to the open/closed principle.\n\n## Goals\n- Grammars are open for extension (new grammars can be added)\n- Core system is closed for modification (adding a grammar doesn't change pipeline code)\n- Clear contract that guides LLM-driven grammar development\n\n## Should cover\n1. **Grammar contract**: What IGrammar implementations must provide\n2. **Annotation requirements**: Required GrammarAnnotation fields for LLM discoverability\n3. **Registration pattern**: How grammars are discovered/registered without modifying core\n4. **Testing requirements**: What tests a grammar must pass before inclusion\n5. **File/folder conventions**: Where grammar code and annotations live\n6. **Example template**: A minimal grammar that serves as a starting point\n\n## Constraints\n- Grammars MUST NOT compute musical semantics (I4)\n- Grammars MUST NOT read other parts (I7)\n- Grammars receive IntentFrame, emit SceneFrame\n- All entities must be tagged with the grammar's PartId\n\n## Evolution policy\nThis guide may be iterated as we learn. Any changes MUST be back-ported to all existing grammars to maintain consistency. The guide is a living document during Phase 1.\n\n## Output\nA SPEC or guide document that an LLM could follow to implement a new grammar from scratch.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-16T10:01:26.372543Z","created_by":"Nic Young","updated_at":"2026-01-17T12:56:01.758537Z"}
{"id":"synesthetica-dh7","title":"P0: Passthrough stabilizer","description":"Identity stabilizer that returns input unchanged. Placeholder for Phase 2.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-17T12:33:22.162305Z","created_by":"Nic Young","updated_at":"2026-01-18T10:50:21.788658Z","closed_at":"2026-01-18T10:50:21.788658Z","close_reason":"Implemented as PassthroughStabilizer in packages/engine/src/stubs","dependencies":[{"issue_id":"synesthetica-dh7","depends_on_id":"synesthetica-c79","type":"blocks","created_at":"2026-01-17T12:36:59.599242Z","created_by":"Nic Young"}]}
{"id":"synesthetica-dib","title":"Paper prototype: LLM annotation interpretation","description":"## Problem\n\nThe entire speech interface depends on an LLM correctly interpreting annotations and issuing control ops. This is novel and untested.\n\n## Action\n\nBefore Phase 2 (LLM integration), do a paper prototype:\n\n1. Write 20 realistic user utterances:\n   - \"use the starfield style\"\n   - \"emphasise rhythm\"\n   - \"make it linger more\"\n   - \"this is the guitar\" (while playing)\n   - \"save this as jazz practice\"\n   - etc.\n\n2. For each utterance, manually trace:\n   - What annotation lookups are needed?\n   - What control ops should result?\n   - What could go wrong?\n\n3. Evaluate:\n   - Are annotations sufficient for disambiguation?\n   - What's missing from GrammarAnnotation/MacroAnnotation?\n   - Where would the LLM need to guess?\n\n## Deliverable\n\n- Document with 20 utterance → control op mappings\n- List of annotation gaps discovered\n- Confidence assessment: \"LLM mediation is feasible\" or \"needs redesign\"\n\n## Why This Matters\n\nAn hour of paper prototyping could reveal that the annotation model is insufficient — before you build the LLM integration.\n\nSource: Session critique — \"LLM mediation model is high-risk and untested\"","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-17T13:17:08.607633Z","created_by":"Nic Young","updated_at":"2026-01-17T13:17:08.607633Z","dependencies":[{"issue_id":"synesthetica-dib","depends_on_id":"synesthetica-8f4","type":"blocks","created_at":"2026-01-19T10:35:38.658287Z","created_by":"Nic Young"}]}
{"id":"synesthetica-du1","title":"Grammar: Ambient Rhythm","description":"Ambient/background variant of RhythmGrammar.\n\nAtmospheric pulse visualization rather than precise timing feedback:\n- Lower contrast, more subtle\n- Flowing, organic movement\n- Suitable for background/screensaver mode\n\nSee also: synesthetica-o1v (production RhythmGrammar)","status":"open","priority":4,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-22T15:41:45.17547Z","created_by":"Nic Young","updated_at":"2026-01-22T15:41:45.17547Z"}
{"id":"synesthetica-dxb","title":"Rename Registration→Preset and Motif→Style throughout codebase","description":"Registration and Motif are obtuse jargon. Rename to clearer terms:\n\n- Motif → Style (built-in visual effect: stars, comets, rain)\n- Registration → Preset (user-selectable/saveable configuration bundling styles + settings)\n\nUpdate:\n- All contracts in packages/contracts/\n- All RFCs\n- PRD\n- Glossaries\n- Any other docs","status":"closed","priority":1,"issue_type":"task","owner":"nic@o1labs.org","created_at":"2026-01-14T13:38:36.298633Z","created_by":"Nic Young","updated_at":"2026-01-14T13:57:34.343024Z","closed_at":"2026-01-14T13:57:34.343024Z","close_reason":"Renamed Registration→Preset and Motif→Style throughout: contracts, RFCs, PRD, glossaries, and related beads issues."}
{"id":"synesthetica-e2q","title":"Control op: Override key (disable key detection)","description":"## Context\n\nSimilar to BPM override, users may want to specify a key rather than have the system infer it. Useful for:\n- Practice in a specific key\n- When playing atonal or chromatic music\n- When the detection is wrong\n\n## User Intent\n\n- \"Set key to C major\" → Disable KeyDetectionStabilizer, supply fixed key\n- \"Clear key override\" → Re-enable KeyDetectionStabilizer\n\n## Control Op Design\n\n```ts\n// Set fixed key\n{ op: \"setKey\", tonic: PitchClass, mode: \"major\" | \"minor\" }\n\n// Clear override, resume detection\n{ op: \"clearKey\" }\n```\n\n## Implementation\n\nSame pattern as BPM override:\n1. ControlOpProcessor receives op\n2. Disables KeyDetectionStabilizer output\n3. Injects fixed key into MusicalFrame\n4. On clear, re-enables stabilizer\n\n## Depends On\n\n- KeyDetectionStabilizer (must exist first)","status":"open","priority":3,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-20T11:34:55.154471Z","created_by":"Nic Young","updated_at":"2026-01-20T11:34:55.154471Z","dependencies":[{"issue_id":"synesthetica-e2q","depends_on_id":"synesthetica-0la","type":"blocks","created_at":"2026-01-20T11:35:20.213951Z","created_by":"Nic Young"}]}
{"id":"synesthetica-eh6","title":"Golden tests: Stabilizer boundary (RawInputFrame → MusicalFrame)","description":"## Purpose\n\nGolden tests for the stabilizer boundary: `RawInputFrame → MusicalFrame`.\n\nThis is the most constrained, best-understood part of the pipeline. Note tracking semantics are well-defined, and bugs here are hard to spot visually (did attack phase last 50ms or 60ms?).\n\n## Test Scenarios\n\n### 1. Single note lifecycle\n- Input: note_on at t=0, note_off at t=200ms\n- Expected: Note in attack phase at t=10ms, sustain at t=100ms, release at t=210ms, gone by t=710ms\n\n### 2. Attack → sustain transition timing\n- Input: note_on at t=0\n- Expected: Note in attack at t=0, transitions to sustain after attackDurationMs (default 50ms)\n\n### 3. Release window expiration\n- Input: note_on at t=0, note_off at t=100ms\n- Expected: Note still present (release phase) at t=500ms, removed by t=600ms (releaseWindowMs default 500ms)\n\n### 4. Overlapping notes\n- Input: C4 note_on at t=0, E4 note_on at t=50ms, C4 note_off at t=200ms, E4 note_off at t=250ms\n- Expected: Two Notes tracked independently with correct phases\n\n### 5. Rapid repeated notes\n- Input: C4 note_on at t=0, note_off at t=50ms, note_on at t=100ms, note_off at t=150ms\n- Expected: Two distinct Note IDs (different onset times)\n\n### 6. Edge case: note_off without prior note_on\n- Input: note_off for C4 with no matching note_on\n- Expected: Gracefully ignored, no crash\n\n### 7. Dynamics state\n- Input: Sequence with varying velocities\n- Expected: DynamicsState.level and .trend computed correctly\n\n## Fixture Format\n\n```ts\ninterface StabilizerGoldenFixture {\n  name: string;\n  description: string;\n  config: { attackDurationMs: number; releaseWindowMs: number };\n  frames: Array\u003c{\n    t: Ms;\n    rawInputs: RawInput[];\n    expected: {\n      notes: Array\u003c{ pitch: Pitch; phase: NotePhase; velocity: number }\u003e;\n      dynamics: DynamicsState;\n    };\n  }\u003e;\n}\n```\n\n## Location\n\n`packages/engine/test/golden/stabilizer/`\n\n## Depends On\n\n- synesthetica-h06 (Test harness infrastructure)","status":"closed","priority":1,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-19T11:02:42.776861Z","created_by":"Nic Young","updated_at":"2026-01-19T11:18:20.896879Z","closed_at":"2026-01-19T11:18:20.896879Z","close_reason":"Implemented all 7 test scenarios from the issue spec","dependencies":[{"issue_id":"synesthetica-eh6","depends_on_id":"synesthetica-h06","type":"blocks","created_at":"2026-01-19T11:03:34.60876Z","created_by":"Nic Young"}]}
{"id":"synesthetica-fom","title":"Update VisualParticleGrammar to TTL-based lifecycle","description":"## Context\n\nSPEC_009 clarifies that entity lifecycle is grammar's domain, not tied to intent presence. Current VisualParticleGrammar tracks intent IDs and fades entities when intents disappear. This couples entity lifetime to intent lifetime.\n\n## New Model\n\nGrammars should:\n1. Spawn entities with their own TTL when intents appear\n2. Optionally reinforce/update entities when intents continue\n3. NOT require intent presence to keep entity alive\n\n## Implementation\n\nUpdate `packages/engine/src/grammars/VisualParticleGrammar.ts`:\n\n1. When PaletteIntent appears:\n   - Spawn particle with configurable TTL (e.g., 2000ms)\n   - Entity manages its own lifecycle via ttlMs/ageMs\n\n2. When PaletteIntent continues:\n   - Option A: Reinforce (reset TTL, boost intensity)\n   - Option B: Spawn additional particle (trails effect)\n   - Option C: Ignore (fire-and-forget)\n\n3. When PaletteIntent disappears:\n   - Option A: Do nothing (entity fades on its own)\n   - Option B: Spawn release effect (trail, burst)\n\n4. Add configuration options:\n   ```ts\n   interface ParticleGrammarConfig {\n     particleTtlMs: Ms;           // Default: 2000\n     reinforceOnContinue: boolean; // Default: true\n     spawnOnRelease: boolean;      // Default: false\n   }\n   ```\n\n## Relates To\n\n- SPEC_009 (Entity Lifecycle is Grammar's Domain)\n- synesthetica-ray (Entity lifecycle resolution)\n- synesthetica-n6j (IntentPhase contract)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-19T10:43:05.741184Z","created_by":"Nic Young","updated_at":"2026-01-20T11:12:33.978208Z","closed_at":"2026-01-20T11:12:33.978208Z","close_reason":"Superseded - VisualParticleGrammar was never built. TestRhythmGrammar and TestChordProgressionGrammar now serve as reference implementations demonstrating correct entity lifecycle patterns per SPEC_009.","dependencies":[{"issue_id":"synesthetica-fom","depends_on_id":"synesthetica-n6j","type":"blocks","created_at":"2026-01-19T10:44:19.491662Z","created_by":"Nic Young"},{"issue_id":"synesthetica-fom","depends_on_id":"synesthetica-ray","type":"blocks","created_at":"2026-01-19T10:44:19.687448Z","created_by":"Nic Young"}]}
{"id":"synesthetica-gyj","title":"Define LLM-mediation threshold criteria","description":"## Purpose\n\nDefine the minimum pipeline sophistication required before LLM-mediation adds value.\n\n## Proposed Threshold\n\nLLM-mediation development begins when ALL of these are met:\n\n### 1. Multiple stabilizers producing different musical elements\n- NoteTrackingStabilizer (notes with phase) ✓ exists\n- At least one of: ChordDetectionStabilizer, BeatDetectionStabilizer, DynamicsStabilizer\n\n### 2. Multiple grammar options\n- VisualParticleGrammar ✓ exists  \n- At least one other (trails, fields, glyphs)\n\n### 3. Configurable ruleset parameters\n- Pitch-hue mapping parameters (reference PC, direction)\n- Phase-stability curve parameters\n- Dynamics-motion mapping parameters\n\n### 4. Basic preset system\n- Named configurations that can be saved/loaded\n- Presets capture: stabilizer config, ruleset params, grammar selection\n\n### 5. Audio adapter functional\n- Audio → RawInputFrame working\n- Confidence/uncertainty propagating through pipeline\n- See synesthetica-8f4\n\n## Why This Matters\n\nLLM-mediation controls parameters and selects components. Without meaningful parameters to adjust and components to select, the LLM has nothing to mediate.\n\n## Relates To\n\n- synesthetica-8f4 (Audio adapter gates LLM-mediation)\n- synesthetica-jes (Phase 2: Full System epic)\n- SPEC_004 (LLM mediation and annotations)","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-19T10:28:01.450774Z","created_by":"Nic Young","updated_at":"2026-01-19T10:28:01.450774Z","dependencies":[{"issue_id":"synesthetica-gyj","depends_on_id":"synesthetica-8f4","type":"blocks","created_at":"2026-01-19T10:35:26.448755Z","created_by":"Nic Young"}]}
{"id":"synesthetica-h06","title":"Golden test infrastructure: Test harness and fixture utilities","description":"## Purpose\n\nCreate the shared infrastructure for golden tests across all boundaries.\n\n## Deliverables\n\n### Directory Structure\n```\npackages/engine/test/golden/\n├── fixtures/           # JSON fixture files\n├── harness.ts          # Test harness utilities\n├── stabilizer/         # Stabilizer boundary tests\n├── ruleset/            # Ruleset invariant tests\n└── README.md           # Golden test guide\n```\n\n### Test Harness (`harness.ts`)\n- `loadFixture\u003cT\u003e(path: string): T` — Load and parse JSON fixture\n- `compareFrames(actual, expected, options?)` — Deep comparison with tolerance for floats\n- `updateFixture(path, actual)` — CLI helper to update fixtures when changes are intentional\n- Clear failure messages showing which field differs\n\n### Fixture Format\n```ts\ninterface GoldenFixture\u003cInput, Output\u003e {\n  name: string;\n  description: string;\n  input: Input;\n  expected: Output;\n}\n```\n\n### README.md\n- When to use golden tests vs unit tests\n- How to add new fixtures\n- How to update fixtures when changes are intentional\n- How to run golden tests separately\n\n## Why Separate Directory\n\nGolden tests serve a different purpose (regression vs behavior verification). Separation:\n- Makes fixture management clearer\n- Allows different vitest config if needed (longer timeouts, etc.)\n- Signals that fixture updates are deliberate decisions\n\n## Relates To\n\n- Stabilizer boundary tests (separate issue)\n- Ruleset invariant tests (separate issue)","status":"closed","priority":1,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-19T11:01:54.216992Z","created_by":"Nic Young","updated_at":"2026-01-19T11:11:41.456432Z","closed_at":"2026-01-19T11:11:41.456432Z","close_reason":"Implemented golden test harness with fixture loading, frame comparison, and UPDATE_GOLDEN support. Created example stabilizer golden test."}
{"id":"synesthetica-h09","title":"Ensemble mode: cross-part musical interpretation","description":"## Context\n\nDuring frame timing design (SPEC_005), we identified a tension between:\n- **Per-part interpretation** (current design): Each part gets independent musical interpretation. Essential for ear training where you need to compare reference vs. attempt.\n- **Ensemble interpretation** (deferred): Multiple sources contribute to a single unified musical interpretation (e.g., Part 1's C-E-G + Part 2's E-G-B = Cmaj7).\n\n## Why Deferred\n\nPer-part is correct for v0's ear training focus. Ensemble mode would:\n- Require a fusion step upstream of CMS generation\n- Lose per-part attribution at the CMS level\n- Violate the current I3 invariant if done at the wrong layer\n\n## Architectural Insight\n\nIf implemented, ensemble mode would need:\n1. Adapters emit an intermediate \"raw musical evidence\" format\n2. A fusion step merges evidence from multiple sources\n3. CMS is generated from the fused evidence\n4. A synthetic PartId (e.g., \"ensemble\") for the fused stream\n\nThis is a fundamentally different mode of operation, not something achievable by merging at the compositor level (which can only blend visuals, not re-interpret musical meaning).\n\n## When to Revisit\n\n- When supporting live ensemble performance visualization\n- When users want unified harmonic analysis across multiple players\n- Not needed for single-player ear training scenarios","status":"open","priority":4,"issue_type":"feature","owner":"nic@o1labs.org","created_at":"2026-01-15T12:32:49.371723Z","created_by":"Nic Young","updated_at":"2026-01-15T12:32:49.371723Z"}
{"id":"synesthetica-hyz","title":"Implement buildChordShape() in vocabulary","description":"Implement the function that builds ChordShapeGeometry from MusicalChord.\n\n## Function\n\n```ts\nfunction buildChordShape(\n  chord: MusicalChord,\n  inv: PitchHueInvariant\n): ChordShapeGeometry\n```\n\n## Responsibilities\n\n- Convert chord intervals to angular positions (30° per semitone, root at 0°)\n- Assign radius tiers (triadic=1.0, seventh=0.618, extension=0.382)\n- Determine margin style from chord quality (major=straight, minor=wavy, etc.)\n- Compute color for each element from pitch class\n- Identify chromatic alterations vs diatonic tones (wedge vs line)\n\n## Location\n\npackages/engine/src/vocabulary/chordShape.ts\n\n## Depends on\n\n- synesthetica-rtr (ChordShapeElement color field)\n\n## Enables\n\n- synesthetica-39e (MusicalVisualVocabulary)","status":"closed","priority":2,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-28T11:38:23.398814Z","created_by":"Nic Young","updated_at":"2026-01-28T12:07:07.892249Z","closed_at":"2026-01-28T12:07:07.892249Z","close_reason":"Extracted buildChordShape to vocabularies/utils.ts with per-element color computation","dependencies":[{"issue_id":"synesthetica-hyz","depends_on_id":"synesthetica-rtr","type":"blocks","created_at":"2026-01-28T11:38:39.297716Z","created_by":"Nic Young"}]}
{"id":"synesthetica-i60","title":"Golden tests: Ruleset invariants (pitch→hue, velocity→brightness)","description":"## Purpose\n\nProperty tests (not full-frame golden tests) for ruleset invariants.\n\nThese verify that instrument invariants hold, not exact output. The ruleset interface is still evolving, so we test properties rather than locking down exact VisualIntentFrame structure.\n\n## Invariant Tests\n\n### 1. Pitch class → hue mapping\n- Property: pitch class C always maps to hue in expected range (per pcToHue formula)\n- Test all 12 pitch classes map to distinct hue ranges\n- Verify A=0° reference point and direction (clockwise/counterclockwise per config)\n\n### 2. Velocity → brightness mapping\n- Property: higher velocity → higher brightness\n- Test velocity 127 produces higher brightness than velocity 32\n- Verify 0-1 output range\n\n### 3. Note phase → stability mapping\n- Property: attack phase → lower stability, sustain → higher stability, release → decreasing stability\n- Verify the relationship holds across different note inputs\n\n### 4. Octave affects value (not hue)\n- Property: C4 and C5 have same hue, different visual treatment (brightness or size)\n- Verify octave equivalence for hue\n\n### 5. Intent IDs are deterministic\n- Property: Same NoteId input produces same VisualIntentId\n- Verify intent IDs can be correlated across frames\n\n## Why Property Tests, Not Full Golden Tests\n\nThe exact structure of VisualIntentFrame may evolve. We care that:\n- Invariants hold\n- Mappings are consistent\n- Regressions don't break core semantics\n\nWe don't want to lock down exact field values prematurely.\n\n## Location\n\n`packages/engine/test/golden/ruleset/`\n\n## Depends On\n\n- synesthetica-h06 (Test harness infrastructure)","status":"closed","priority":2,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-19T11:03:19.776811Z","created_by":"Nic Young","updated_at":"2026-01-19T11:24:40.787264Z","closed_at":"2026-01-19T11:24:40.787264Z","close_reason":"Implemented all 5 invariant test categories from the issue spec","dependencies":[{"issue_id":"synesthetica-i60","depends_on_id":"synesthetica-h06","type":"blocks","created_at":"2026-01-19T11:03:34.725112Z","created_by":"Nic Young"}]}
{"id":"synesthetica-ise","title":"P0: MIDI adapter (note_on/off only)","description":"Minimal MIDI adapter that produces CMSFrame from note_on/off events.\n\n- Single channel only\n- No CC/sustain pedal handling\n- Produces NoteOn/NoteOff events with pitch, velocity, timestamp\n- Web MIDI API","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-17T12:33:18.62793Z","created_by":"Nic Young","updated_at":"2026-01-18T10:38:49.385176Z","closed_at":"2026-01-18T10:38:49.385176Z","close_reason":"Implemented with DI pattern, 19 unit tests passing","dependencies":[{"issue_id":"synesthetica-ise","depends_on_id":"synesthetica-c79","type":"blocks","created_at":"2026-01-17T12:36:59.509687Z","created_by":"Nic Young"}]}
{"id":"synesthetica-j5y","title":"[EPIC] Phase 0: Playable Sketch","description":"Minimal vertical slice to prove the architecture and provide a test harness for ruleset/grammar iteration.\n\n## Goal\nMIDI in → visuals out. Ugly but playable. This becomes the scaffold for Phase 1 exploration.\n\n## Exit Criteria\n- Can connect a MIDI keyboard and see colored particles\n- Pipeline interfaces are exercised end-to-end\n- Foundation for golden tests exists\n\n## What's NOT in scope\n- Audio input, multiple parts, real stabilizers, LLM integration, polish","status":"closed","priority":1,"issue_type":"feature","created_at":"2026-01-17T12:33:00.812963Z","created_by":"Nic Young","updated_at":"2026-01-18T12:21:32.611731Z","closed_at":"2026-01-18T12:21:32.611731Z","close_reason":"Closed","dependencies":[{"issue_id":"synesthetica-j5y","depends_on_id":"synesthetica-0jg","type":"blocks","created_at":"2026-01-17T12:36:12.24072Z","created_by":"Nic Young"}]}
{"id":"synesthetica-jes","title":"[EPIC] Phase 2: Full System","description":"Expand to full system capabilities once core semantics are proven.\n\n## Scope\n- Audio adapter (MIR pipeline)\n- Real stabilizers (tension, beat phase, etc.)\n- Multiple parts and routing\n- WebGL renderer\n- LLM integration\n- Additional grammars\n\n## Depends on\n- Phase 1 complete (confident in ruleset/grammar patterns)","status":"open","priority":3,"issue_type":"feature","created_at":"2026-01-17T12:33:13.251307Z","created_by":"Nic Young","updated_at":"2026-01-17T12:33:13.251307Z","dependencies":[{"issue_id":"synesthetica-jes","depends_on_id":"synesthetica-zd8","type":"blocks","created_at":"2026-01-17T12:36:30.028501Z","created_by":"Nic Young"},{"issue_id":"synesthetica-jes","depends_on_id":"synesthetica-8f4","type":"blocks","created_at":"2026-01-19T10:35:38.466835Z","created_by":"Nic Young"}]}
{"id":"synesthetica-jxy","title":"Define error and diagnostic model","description":"No error handling contract exists. What happens when:\n- An adapter fails to parse input?\n- A motif throws during update?\n- The LLM produces an invalid ControlOp?\n- A registration references a non-existent motif?\n\nOutput: Add Diagnostic, PipelineError, and ValidationResult types to packages/contracts. Define error propagation semantics (fail-fast vs graceful degradation per component).","status":"closed","priority":2,"issue_type":"feature","owner":"nic@o1labs.org","created_at":"2026-01-14T13:11:23.170264Z","created_by":"Nic Young","updated_at":"2026-01-15T15:03:14.283488Z","closed_at":"2026-01-15T15:03:14.283488Z","close_reason":"Resolved in SPEC_007. Added Diagnostic, ValidationError, ControlOpResult types. Graceful degradation for runtime issues, fail-fast for config/invariant violations. Visual indicator recommended for renderers. All diagnostics logged."}
{"id":"synesthetica-jz4","title":"P1: Ruleset iteration (find what works)","description":"## Purpose\n\nExploratory work on rulesets. This is creative, not mechanical.\n\n## Focus Areas\n\n- Experiment with MusicalFrame → VisualIntentFrame mappings\n- Try different approaches to chord representation via intents\n- Explore dynamics/loudness handling via MotionIntents\n- Leverage intent phase (attack/sustain/release) for visual expression\n- Document what feels right\n- Build golden tests as we go\n\n## Key Contracts\n\nRulesets are pure functions (SPEC_006):\n- Input: MusicalFrame (notes, chords, progression, phrases, beat, dynamics)\n- Output: VisualIntentFrame (palette, motion, texture, shape intents)\n- No internal state\n\nIntents have phase (SPEC_009):\n- attack/sustain/release envelope\n- Grammars interpret phase but manage entity lifecycle independently\n\n## Exit Criteria\n\n- At least one ruleset that feels musically meaningful\n- Confidence in the VisualIntentFrame interface\n- Golden tests covering core mappings\n\nThis task stays open during exploration. Close when we have confidence.","status":"in_progress","priority":2,"issue_type":"task","created_at":"2026-01-17T12:33:57.905382Z","created_by":"Nic Young","updated_at":"2026-01-19T11:36:40.734418Z","dependencies":[{"issue_id":"synesthetica-jz4","depends_on_id":"synesthetica-901","type":"blocks","created_at":"2026-01-17T12:36:22.610289Z","created_by":"Nic Young"},{"issue_id":"synesthetica-jz4","depends_on_id":"synesthetica-j5y","type":"blocks","created_at":"2026-01-17T12:40:35.537766Z","created_by":"Nic Young"}]}
{"id":"synesthetica-khj","title":"SPEC: Entity position and canvas coordinate system","description":"## The Gap\n\nEntity.position is Vec2, GrammarContext has canvasSize, but the coordinate system is never defined.\n\n## Why It Matters\n\n- Grammars spawn entities with positions — what's the reference frame?\n- Layout transforms apply to positions — what order? What semantics?\n- Different renderers (Canvas2D, WebGL) have different conventions\n- Multi-part rendering coordination requires shared coordinate semantics\n\n## Current State\n\n- Entity.position?: Vec2 (x, y numbers, no units specified)\n- GrammarContext.canvasSize: { width, height } — pixels? normalized?\n- LayoutPolicy.region: left/right/top/bottom/center/full — transform behavior undefined\n- No origin convention (top-left? center? bottom-left?)\n\n## Questions to Answer\n\n1. What coordinate system do grammars emit positions in? (0–1 normalized? pixels?)\n2. Where is the origin? (canvas top-left? center? part-local?)\n3. How do layout policies transform grammar-generated positions?\n4. How does scaling work for responsive canvas resize?\n\n## Relates To\n\n- RFC_002 (grammar context)\n- RFC_003 (layout policies)\n- SPEC_008 (compositor)\n\n## Output\n\nAdditions to RFC_002 and RFC_003 defining coordinate conventions and transform order.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-17T13:03:29.080479Z","created_by":"Nic Young","updated_at":"2026-01-17T13:03:29.080479Z"}
{"id":"synesthetica-lfv","title":"Add triplet subdivision support","description":"Add triplet subdivision as an option alongside quarter/eighth/sixteenth.\n\nThis affects:\n- SubdivisionDrift calculation in stabilizers\n- RhythmGrammar subdivision depth macro (add triplet as a notched value)\n- Any grid line rendering that shows subdivisions\n- OnsetDrift data structure (already has label field, may need triplet-specific handling)\n\nDiscovered during RhythmGrammar design - triplets are a common musical subdivision but weren't included in the initial 4-value macro design.\n\nDepends on:\n- synesthetica-o1v: RhythmGrammar implementation","status":"open","priority":4,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-21T17:34:45.438174Z","created_by":"Nic Young","updated_at":"2026-01-21T17:34:45.438174Z","dependencies":[{"issue_id":"synesthetica-lfv","depends_on_id":"synesthetica-o1v","type":"blocks","created_at":"2026-01-21T17:34:51.883712Z","created_by":"Nic Young"}]}
{"id":"synesthetica-n2o","title":"P1: Grammar iteration (build vocabulary)","description":"Exploratory work on grammars. Build a vocabulary of visual treatments.\n\nTarget: at least 3 distinct grammars with different characters:\n- Something discrete/transient (particles, stars)\n- Something continuous/flowing (trails, fields)\n- Something structural (chords, harmony visualization)\n\nDocument macro responses as we learn them.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-17T12:34:02.821893Z","created_by":"Nic Young","updated_at":"2026-01-17T12:34:02.821893Z","dependencies":[{"issue_id":"synesthetica-n2o","depends_on_id":"synesthetica-901","type":"blocks","created_at":"2026-01-17T12:36:22.715414Z","created_by":"Nic Young"},{"issue_id":"synesthetica-n2o","depends_on_id":"synesthetica-d53","type":"blocks","created_at":"2026-01-17T12:36:40.496889Z","created_by":"Nic Young"},{"issue_id":"synesthetica-n2o","depends_on_id":"synesthetica-j5y","type":"blocks","created_at":"2026-01-17T12:40:35.652492Z","created_by":"Nic Young"},{"issue_id":"synesthetica-n2o","depends_on_id":"synesthetica-n63","type":"blocks","created_at":"2026-01-17T12:56:50.966489Z","created_by":"Nic Young"}]}
{"id":"synesthetica-n63","title":"SPEC: Grammar composition and conflict resolution","description":"## The Problem\n\nMultiple active grammars may respond to the same intents differently. How do we combine their outputs?\n\nCurrent implicit model: grammars are additive (each emits entities, compositor merges).\n\n### Data flow context\n```\nCMS → Ruleset → IntentFrame → Grammar(s) → SceneFrame → Renderer\n```\n\n- Ruleset interprets CMS into musical intents (PaletteIntent, MotionIntent, TextureIntent, ShapeIntent)\n- Each intent carries confidence\n- Multiple grammars receive the SAME IntentFrame\n- Each grammar emits entities to a SceneFrame\n- Compositor merges SceneFrames (concat + layout + blending)\n\n### Where this breaks down\n\n1. **Conflicting motion**: Grammar A interprets MotionIntent.flow as \"drift left\", Grammar B as \"drift right\"\n2. **Macro confusion**: User says \"emphasise rhythm\" — macroResponses guide which grammars to adjust, but they may respond in incompatible ways\n3. **Visual chaos**: Two \"reactive\" grammars both responding to onsets = doubled visual noise\n4. **Coherence**: User expects a unified visual response, not independent layers doing their own thing\n\n### Concrete example\n\nActive grammars: Starfield (discrete, transient) + Rain (continuous, persistent)\n\nUser plays a chord. Both grammars receive the same IntentFrame:\n- Starfield spawns burst of particles\n- Rain increases field density\n\nIs this composition? Or conflict? Depends on the grammars' traits and whether they're designed to complement.\n\n## Questions to answer\n\n1. **Are grammars truly independent?**\n   - Do they share any state or negotiate?\n   - Can one grammar suppress or modify another?\n   - Should grammars be aware of what other grammars are active?\n\n2. **What is the composition model?**\n   - Pure entity concatenation (current)?\n   - Priority/layering with masking?\n   - Domain-based routing (grammar A handles motion, B handles texture)?\n   - Grammars declare \"slots\" they fill?\n\n3. **How do macros interact with multiple grammars?**\n   - Each grammar interprets macros independently via paramsSchema?\n   - macroResponses annotations guide which grammars to adjust?\n   - Some macros are \"global\" vs \"per-grammar\"?\n   - LLM uses macroResponses to make coherent choices?\n\n4. **What happens on conflict?**\n   - Both emit (visual chaos)?\n   - One wins (priority)?\n   - They blend (how?)?\n   - It's a design error (grammars shouldn't conflict)?\n\n5. **Role of presets**\n   - Do presets guarantee coherent grammar combinations?\n   - Is \"these grammars work together\" part of preset design?\n   - Should presets declare grammar relationships?\n\n## Relevant contracts\n\n- `IGrammar.update(input: IntentFrame, previous: SceneFrame | null): SceneFrame`\n- `ICompositor.compose(frames: SceneFrame[]): SceneFrame`\n- `GrammarAnnotation.traits` — could indicate compatibility\n- `GrammarAnnotation.macroResponses` — how grammar responds to macros\n- `Preset.grammars` — list of grammars with enabled/params/priority\n\n## Approaches to evaluate\n\n### 1. Additive (status quo)\n- Document when it works and when it doesn't\n- Rely on preset curation to avoid conflicts\n- Traits annotations help LLM avoid bad combinations\n- Simple, but pushes complexity to users/LLM\n\n### 2. Priority-based layering\n- Grammars have explicit priority in preset\n- Higher-priority grammar's entities render on top\n- Doesn't solve semantic conflict, only visual layering\n\n### 3. Domain declarations\n- Grammar declares which intent channels it consumes\n- `consumes: [\"motion\", \"palette\"]` vs `consumes: [\"texture\"]`\n- Compositor routes accordingly\n- Conflict = build-time warning\n- Limits expressiveness\n\n### 4. Slot-based composition\n- Define visual \"slots\" (background field, mid particles, foreground glyphs)\n- Each grammar fills specific slots\n- Compositor arranges slots\n- More structured, less flexible\n\n### 5. Pre-grammar intent arbitration\n- Intents are merged/arbitrated before reaching grammars\n- Single \"negotiated\" IntentFrame per part\n- Grammars see consistent signals\n- Loses per-grammar character\n\n## Phase 0 avoidance\n\nPhase 0 uses a single grammar, so this is not blocking. But Phase 1 grammar iteration will hit this immediately when combining grammars.\n\n## Output\n\nEither a SPEC or additions to SPEC_004/SPEC_008 clarifying:\n1. Grammar composition semantics\n2. Conflict detection/resolution strategy\n3. How presets encode grammar compatibility\n4. How macroResponses guide multi-grammar adjustment","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-17T12:56:39.738075Z","created_by":"Nic Young","updated_at":"2026-01-17T12:58:26.959429Z"}
{"id":"synesthetica-n6j","title":"Add IntentPhase to PaletteIntent contract","description":"## Context\n\nSPEC_009 now specifies that intents have their own lifecycle phase (attack/sustain/release), but the contract types don't reflect this yet.\n\n## Implementation\n\nUpdate `packages/contracts/intents/intents.ts`:\n\n```ts\nexport type IntentPhase = \"attack\" | \"sustain\" | \"release\";\n\nexport interface PaletteIntent {\n  type: \"palette\";\n  id: VisualIntentId;\n  t: Ms;\n  base: ColorHSVA;\n  stability: number;\n  phase: IntentPhase;  // ADD THIS\n  confidence: Confidence;\n}\n```\n\nAlso update MotionIntent, TextureIntent, ShapeIntent if they should have phase.\n\n## Downstream Changes\n\n- MusicalVisualRuleset: Set intent phase from note phase\n- VisualParticleGrammar: Can use phase to vary visual (optional)\n\n## Relates To\n\n- SPEC_009 (Intent Phase and Entity Lifecycle)\n- synesthetica-ray (Entity lifecycle resolution)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-19T10:42:43.293109Z","created_by":"Nic Young","updated_at":"2026-01-20T11:13:06.868288Z","closed_at":"2026-01-20T11:13:06.868288Z","close_reason":"Superseded by RFC 006 - AnnotatedMusicalFrame passes NotePhase directly through the musical primitives. Grammars access note.phase directly from AnnotatedNote, eliminating need for separate IntentPhase on visual intents.","dependencies":[{"issue_id":"synesthetica-n6j","depends_on_id":"synesthetica-ray","type":"blocks","created_at":"2026-01-19T10:44:19.883975Z","created_by":"Nic Young"}]}
{"id":"synesthetica-nob","title":"Implement PhraseDetectionStabilizer","description":"Detect phrase boundaries from note density, beat patterns, and harmonic cadences. Derived stabilizer (depends on NoteTrackingStabilizer and BeatDetectionStabilizer). Outputs phrase onset times and types. See SPEC_008 for stabilizer DAG architecture.","status":"open","priority":3,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-19T15:16:00.898909Z","created_by":"Nic Young","updated_at":"2026-01-19T15:16:17.511281Z"}
{"id":"synesthetica-nqx","title":"Define derived signals schema for stabilizers","description":"## The Gap\n\nSPEC_006 and SPEC_008 define the stabilizer DAG and MusicalFrame windowing, but the schema for derived signals is not fully specified.\n\n## What's Now Defined\n\nSPEC_006 now specifies MusicalFrame fields:\n- `notes: Note[]` — Active notes with phase\n- `chords: MusicalChord[]` — Detected chords\n- `progression: ChordId[]` — Recent chord history\n- `phrases: Phrase[]` — Phrase boundaries\n- `beat: BeatState` — Current beat position\n- `dynamics: DynamicsState` — Loudness level and trend\n\n## What's Still Missing\n\nHigher-level derived signals that rulesets might want:\n- `harmonicTension: number` — Computed from progression\n- `phrasePosition: number` — 0-1 position within current phrase\n- `rhythmicDensity: number` — Notes per beat\n- `registralSpread: number` — Range of active pitches\n\n## Questions\n\n1. Should these be part of MusicalFrame, or computed by rulesets?\n2. If part of MusicalFrame, which stabilizer owns each?\n3. Are these signals needed for Phase 1, or can we defer?\n\n## Relates To\n\n- SPEC_006 (MusicalFrame definition)\n- SPEC_008 (Stabilizer DAG, field ownership)\n- synesthetica-s0x (Stabilizer ordering - resolved)","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-16T09:39:03.04577Z","created_by":"Nic Young","updated_at":"2026-01-19T10:34:08.435785Z","dependencies":[{"issue_id":"synesthetica-nqx","depends_on_id":"synesthetica-s0x","type":"blocks","created_at":"2026-01-19T10:35:26.843642Z","created_by":"Nic Young"}]}
{"id":"synesthetica-nrx","title":"SPEC: Control operation validation error format","description":"## The Gap\n\nControlOpResult includes ValidationError with field/reason/hint, but the format and completeness of feedback are undefined.\n\n## Why It Matters\n\n- LLM relies on errors to diagnose and fix bad commands\n- Incomplete error context forces guessing or random retry\n- No examples or error message grammar is provided\n- Recovery quality depends on error quality\n\n## Current State\n\n- ValidationError: { field, reason, hint? }\n- ControlOpResult: { success, errors?, diagnostics? }\n- SPEC_007 defines the types but not content standards\n\n## Questions to Answer\n\n1. What's the format for field paths? (e.g., \"macros.emphasis.rhythm\")\n2. Should reason be machine-readable or prose?\n3. What constitutes a good hint for LLM recovery?\n4. Are there standard error codes or categories?\n\n## Relates To\n\n- SPEC_007 (validation errors)\n- RFC_004 (LLM mediation)\n\n## Output\n\nAdditions to SPEC_007 with examples and format guidelines for validation errors.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-17T13:04:06.145241Z","created_by":"Nic Young","updated_at":"2026-01-17T13:04:06.145241Z"}
{"id":"synesthetica-o1v","title":"Implement production RhythmGrammar","description":"Replace TestRhythmGrammar with a production-ready implementation.\n\n## Core Visual Elements\n\n1. **Beat grid**: Lines/markers showing beat positions based on tier\n2. **Onset markers**: Visual indication of note timing\n3. **Drift indicators**: `((` style markers showing early/late positioning\n   - Position encodes timing; no judgment of \"good\" or \"bad\" (Principle 4: Perceptual Honesty)\n\n## Macro Parameters\n\n### 1. Horizon (continuous)\nControls temporal persistence of visual elements.\n\n- **Ephemeral** (left): Markers fade quickly after onset. Focus on immediate moment.\n- **Persistent** (right): Markers scroll toward horizon (Guitar Hero style), fade with distance. Reveals patterns over time.\n\nThis is a continuous slider, not discrete modes.\n\n### 2. Subdivision Depth (notched, 4 values)\nControls which subdivision level to reference for drift calculation.\n\n- **Quarter**: Reference quarter notes only\n- **Eighth**: Reference up to eighth notes\n- **Triplet**: Include triplet subdivisions\n- **Sixteenth**: Include sixteenth notes (default)\n\nUses `nearest` flag from OnsetDrift data to find appropriate subdivision.\n\n## Tier-Dependent Behavior\n\nThe grammar adapts based on available rhythmic information:\n\n**Tier 1** (detected division only — no prescribed tempo):\n- Beat grid derived from detected IOI\n- Drift shown relative to detected pattern\n- Grid may shift as detection updates\n\n**Tier 2** (prescribed tempo):\n- Beat grid locked to BPM\n- Drift shown relative to stable grid\n- More reliable drift visualization\n\n**Tier 3** (prescribed meter):\n- Beat grid shows bars and downbeats\n- Bar lines stronger than beat lines\n- Downbeat can have special treatment (glow, size)\n\n## Annotations for Discoverability\n\nGrammar should emit annotations that help users understand:\n- Current tier and why (what data is available)\n- Which subdivision drift is being visualized\n- Macro parameter effects\n\n## Data Available\n\nFrom MusicalFrame.rhythmicAnalysis:\n- `detectedDivision: Ms | null` — detected IOI (Tier 1)\n- `onsetDrifts: OnsetDrift[]` — per-onset drift at 4 subdivision levels\n- `stability: number` — how consistent the division is\n- `confidence: number` — detection confidence\n\nFrom MusicalFrame:\n- `prescribedTempo: number | null` — user-set BPM (Tier 2)\n- `prescribedMeter: { beatsPerBar, beatUnit } | null` — user-set meter (Tier 3)\n\nOnsetDrift structure:\n```typescript\n{ t: Ms, subdivisions: SubdivisionDrift[] }\n// where SubdivisionDrift:\n{ label: string, period: Ms, drift: Ms, nearest: boolean }\n```\n\n## Design Approach\n\n1. Build with hardcoded visual choices first\n2. Use simulation tests (Principle 8) to identify what feels right\n3. Extract stable patterns to ruleset contracts later\n4. Ruleset provides palette for drift visualization; grammar provides visual form\n\n## Related Issues\n- synesthetica-5hb: Swing support (depends on this)\n- synesthetica-830: RubatoRhythmGrammar (depends on this)\n- AmbientRhythmGrammar issue TBD (depends on this)","status":"in_progress","priority":2,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-21T15:54:11.183881Z","created_by":"Nic Young","updated_at":"2026-01-21T16:17:16.066521Z","dependencies":[{"issue_id":"synesthetica-o1v","depends_on_id":"synesthetica-cfk","type":"blocks","created_at":"2026-01-21T17:55:00.016252Z","created_by":"Nic Young"}]}
{"id":"synesthetica-oc8","title":"Note strips: player piano roll visual style","description":"Explore representing note strips with a punched-hole visual style inspired by player piano rolls.\n\n## Inspiration\nPhysical player piano rolls use punched holes in paper to trigger notes. The visual effect is:\n- Solid paper at the note's start (onset)\n- Punched holes through the duration\n- Solid paper at the note's end\n\n## ASCII representation\n```\nII   \u003c- solid onset edge\n''   \u003c- punched holes (duration)  \n''\nII   \u003c- solid end edge\n```\n\n## Considerations\n- Could replace current solid rectangular note strips with this style\n- May need different rendering for short vs sustained notes\n- Consider how this interacts with velocity (width) and color\n- Punched hole density could encode information (subdivision, dynamics)\n\n## Related\nRequested as a visual enhancement to disambiguate note strips from beat/bar lines.","status":"open","priority":3,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-23T08:20:07.114424Z","created_by":"Nic Young","updated_at":"2026-01-23T08:20:07.114424Z"}
{"id":"synesthetica-omz","title":"SPEC: Macro persistence across preset changes","description":"## The Gap\n\nWhen switching presets, it's unclear whether macro values are preserved, reset, or interpolated.\n\n## Why It Matters\n\n- User expectations differ: \"keep my rhythm emphasis\" vs \"reset to preset defaults\"\n- Interaction model doesn't specify user intent for transitions\n- LLM has no guidance on whether to explicitly reset macros\n- Affects speech patterns like \"use jazz mode but keep the rhythm emphasis\"\n\n## Current State\n\n- Preset.macros defines default values\n- ControlOp.applyPreset applies a preset\n- ControlOp.setMacro patches macros independently\n- No spec defines transition semantics\n\n## Questions to Answer\n\n1. Does applyPreset reset all macros to preset defaults?\n2. Can users opt to preserve macro values across preset changes?\n3. Should macro transitions be interpolated (smooth) or instant?\n4. Is this configurable per-preset or global?\n\n## Relates To\n\n- RFC_001 (interaction model)\n- SPEC_004 (macros)\n- synesthetica-30r (macro interpolation)\n\n## Output\n\nAdditions to SPEC_004 or RFC_001 defining preset transition semantics for macros.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-17T13:03:57.125904Z","created_by":"Nic Young","updated_at":"2026-01-17T13:03:57.125904Z"}
{"id":"synesthetica-pt7","title":"Triage: Cull backlog before Phase 0","description":"## Problem\n\nIssue count is growing faster than closure rate (48 total, 38 open, 10 closed). A backlog that grows without bound becomes noise.\n\n## Action\n\nBefore starting Phase 0 implementation:\n\n1. Review all open issues\n2. Mark clearly out-of-scope items as wontfix or post-v1\n3. Merge duplicates\n4. Ensure remaining issues have clear scope and acceptance criteria\n5. Target: \u003c25 open issues for v0\n\n## Triage Categories\n\n- **P0-P1**: Must have for Phase 0/1\n- **P2**: Should have, likely needed\n- **P3**: Nice to have, defer if needed\n- **P4**: Backlog, explicitly post-v1\n- **wontfix**: Out of scope, close with reason\n\n## Why This Matters\n\nA shorter, curated list is more useful than a comprehensive one. Context decays — stale issues become misleading.\n\nSource: Session critique — \"issue count growing faster than closure rate\"","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-17T13:16:47.061892Z","created_by":"Nic Young","updated_at":"2026-01-17T13:16:47.061892Z"}
{"id":"synesthetica-qkx","title":"Implement diagnostic logging infrastructure","description":"## Context\n\nSPEC_007 requires that all diagnostics are logged regardless of visual indication. Need to implement the logging infrastructure.\n\n## Requirements\n\n- All Diagnostic emissions logged to console and/or file\n- Minimum log format: [timestamp] [category] [severity] message\n- Include source and partId when available\n- Support structured logging (JSON) for easier parsing\n- Consider log levels for filtering\n\n## Reference\n\nSee SPEC_007_error_and_diagnostic_model.md \"Logging Requirements\" section.\n\n## Acceptance\n\n- Diagnostics from all categories are logged\n- Log format is consistent and parseable\n- Log output is configurable (console, file, both)","status":"open","priority":3,"issue_type":"task","owner":"nic@o1labs.org","created_at":"2026-01-15T15:10:27.104855Z","created_by":"Nic Young","updated_at":"2026-01-15T15:10:27.104855Z"}
{"id":"synesthetica-qtx","title":"Update PRD to reflect RFC proposals","description":"The PRD is sparse and doesn't reflect the detailed requirements that have emerged from the RFCs.\n\nUpdate PRD to include:\n- Functional requirements from RFC 002 (CMS, intents, motifs, registrations)\n- Interaction model from RFC 001 (postures, commitment verbs, layers)\n- Multi-instrument support from RFC 003 (parts, routing, layout)\n- LLM mediation from RFC 004 (speech control, annotations)\n\nKeep it product-focused (what the system does for users), not implementation-focused (how it works internally).","status":"closed","priority":1,"issue_type":"task","owner":"nic@o1labs.org","created_at":"2026-01-14T13:26:10.228756Z","created_by":"Nic Young","updated_at":"2026-01-14T13:29:47.038819Z","closed_at":"2026-01-14T13:29:47.038819Z","close_reason":"PRD updated with functional requirements from all RFCs: input processing, visual output, parts/routing, registrations, interaction model, speech control, and user journeys."}
{"id":"synesthetica-r0y","title":"Define preset export/import JSON schema","description":"SPEC_001 mentions exportUser()/importUser(json) but no JSON schema is defined for the export format. Low priority for v0.","status":"open","priority":4,"issue_type":"task","created_at":"2026-01-16T09:39:03.643254Z","created_by":"Nic Young","updated_at":"2026-01-16T09:39:25.860302Z"}
{"id":"synesthetica-ray","title":"SPEC: Entity lifecycle and decay semantics","description":"## The Gap (RESOLVED)\n\nEntity has `life?: { ttlMs: Ms; ageMs: Ms }` but decay/removal semantics were unclear.\n\n## Resolution\n\nSPEC_009 now clarifies:\n\n**Entity lifecycle is grammar's domain.** Grammars decide how to respond to intents — they are not obligated to tie entity lifetime to intent lifetime.\n\nKey points:\n- Intent phase (attack/sustain/release) describes the intent's current state, not entity lifespan\n- Grammars may spawn entities that outlive their source intent\n- Grammars decide visual persistence based on their purpose\n- Intent disappearing does NOT require entity removal — grammar decides\n\n## Implementation Tasks\n\n1. Update IVisualGrammar interface documentation to clarify entity lifecycle ownership\n2. Update VisualParticleGrammar to use TTL-based lifecycle (not intent-tracking)\n3. Add entity TTL configuration to grammar options\n4. Update GLOSSARY_FULL.md grammar definition\n\n## Relates To\n\n- SPEC_009 (intent phase and entity lifecycle)\n- SPEC_008 (compositor responsibilities)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-17T13:03:09.914237Z","created_by":"Nic Young","updated_at":"2026-01-20T11:12:09.388891Z","closed_at":"2026-01-20T11:12:09.388891Z","close_reason":"Resolved - SPEC_009 clarifies entity lifecycle is grammar's domain. VisualParticleGrammar was never implemented; TestRhythmGrammar and TestChordProgressionGrammar now serve as reference implementations with correct lifecycle patterns."}
{"id":"synesthetica-rtr","title":"Extend ChordShapeElement with per-element color","description":"Add `color: ColorHSVA` to ChordShapeElement so vocabulary can provide per-element colors.\n\n## Problem\n\nCurrently ChordShapeElement has no color field. Grammars wanting to color each arm tip by its pitch have no way to get that information without violating the \"vocabulary defines meaning\" principle.\n\n## Solution\n\n```ts\ninterface ChordShapeElement {\n  angle: number;\n  radius: number;\n  tier: RadiusTier;\n  style: \"wedge\" | \"line\";\n  interval: string;\n  color: ColorHSVA;  // NEW\n}\n```\n\nVocabulary computes color using `pcToHue(root + intervalSemitones)`.\n\n## Files\n\n- packages/contracts/annotated/annotated.ts\n- specs/SPEC_010_visual_vocabulary.md\n\n## Depends on\n\nNothing - this is the first step.\n\n## Enables\n\n- synesthetica-39e (vocabulary harmonic mappings)\n- synesthetica-sn4 (HarmonyGrammar)","status":"closed","priority":2,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-28T11:37:56.405481Z","created_by":"Nic Young","updated_at":"2026-01-28T12:07:02.46279Z","closed_at":"2026-01-28T12:07:02.46279Z","close_reason":"Added color: ColorHSVA field to ChordShapeElement in contracts"}
{"id":"synesthetica-rxi","title":"AmbientRhythmGrammar","description":"Specialized grammar for ambient rhythm visualization, designed for layering with other grammars.\n\n## Purpose\n\nWhile RhythmGrammar focuses on individual note timing and drift visualization, AmbientRhythmGrammar creates atmospheric rhythm presence without onset markers. It's designed for:\n- Layering with chord or melody-focused grammars\n- Creating \"living\" scenes even during silence\n- Subtle rhythm awareness without explicit timing feedback\n\n## Core Visual Elements\n\n1. **Pulse/breath**: Subtle expansion/contraction of scene elements on beat\n   - Works even during silence when prescribed tempo is available\n   - Creates embodied sense of pulse\n   - Intensity can respond to dynamics\n\n2. **Beat anticipation**: Subtle visual cue approaching next beat\n   - Helps internalize pulse without explicit metronome\n   - Forward-looking rather than reactive\n\n3. **Grid density (information mode)**: Subdivision lines respond to playing style\n   - More lines visible when playing faster subdivisions\n   - Grid \"breathes\" with the performance\n   - No judgment, just information\n\n## Key Design Constraint\n\n**No onset markers**: Unlike RhythmGrammar, this grammar does NOT mark individual note onsets. This allows it to layer cleanly with other grammars that may already visualize notes.\n\n## Composition Behavior\n\nDesigned to work as a background layer:\n- Low z-index visual elements\n- Consistent across silence and playing\n- Enhances rather than competes with other grammar output\n\n## Data Requirements\n\n- Works best with prescribed tempo (Tier 2+)\n- Can work with detected tempo but may be unstable\n- May not need OnsetDrift data at all if purely ambient\n\n## Design Questions (deferred)\n\n- What data structure supports \"anticipation\" visualization?\n- How does ambient layer interact with compositor?\n- Should pulse intensity respond to dynamics or note density?\n\n## Depends On\n- synesthetica-o1v: RhythmGrammar (establishes rhythm visualization patterns)","status":"open","priority":4,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-21T16:17:09.428178Z","created_by":"Nic Young","updated_at":"2026-01-21T16:17:09.428178Z","dependencies":[{"issue_id":"synesthetica-rxi","depends_on_id":"synesthetica-o1v","type":"blocks","created_at":"2026-01-21T16:17:15.700336Z","created_by":"Nic Young"}]}
{"id":"synesthetica-s0x","title":"Define stabilizer ordering strategy","description":"## The Gap (RESOLVED)\n\nSPEC_006 deferred stabilizer ordering/composition. When multiple stabilizers run, their order matters.\n\n## Resolution\n\nSPEC_008 now defines Stabilizer DAG:\n\n**Stabilizers form a directed acyclic graph (DAG) based on dependencies.**\n\n### Independent Stabilizers (process RawInputFrame directly)\n- NoteTrackingStabilizer\n- BeatDetectionStabilizer  \n- DynamicsStabilizer\n\n### Derived Stabilizers (require upstream output)\n- ChordDetectionStabilizer (needs notes)\n- PhraseDetectionStabilizer (needs beats + density)\n- ProgressionStabilizer (needs chords over time)\n\n### Execution\n1. Topological sort based on declared dependencies\n2. Run stabilizers in dependency order\n3. Merge outputs into single MusicalFrame\n4. Ownership enforced: one stabilizer per field\n\n## Implementation Tasks\n\n1. Add `dependencies?: string[]` to IMusicalStabilizer interface\n2. Implement topological sort in VisualPipeline\n3. Implement merge logic with ownership enforcement\n4. Update stabilizer factory pattern for DAG support\n\n## Relates To\n\n- SPEC_008 (Stabilizer DAG section)\n- SPEC_006 (MusicalFrame windowing)","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-16T09:39:03.197398Z","created_by":"Nic Young","updated_at":"2026-01-19T10:35:53.143779Z","closed_at":"2026-01-19T10:35:53.143779Z","close_reason":"Closed"}
{"id":"synesthetica-s27","title":"Sustain pedal (CC64) support in stabilizers","description":"Add sustain pedal support to the stabilizer layer.\n\nWhen sustain pedal is held (CC64 \u003e= 64):\n- Notes continue to sound even after note_off\n- Visual representation should reflect sustained state\n- Release happens when pedal is lifted\n\nThis affects NoteTrackingStabilizer and potentially other stabilizers that track note lifecycle.\n\nRelated: RhythmGrammar already renders note bars with duration - sustain pedal would extend those bars.","status":"open","priority":2,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-22T15:40:24.381556Z","created_by":"Nic Young","updated_at":"2026-01-22T15:40:24.381556Z"}
{"id":"synesthetica-s97","title":"Grammar: Dynamics","description":"Visualize dynamic expression - volume, intensity, articulation.\n\nCould include:\n- Overall dynamic level (pp to ff)\n- Dynamic contour over time\n- Accent patterns\n- Crescendo/decrescendo visualization\n- Attack intensity\n\nWorks with existing DynamicsState from stabilizers.","status":"open","priority":3,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-22T15:41:07.822777Z","created_by":"Nic Young","updated_at":"2026-01-22T15:41:07.822777Z"}
{"id":"synesthetica-sn4","title":"Grammar: Basic Harmony (chord qualities)","description":"Visualize chord qualities - major, minor, diminished, augmented, extended chords.\n\n## Purpose\n\nRender the immediate harmonic state - what chord is sounding right now. This grammar focuses on the \"what\" of harmony (chord identity) rather than the \"where\" (tension/resolution).\n\n## Visual Representation\n\nGrammar receives AnnotatedChord from vocabulary with:\n- **Palette**: Colors derived from chord root (pitch-class → hue) and quality annotations\n- **Texture**: Quality-dependent texture (SUGGESTION: major=smooth, minor=textured)\n- **Motion**: Stability characteristics\n\n**Key constraint**: Grammar does NOT compute colors from chord quality. The vocabulary provides semantic annotations; grammar decides rendering form.\n\n### Possible Rendering Approaches (SUGGESTIONS)\n\n1. **Chord Glow**\n   - Central glow at chord root color\n   - Intensity from velocity/dynamics\n   - Shape variation from quality (round=major, angular=minor?)\n\n2. **Stacked Elements**\n   - Visual layers for chord tones\n   - Shows chord structure explicitly\n\n3. **Symbolic Notation**\n   - Chord symbol overlay (Cmaj7, Am, etc.)\n   - Minimalist approach\n\n4. **Extension Indicators**\n   - Additional visual elements for 7ths, 9ths, etc.\n   - Could be separate particles or modifications\n\n## Dependencies\n\n- ChordDetectionStabilizer (provides MusicalChord)\n- MusicalVisualVocabulary (provides AnnotatedChord with visual properties)\n- synesthetica-39e (vocabulary harmonic mappings) - provides quality annotations\n\n## Acceptance Criteria\n\n- [ ] Renders current chord(s)\n- [ ] Uses vocabulary-provided colors (NOT self-computed)\n- [ ] Shows chord quality through form (shape, texture, motion)\n- [ ] Handles simultaneous chords\n- [ ] Golden tests for rendering\n\n## See Also\n\n- synesthetica-xc0 (Harmonic Tension Grammar) - for progression context\n- synesthetica-39e (Vocabulary mappings) - provides annotations\n- synesthetica-al3 (Vocabulary spike) - decides annotation details\n- docs/vocabulary/semantic-mappings-v1.md - mapping proposals\n\n---\n\n## Previous Description (preserved for reference)\n\nVisualize chord qualities - major, minor, diminished, augmented, extended chords.\n\nFocus on the 'what' of harmony: what chord is being played right now.\n\nCould include:\n- Chord root highlighting\n- Quality indicators (major warm, minor cool, etc.)\n- Extension visualization (7ths, 9ths, etc.)\n\nSee also: Harmonic Tension grammar for progression context.","status":"open","priority":3,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-22T15:40:33.850591Z","created_by":"Nic Young","updated_at":"2026-01-23T15:09:27.201137Z","dependencies":[{"issue_id":"synesthetica-sn4","depends_on_id":"synesthetica-39e","type":"blocks","created_at":"2026-01-28T11:38:39.7272Z","created_by":"Nic Young"},{"issue_id":"synesthetica-sn4","depends_on_id":"synesthetica-c9t","type":"blocks","created_at":"2026-01-28T11:38:39.82345Z","created_by":"Nic Young"}]}
{"id":"synesthetica-tzc","title":"Specify try/keep/discard lifecycle and session state","description":"RFC 001 introduces commitment verbs (try, keep, discard, queue) but there's no contract surface for this.\n\nQuestions to resolve:\n- What is the representation of a 'trial' state?\n- Can you have nested trials?\n- How does 'discard' know what to revert to?\n- What is a Checkpoint?\n\nOutput: Add SessionState, Checkpoint, and Trial types to packages/contracts. Amend RFC 001 or create a new RFC section specifying the lifecycle semantics.","status":"closed","priority":2,"issue_type":"feature","owner":"nic@o1labs.org","created_at":"2026-01-14T13:11:22.578857Z","created_by":"Nic Young","updated_at":"2026-01-14T19:43:56.410254Z","closed_at":"2026-01-14T19:43:56.410254Z","close_reason":"Deferred to LLM. The engine provides preset CRUD (IPresetCatalog); try/keep/discard semantics are left to the user↔LLM conversation, not specified by the engine.","dependencies":[{"issue_id":"synesthetica-tzc","depends_on_id":"synesthetica-ysk","type":"blocks","created_at":"2026-01-14T13:12:07.892904Z","created_by":"Nic Young"}]}
{"id":"synesthetica-uky","title":"P0: Pipeline orchestrator","description":"Implement IPipeline.requestFrame() - the central coordinator.\n\n- Wire adapter → stabilizer → ruleset → grammar → compositor\n- Single part only (no routing yet)\n- Pull-based frame model per SPEC_005/SPEC_008","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-17T12:33:36.693546Z","created_by":"Nic Young","updated_at":"2026-01-18T10:50:35.121777Z","closed_at":"2026-01-18T10:50:35.121777Z","close_reason":"Pipeline orchestrator complete with 15 tests","dependencies":[{"issue_id":"synesthetica-uky","depends_on_id":"synesthetica-ise","type":"blocks","created_at":"2026-01-17T12:34:43.954334Z","created_by":"Nic Young"},{"issue_id":"synesthetica-uky","depends_on_id":"synesthetica-dh7","type":"blocks","created_at":"2026-01-17T12:34:44.071316Z","created_by":"Nic Young"},{"issue_id":"synesthetica-uky","depends_on_id":"synesthetica-ymc","type":"blocks","created_at":"2026-01-17T12:34:44.180879Z","created_by":"Nic Young"},{"issue_id":"synesthetica-uky","depends_on_id":"synesthetica-6lf","type":"blocks","created_at":"2026-01-17T12:34:44.302812Z","created_by":"Nic Young"},{"issue_id":"synesthetica-uky","depends_on_id":"synesthetica-d41","type":"blocks","created_at":"2026-01-17T12:34:44.406463Z","created_by":"Nic Young"}]}
{"id":"synesthetica-un4","title":"Grammar: Ambient Tension","description":"Ambient/background variant of Harmonic Tension grammar.\n\nAtmospheric tension/release field rather than precise progression feedback:\n- Gradual intensity shifts\n- Organic build and release\n- Suitable for background/screensaver mode\n\nSee also: synesthetica-xc0 (Harmonic Tension grammar)","status":"open","priority":4,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-22T15:41:54.515339Z","created_by":"Nic Young","updated_at":"2026-01-22T15:41:54.515339Z"}
{"id":"synesthetica-uty","title":"SPEC: PartSelector resolution and error handling","description":"## The Gap\n\nPartSelector supports label/mostActive/all modes, but resolution logic and failure behavior are unspecified.\n\n## Why It Matters\n\n- Control op targeting \"guitar\" fails if no part has that label\n- mostActive returns null when no recent activity\n- LLM has no feedback to disambiguate failed resolution\n- Speech patterns (\"this is the guitar\") depend on reliable deictic resolution\n\n## Current State\n\n- PartSelector: partId | label | mostActive | all\n- IActivityTracker.getMostActive(windowMs) can return null\n- PartRegistry.setLabel() exists but no query for \"does label exist?\"\n- SPEC_007 mentions control diagnostics but not selector resolution\n\n## Questions to Answer\n\n1. What diagnostic is emitted when label resolution fails?\n2. What happens when mostActive returns null? No-op? Error?\n3. Should LLM query available parts/labels before issuing ops?\n4. Is there a \"best effort\" mode vs \"strict\" mode?\n\n## Relates To\n\n- RFC_004 (LLM mediation)\n- SPEC_007 (control diagnostics)\n- RFC_003 (part registry)\n\n## Output\n\nAdditions to SPEC_007 or RFC_003 defining selector resolution semantics and error reporting.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-17T13:03:19.751812Z","created_by":"Nic Young","updated_at":"2026-01-17T13:03:19.751812Z"}
{"id":"synesthetica-w5z","title":"Note: Include actual pitch (Hz) for continuous-pitch instruments","description":"## Context\n\nCurrently Note only includes pitch class (0-11) and octave. For audio input from continuous-pitch instruments (voice, violin, slide guitar), we need the actual frequency to:\n- Enable pitch matching practice (how close am I to the target?)\n- Express microtunings and pitch bends\n- Show pitch drift/vibrato visually\n\n## Contract Change\n\nExtend Note:\n```ts\ninterface Note {\n  // Existing\n  pitch: { pc: PitchClass; octave: number };\n  \n  // New\n  frequency?: Hz;          // Actual detected frequency\n  pitchDeviation?: Cents;  // Deviation from equal temperament (-50 to +50)\n}\n```\n\n## Source\n\n- MIDI: frequency can be derived from pitch (440 * 2^((midi-69)/12))\n- Audio: frequency comes from pitch detection (YIN, pYIN, CREPE)\n\n## Use Cases\n\n1. **Pitch matching practice**: Show target note and actual pitch, visualize the gap\n2. **Vibrato visualization**: Rapid pitchDeviation oscillation\n3. **Microtonal music**: Notes that don't fit 12-TET\n\n## Depends On\n\n- Audio adapter implementation (synesthetica-5cq)\n- Pitch detection algorithm selection\n\n## Implementation Notes\n\n- For MIDI, frequency is deterministic (can be computed on demand)\n- For audio, this is the native representation\n- Grammars can use pitchDeviation for visual effects (wobble, drift)","status":"open","priority":3,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-20T11:35:15.148208Z","created_by":"Nic Young","updated_at":"2026-01-20T11:35:15.148208Z","dependencies":[{"issue_id":"synesthetica-w5z","depends_on_id":"synesthetica-5cq","type":"blocks","created_at":"2026-01-20T11:35:20.409995Z","created_by":"Nic Young"}]}
{"id":"synesthetica-w9j","title":"Spike: MIDI-to-canvas throwaway prototype","description":"## Purpose\n\nValidate core architectural assumptions before completing spec work. This is a throwaway prototype — not production code.\n\n## What to Build (2-3 hours max)\n\nMinimal path from MIDI input to visual output:\n- Web MIDI API receiving note_on/off\n- Direct render to Canvas2D (no pipeline abstraction)\n- Colored circles based on pitch (any mapping)\n- Basic fade on note_off\n\n## What to Validate\n\n1. Does Web MIDI's event-driven model work with our pull-based timing assumption?\n2. What's the actual latency from keypress to pixel?\n3. Does requestAnimationFrame give smooth enough updates?\n4. Any browser quirks with MIDI permissions?\n\n## What NOT to Do\n\n- Don't implement contracts/interfaces\n- Don't write tests\n- Don't refactor\n- Don't keep the code\n\n## Exit Criteria\n\n- Successfully see colored response to MIDI input\n- Document any surprises or assumption violations\n- Delete the code (or stash it)\n- **Write a \"What We Learned\" document** capturing:\n  - Assumption validations (confirmed or violated)\n  - Surprising behaviors encountered\n  - Spec amendments needed\n  - Unknowns that remain\n  - This document gets committed even if the code doesn't\n\n## Why This Matters\n\nThe specs assume certain behaviors (pull-based timing, adapter abstraction) that haven't been validated against browser APIs. A 2-hour spike now could save weeks of rework later.\n\nSource: Session critique — \"spec/implementation gap is widening\"\n\n---\n\n## Outcome\n\n**Completed 2026-01-18.** All assumptions validated.\n\nSee: `docs/learnings/2026-01-18-midi-spike.md`\n\nKey findings:\n- MIDI latency: ~0.4ms avg (1-3ms range) — negligible\n- Frame timing: stable 16.7ms (60fps)\n- Push-to-pull reconciliation works via state buffering\n- No dropped events under fast playing\n\nSpec amendment made: SPEC_008 updated with push-to-pull reconciliation pattern.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-17T13:16:37.823384Z","created_by":"Nic Young","updated_at":"2026-01-18T10:22:18.96769Z","closed_at":"2026-01-18T10:22:18.96769Z","close_reason":"Spike complete. All assumptions validated. See docs/learnings/2026-01-18-midi-spike.md"}
{"id":"synesthetica-wf2","title":"Implement diagnostic visual indicator in renderer","description":"## Context\n\nSPEC_007 recommends that renderers display visual indicators for active diagnostics. This is a user experience feature to surface issues without requiring log inspection.\n\n## Requirements\n\n- Display category-specific icons in top-right corner (or configurable location)\n- Categories: input (🔌), stabilizer (⚙️), grammar (🎨), control (🎛️)\n- Transient diagnostics: flash briefly then fade\n- Sticky diagnostics: persist until condition clears\n- Multiple diagnostics: show count badge or stack icons\n\n## Reference\n\nSee SPEC_007_error_and_diagnostic_model.md \"Visual Indicator\" section.\n\n## Acceptance\n\n- Renderer displays appropriate icon when diagnostics are present in SceneFrame\n- Icons decay/persist according to diagnostic persistence mode\n- Implementation is clean and doesn't interfere with main visual content","status":"open","priority":3,"issue_type":"task","owner":"nic@o1labs.org","created_at":"2026-01-15T15:10:20.302069Z","created_by":"Nic Young","updated_at":"2026-01-15T15:10:20.302069Z"}
{"id":"synesthetica-xc0","title":"Grammar: Harmonic Tension (chord progressions)","description":"Visualize harmonic tension and resolution in chord progressions.\n\n## Purpose\n\nRender the harmonic journey - tension building, resolution moments, and unexpected turns. This grammar focuses on the \"where\" of harmony (progression context) rather than the \"what\" (chord identity).\n\n## Visual Representation\n\nGrammar receives from vocabulary:\n- **Tension value**: 0-1 continuous value from ProgressionStabilizer\n- **Tension components**: Dissonance, hierarchical, key distance, voice leading (optional detail)\n- **Function annotation**: Tonic/dominant/subdominant (when key is known)\n- **Cadence approaching**: V-I, IV-I, deceptive, etc.\n\n**Key constraint**: Grammar does NOT compute tension. The stabilizer computes it; vocabulary annotates it; grammar renders it.\n\n### Possible Rendering Approaches (SUGGESTIONS)\n\n1. **Tension Field**\n   - Global visual effect that responds to tension level\n   - Calm/stable at low tension, turbulent/expanded at high tension\n   - Resolution moments as visual \"release\"\n\n2. **Progression Trail**\n   - Visual trail showing recent harmonic movement\n   - Tension affects trail characteristics (smooth vs. jagged)\n   - Resolution points as visual \"anchors\"\n\n3. **Expectation Visualization**\n   - Show expected vs. actual chord\n   - Surprise moments (deceptive cadence) as visual disruption\n   - Satisfaction (authentic cadence) as visual resolution\n\n4. **Layered Approach**\n   - Combine with Basic Harmony Grammar (sn4)\n   - This grammar adds tension overlay to chord visualization\n\n## Dependencies\n\n- ProgressionStabilizer (synesthetica-bad) - provides tension data\n- KeyDetectionStabilizer (synesthetica-49n) - optional, enables function-aware visualization\n- MusicalVisualVocabulary (synesthetica-39e) - provides annotated tension values\n\n## Acceptance Criteria\n\n- [ ] Renders tension level visually\n- [ ] Uses vocabulary-provided annotations (NOT self-computed tension)\n- [ ] Shows resolution moments\n- [ ] Handles uncertain key context gracefully\n- [ ] Composes well with Basic Harmony Grammar\n- [ ] Golden tests for rendering\n\n## See Also\n\n- synesthetica-sn4 (Basic Harmony Grammar) - for chord identity visualization\n- synesthetica-bad (ProgressionStabilizer) - provides tension data\n- synesthetica-49n (KeyDetectionStabilizer) - provides key context\n- synesthetica-39e (Vocabulary mappings) - provides annotations\n- synesthetica-al3 (Vocabulary spike) - decides tension representation\n- docs/vocabulary/semantic-mappings-v1.md - tension mapping proposals\n\n---\n\n## Previous Description (preserved for reference)\n\nVisualize harmonic tension and resolution in chord progressions.\n\nFocus on the 'where' of harmony: tension/release, expectation/surprise.\n\nCould include:\n- Tension building (V approaching I)\n- Resolution moments\n- Unexpected progressions (deceptive cadences)\n- Tonal center gravity\n\nRequires ProgressionStabilizer (synesthetica-bad) to provide harmonic context.\n\nSee also: Basic Harmony grammar for chord quality visualization.","status":"open","priority":3,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-22T15:40:46.665949Z","created_by":"Nic Young","updated_at":"2026-01-23T15:09:42.421389Z"}
{"id":"synesthetica-y72","title":"SPEC: Preset versioning and backward compatibility","description":"## The Gap\n\nNo versioning scheme exists for presets — if a grammar's parameter schema changes, existing saved presets break silently.\n\n## Why It Matters\n\n- Users accumulate presets over time\n- Breaking changes orphan saved configurations\n- No migration semantics or compatibility markers exist\n- Imports from other users may reference unknown grammars\n\n## Current State\n\n- PresetMeta has id, name, source, timestamps — no version\n- IPresetCatalog.importUser validates but behavior for unknowns is undefined\n- synesthetica-r0y notes JSON schema gap\n- No deprecation policy for grammars/macros\n\n## Questions to Answer\n\n1. Should presets have version numbers?\n2. What's the migration strategy for incompatible presets?\n3. How are unknown grammar references handled?\n4. Should presets declare minimum engine version?\n\n## Relates To\n\n- SPEC_001 (preset storage)\n- synesthetica-r0y (export/import schema)\n\n## Output\n\nAdditions to SPEC_001 defining preset versioning, compatibility markers, and migration rules.","status":"open","priority":4,"issue_type":"task","created_at":"2026-01-17T13:04:14.518632Z","created_by":"Nic Young","updated_at":"2026-01-17T13:04:14.518632Z"}
{"id":"synesthetica-y7q","title":"P2: Evaluate Meyda.js for audio adapter","description":"Evaluate whether Meyda.js (https://meyda.js.org/) is suitable for the audio MIR pipeline.\n\n## What Meyda provides\n- Real-time audio feature extraction in browser\n- Spectral features (centroid, rolloff, flatness, etc.)\n- Perceptual features (loudness, RMS)\n- Chroma / pitch class distribution\n\n## Questions to answer\n- Does it provide pitch-class distributions with confidence?\n- Can it detect beats/onsets?\n- What's the latency profile?\n- Does it fit our CMSFrame model?\n\n## Alternatives to consider\n- Essentia.js\n- Custom Web Audio API implementation\n- Combination approach\n\nThis is Phase 2 work — we need the pipeline proven with MIDI first.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-17T12:40:43.836112Z","created_by":"Nic Young","updated_at":"2026-01-17T12:40:43.836112Z","dependencies":[{"issue_id":"synesthetica-y7q","depends_on_id":"synesthetica-j5y","type":"blocks","created_at":"2026-01-17T12:40:54.769807Z","created_by":"Nic Young"}]}
{"id":"synesthetica-ymc","title":"P0: Minimal ruleset (pitch→hue, velocity→brightness)","description":"First ruleset implementation. Minimal but real.\n\n- pitch-class → hue (using pcToHue invariant)\n- velocity → brightness\n- Produces PaletteIntent and basic MotionIntent\n- No chord/beat/phrase handling yet","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-17T12:33:27.736655Z","created_by":"Nic Young","updated_at":"2026-01-18T10:50:31.322135Z","closed_at":"2026-01-18T10:50:31.322135Z","close_reason":"Implemented as MinimalRuleset with unit tests. Golden tests deferred.","dependencies":[{"issue_id":"synesthetica-ymc","depends_on_id":"synesthetica-c79","type":"blocks","created_at":"2026-01-17T12:36:59.704563Z","created_by":"Nic Young"},{"issue_id":"synesthetica-ymc","depends_on_id":"synesthetica-901","type":"blocks","created_at":"2026-01-17T12:40:24.068414Z","created_by":"Nic Young"}]}
{"id":"synesthetica-ysk","title":"Design Configuration Service and composite storage","description":"User-authored presets (named configurations like 'matching fireworks') need persistent storage, but the LLM shouldn't own this.\n\nProposed approach:\n- LLM proposes names/checkpoints via bounded ControlOps\n- A Configuration Service owns the catalog and validates all writes\n- User presets stored as first-class catalog entries\n\nNew types needed:\n- UserPreset (snapshot of style selection + macro values + patches)\n- Checkpoint (trial state for undo/discard)\n- IConfigurationService interface\n\nStorage for v0: localStorage in browser\n\nOutput:\n1. Add checkpoint and user preset types to packages/contracts/config/\n2. Extend ControlOps with checkpoint operations\n3. Add IConfigurationService to packages/contracts/pipeline/\n4. Create RFC or SPEC documenting the persistence model","status":"closed","priority":2,"issue_type":"feature","owner":"nic@o1labs.org","created_at":"2026-01-14T13:11:23.551867Z","created_by":"Nic Young","updated_at":"2026-01-14T19:43:51.599972Z","closed_at":"2026-01-14T19:43:51.599972Z","close_reason":"Complete. IPresetCatalog provides CRUD for presets (list, get, save, delete, import/export). Types in packages/contracts/config/preset.ts, documented in SPEC_001.","dependencies":[{"issue_id":"synesthetica-ysk","depends_on_id":"synesthetica-8do","type":"blocks","created_at":"2026-01-14T13:12:07.705103Z","created_by":"Nic Young"}]}
{"id":"synesthetica-zd8","title":"[EPIC] Phase 1: Ruleset \u0026 Grammar Exploration","description":"Deep iteration on rulesets and grammars with the Phase 0 scaffold as test harness.\n\n## Goal\nDiscover what mappings and visual treatments actually work. This is where the \"magic\" happens.\n\n## Approach\n- Freeze adapters/pipeline/renderer from Phase 0\n- Iterate freely on rulesets (CMS → IntentFrame mappings)\n- Iterate freely on grammars (IntentFrame → SceneFrame)\n- Build golden test corpus as we go\n\n## Exit Criteria\n- At least one ruleset that feels musically meaningful\n- At least 3 grammars with distinct characters\n- Golden tests covering core behaviours\n- Confidence in the IntentFrame interface\n\n## Depends on\n- Phase 0 complete","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-17T12:33:07.868512Z","created_by":"Nic Young","updated_at":"2026-01-17T12:33:07.868512Z","dependencies":[{"issue_id":"synesthetica-zd8","depends_on_id":"synesthetica-j5y","type":"blocks","created_at":"2026-01-17T12:36:22.390715Z","created_by":"Nic Young"}]}
{"id":"synesthetica-zmm","title":"DECISION: Auto-start session on MIDI device selection","description":"Document the decision to auto-start sessions on device selection rather than requiring explicit start/stop buttons.\n\n## Context\nDuring Phase 0 web app shell implementation, we clarified the session lifecycle UX.\n\n## Decision\n**Option B: Auto-start on device selection** (chosen)\n\nSession flow:\n1. Page loads → show MIDI device selector\n2. User selects device → session auto-starts\n3. Session runs until page unload or device change\n4. Cleanup in beforeunload handler\n\n## Alternatives Considered\n- Option A: Explicit start/stop buttons (rejected - unnecessary complexity)\n- Option C: Other (not explored)\n\n## Rationale\n- Simpler UX - fewer controls to understand\n- Aligns with session lifecycle model from SPEC_005 (session-relative timestamps)\n- Aligns with stabilizer lifecycle from SPEC_006 (init/reset/dispose)\n- Natural mental model: selecting device = \"I want to use this now\"\n\n## Implementation\nSee packages/web-app/src/main.ts:\n- startSession() called from handleDeviceSelection()\n- No manual start/stop UI elements\n- Session lifecycle managed automatically\n\n## Related\n- SPEC_005: Frame timing and session epochs\n- SPEC_006: Stabilizer lifecycle (init/reset/dispose)\n- packages/web-app/README.md: Documents the UX flow","status":"closed","priority":4,"issue_type":"task","created_at":"2026-01-18T12:24:19.9441Z","created_by":"Nic Young","updated_at":"2026-01-18T12:24:58.716996Z","closed_at":"2026-01-18T12:24:58.716996Z","close_reason":"Closed"}
{"id":"synesthetica-zv3","title":"Redesign TestRhythmGrammar for three-tier rhythm visualization","description":"## Problem\n\nThe current TestRhythmGrammar was updated for RFC 007 but not redesigned. It produces basic entities but doesn't clearly illustrate the three-tier rhythm model:\n\n1. **Historic-only** (no tempo): Just show detected timing patterns\n2. **Tempo-relative** (tempo set): Show timing relative to expected beat grid, visualize drift\n3. **Meter-relative** (tempo + meter): Show bar/beat structure overlaid on timing\n\nThe grammar should be a clear demonstration of how these tiers work, serving as both a reference implementation and a visual debugging tool.\n\n## Proposed Design\n\n### Core Principle: Single Timeline with Contextual Decoration\n\nThe visualization is always **onset markers scrolling left and fading**. Everything else is subtle context that helps interpret those markers. Each tier *replaces* the previous decoration rather than adding to it.\n\n### Visual Layout\n\nHorizontal timeline scrolling left:\n- Right edge = \"now\"\n- Left edge = past (configurable window, e.g., 4 seconds)\n- Vertical center = timeline baseline\n\n### Tier 1: Historic-Only (no prescribedTempo)\n\nWhen only `rhythmicAnalysis` is available:\n\n```\n                                    NOW\n    ●      ●    ●      ●    ●    ●  │\n────┴──────┴────┴──────┴────┴────┴──┼────\n    ← older                    newer →\n```\n\n- **Onset markers** (particles): Circles at each `recentOnsets` timestamp\n  - Color from `rhythm.visual.palette` (ruleset-defined)\n  - Opacity fades with age (1.0 at now → 0.2 at window edge)\n  - Size: small, uniform\n- **Detected division** (if exists): Subtle tick marks at `detectedDivision` intervals, very low opacity (0.15)\n- **Stability**: Affects tick mark opacity (higher stability = slightly more visible ticks)\n\nEntities:\n- `onset-marker` (particle): For each recent onset\n- `division-tick` (field): Background tick marks if detectedDivision exists\n\n### Tier 2: Tempo-Relative (prescribedTempo set, no meter)\n\nReplaces division ticks with beat grid. Adds drift indication without overriding marker colors.\n\n```\n    Beat grid (from tempo)\n    ↓    ↓    ↓    ↓    ↓    ↓    NOW\n    ┃    ┃    ┃    ┃    ┃    ┃    │\n    ●    ●    ●    ●    ●    ●    │  ← Markers keep ruleset color\n    │         ↑              ↑    │\n              │              └── slightly late (below center)\n              └── on beat (centered)\n```\n\n- **Beat grid** (field): Vertical lines at expected beat positions, low opacity (0.2)\n- **Drift visualization**: Onset markers positioned *vertically* based on deviation from nearest beat\n  - Center (y=0.5) = on beat\n  - Above center = early\n  - Below center = late\n  - Range: ±15% of canvas height for ±50% beat deviation\n- **Drift indicator ring**: A second, smaller ring around each marker showing drift magnitude\n  - Green ring = on beat (within 10%)\n  - Yellow ring = slight drift (10-25%)\n  - Red ring = significant drift (\u003e25%)\n  - This adds information without changing the marker's core color\n\n**Important**: Marker fill color remains from `rhythm.visual.palette`. Only the drift ring indicates timing accuracy.\n\nEntities:\n- `onset-marker` (particle): Same as Tier 1, but with vertical drift offset\n- `drift-ring` (particle): Secondary indicator around each marker\n- `beat-grid` (field): Vertical lines at tempo-derived positions\n\n### Tier 3: Meter-Relative (prescribedTempo + prescribedMeter)\n\nEnhances beat grid with bar structure. Downbeats get emphasis.\n\n```\n    Bar 1              Bar 2              NOW\n    ┃    │   │   │    ┃    │   │   │    │\n    ●    ●   ●   ●    ●    ●   ●   ●    │\n```\n\n- **Bar lines**: Beat 1 gets thicker/brighter line (opacity 0.4 vs 0.2)\n- **Downbeat markers**: Onset markers on beat 1 get a subtle outer glow\n- **Beat grid**: Non-downbeat lines remain subtle (opacity 0.15)\n\nEntities (replaces Tier 2):\n- `onset-marker` (particle): With drift offset\n- `drift-ring` (particle): Drift indicator\n- `downbeat-glow` (particle): Extra glow for markers landing on beat 1\n- `bar-grid` (field): Bar lines + beat lines with differentiated opacity\n\n### Color Scheme\n\n- **Onset markers**: Always from `rhythm.visual.palette.primary` (ruleset-defined)\n- **Drift rings**: Green (#4a4) → Yellow (#aa4) → Red (#a44) based on timing accuracy\n- **Beat/bar grid**: Neutral gray (#888), opacity varies by importance\n- **Downbeat glow**: White, low opacity (0.3)\n\n### Entity Summary by Tier\n\n| Tier | Entities |\n|------|----------|\n| 1 (historic) | `onset-marker`, `division-tick` |\n| 2 (tempo) | `onset-marker` (with y-drift), `drift-ring`, `beat-grid` |\n| 3 (meter) | `onset-marker` (with y-drift), `drift-ring`, `downbeat-glow`, `bar-grid` |\n\n### Implementation Notes\n\n1. Timeline position: `x = 1 - (now - onset) / windowMs`\n2. Drift calculation: \n   ```ts\n   const beatMs = 60000 / prescribedTempo;\n   const nearestBeat = Math.round(onset / beatMs) * beatMs;\n   const drift = (onset - nearestBeat) / beatMs; // -0.5 to 0.5\n   const y = 0.5 + drift * 0.3; // ±15% canvas height\n   ```\n3. Downbeat detection:\n   ```ts\n   const barMs = beatMs * beatsPerBar;\n   const positionInBar = ((onset - referenceOnset) % barMs) / beatMs;\n   const isDownbeat = positionInBar \u003c 0.5; // within half a beat of beat 1\n   ```\n\n## Acceptance Criteria\n\n- [ ] With no tempo: Shows onset markers fading left, optional division ticks\n- [ ] With tempo: Shows beat grid, markers vertically positioned by drift, drift rings indicate accuracy\n- [ ] With tempo + meter: Shows bar lines (emphasized), downbeat glows\n- [ ] Marker colors always come from ruleset palette (never overridden by drift)\n- [ ] Clear visual progression as tiers are added\n- [ ] Serves as reference for rhythm visualization patterns","status":"closed","priority":2,"issue_type":"task","owner":"nic.youngster@gmail.com","created_at":"2026-01-20T15:54:26.12326Z","created_by":"Nic Young","updated_at":"2026-01-20T16:09:47.801726Z","closed_at":"2026-01-20T16:09:47.801726Z","close_reason":"Implemented three-tier rhythm visualization with onset-marker, drift-ring, beat-line, bar-line, division-tick, downbeat-glow entities"}
