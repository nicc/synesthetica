{"id":"synesthetica-0dm","title":"Write concrete acceptance scenarios for Phase 0","description":"## Problem\n\nPhase 0 epic says \"can connect a MIDI keyboard and see colored particles\" — but that's vague. What colors? What behavior? How do we know it's correct?\n\n## Deliverable\n\nWrite 5-10 concrete scenarios with expected outcomes. Examples:\n\n### Scenario 1: Single note color mapping\n- Input: Play C4 (MIDI note 60)\n- Expected: Particle appears at hue=90° (per pcToHue with A=0°, clockwise)\n- Verify: Visual inspection or screenshot test\n\n### Scenario 2: Velocity affects brightness\n- Input: Play C4 at velocity 127, then velocity 32\n- Expected: First particle brighter than second\n- Verify: Measurable brightness difference\n\n### Scenario 3: Note decay\n- Input: Play and release C4\n- Expected: Particle fades over ~500ms after release\n- Verify: Particle gone within 1 second\n\n### Scenario 4: Chord visualization\n- Input: Play C major chord (C4, E4, G4 simultaneously)\n- Expected: Three particles with hues 90°, 150°, 210°\n- Verify: Three distinct colors visible\n\n## Why This Matters\n\nWithout concrete acceptance criteria, \"done\" is subjective. These scenarios become the definition of success and can drive test fixtures.\n\nSource: Session critique — \"not defining what success looks like for the user\"","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-17T13:16:57.995383Z","created_by":"Nic Young","updated_at":"2026-01-17T13:16:57.995383Z"}
{"id":"synesthetica-0jg","title":"P0: Web app shell","description":"Minimal web app that hosts the pipeline.\n\n- HTML page with canvas\n- MIDI device selection\n- Start/stop session\n- No UI beyond essentials","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-17T12:33:48.42405Z","created_by":"Nic Young","updated_at":"2026-01-18T12:20:10.336752Z","closed_at":"2026-01-18T12:20:10.336752Z","close_reason":"Closed","dependencies":[{"issue_id":"synesthetica-0jg","depends_on_id":"synesthetica-uky","type":"blocks","created_at":"2026-01-17T12:36:01.800816Z","created_by":"Nic Young"},{"issue_id":"synesthetica-0jg","depends_on_id":"synesthetica-2d5","type":"blocks","created_at":"2026-01-17T12:36:01.916107Z","created_by":"Nic Young"}]}
{"id":"synesthetica-1g0","title":"Execute RFC 005 migration: Pipeline frame types","description":"## Summary\n\nExecute the migration plan defined in RFC 005 to introduce distinct frame types for each pipeline boundary:\n- `RawInputFrame` (adapter output)\n- `MusicalFrame` (stabilizer output, ruleset input)  \n- `VisualIntentFrame` (ruleset output, grammar input)\n\n## Migration Phases\n\n### Phase 1: Introduce New Types\n- Add new types to @synesthetica/contracts\n- Keep existing CMSFrame temporarily\n\n### Phase 2: Create/Update Specs\n- Create SPEC_009 for new frame type contracts\n- Update SPEC_008 (Pipeline Orchestration)\n- Update SPEC_006 (Stabilizer Statefulness)\n\n### Phase 3: Update Adapters\n- Change MidiAdapter to emit RawInputFrame\n- Update adapter tests\n- Ensure tests pass\n\n### Phase 4: Implement Note-Tracking Stabilizer\n- Create NoteTrackingStabilizer\n- Implement note lifecycle (attack → sustain → release)\n- Add comprehensive tests\n\n### Phase 5: Update Ruleset\n- Change MinimalRuleset to consume MusicalFrame\n- Remove events from VisualIntentFrame\n- Update tests\n\n### Phase 6: Update Grammar\n- Change ParticleGrammar to respond to intents only\n- Remove references to input.events\n- Update tests\n\n### Phase 7: Update Pipeline\n- Update Pipeline class for new frame types\n- Update tests\n\n### Phase 8: Rebuild Web App\n- Update web app for new pipeline\n- Manual testing of note visualization with release behavior\n\n### Phase 9: Cleanup\n- Remove CMSFrame and legacy types\n- Final test pass\n- Update documentation\n\n## Related\n\n- RFC 005: rfcs/rfc_005_pipeline_frame_types.md\n- Depends on: synesthetica-723 (rename Intent to VisualIntent)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-18T15:11:07.491925Z","created_by":"Nic Young","updated_at":"2026-01-19T08:53:09.18912Z","closed_at":"2026-01-19T08:53:09.18912Z","close_reason":"RFC 005 migration complete. All legacy types removed, new pipeline implemented."}
{"id":"synesthetica-1wq","title":"SPEC: Macro-to-grammar parameter binding","description":"## The Gap\n\nMacros (articulation, persistence, emphasis.*) are 0–1 continuous values that \"adjust high-level characteristics\", but no contract specifies how these map to individual grammar parameters.\n\n## Why It Matters\n\n- SPEC_004 provides macro annotations with directionality descriptions (for LLM)\n- But grammars have paramsSchema — how do macro changes translate to param changes?\n- Implementation teams must reverse-engineer intent from prose annotations\n- Different grammars may interpret the same macro delta differently\n\n## Current State\n\n- `Preset.macros` defines articulation, persistence, emphasis.{melody,harmony,rhythm,timbre}\n- `GrammarAnnotation.macroResponses` indicates responsiveness (strong/moderate/weak/none)\n- `IGrammar.paramsSchema` exists but linkage to macros is undefined\n\n## Questions to Answer\n\n1. Is there a binding layer between macros and grammar params?\n2. Do grammars receive macro values directly, or do they receive transformed params?\n3. How does `macroResponses.responsiveness` translate to actual behavior?\n4. Are sensitivity curves (linear, exponential) per-grammar or global?\n\n## Relates To\n\n- SPEC_004 (macro annotations)\n- RFC_002 (Preset interface)\n- synesthetica-30r (macro interpolation curves)\n\n## Output\n\nEither extend SPEC_004 or create a new spec defining the macro → grammar param binding contract.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-17T13:02:49.038531Z","created_by":"Nic Young","updated_at":"2026-01-17T13:02:49.038531Z"}
{"id":"synesthetica-2d5","title":"P0: Canvas2D renderer","description":"Minimal renderer that draws SceneFrame entities to canvas.\n\n- Canvas2D (not WebGL)\n- Draw particles as circles\n- Handle color, size, opacity from entity style\n- No effects or post-processing","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-17T12:33:41.163358Z","created_by":"Nic Young","updated_at":"2026-01-18T12:20:01.97557Z","closed_at":"2026-01-18T12:20:01.97557Z","close_reason":"Closed","dependencies":[{"issue_id":"synesthetica-2d5","depends_on_id":"synesthetica-c79","type":"blocks","created_at":"2026-01-17T12:37:00.038581Z","created_by":"Nic Young"}]}
{"id":"synesthetica-2uv","title":"Should Style be called VisualGrammar?","status":"closed","priority":2,"issue_type":"task","owner":"nic@o1labs.org","created_at":"2026-01-14T19:18:59.937246Z","created_by":"Nic Young","updated_at":"2026-01-14T20:14:30.051662Z","closed_at":"2026-01-14T20:14:30.051662Z","close_reason":"Resolved. Renamed Style → Grammar throughout codebase. Annotations include aliases field for user-facing synonyms (style, look, effect). See SPEC_004."}
{"id":"synesthetica-30r","title":"Define macro interpolation curves","description":"Macros are 0-1 continuous values but how they map to internal parameters (linear, exponential, stepped) is not defined. Low priority for v0.","status":"open","priority":4,"issue_type":"task","created_at":"2026-01-16T09:39:03.344196Z","created_by":"Nic Young","updated_at":"2026-01-16T09:39:25.569156Z"}
{"id":"synesthetica-589","title":"Decide platform and rendering target for v0","description":"The PRD defers platform assumptions, but practical development requires a decision.\n\nOptions:\n1. Browser-first: Web Audio API + Web MIDI API + Canvas/WebGL\n2. Native-first: Electron + Node MIDI libraries + native rendering\n3. Hybrid: Core logic portable, adapters platform-specific\n\nConsiderations:\n- Browser has better MIDI support than commonly assumed (Web MIDI API)\n- Audio input in browser requires user permission flow\n- WebGL gives good rendering performance\n- Native gives lower latency but more setup friction\n\nOutput: Document platform decision in PRD.md under 'Platform assumptions'. This unblocks adapter and renderer implementation.","status":"closed","priority":1,"issue_type":"feature","owner":"nic@o1labs.org","created_at":"2026-01-14T13:11:23.362362Z","created_by":"Nic Young","updated_at":"2026-01-14T13:24:47.978068Z","closed_at":"2026-01-14T13:24:47.978068Z","close_reason":"Platform decision documented in PRD.md: Browser-first (Web MIDI + Web Audio + WebGL), with audio file input for testing. Native deferred to post-v0."}
{"id":"synesthetica-5cq","title":"SPEC: Audio adapter contract","description":"## The Gap\n\nAudio adapter is referenced in PRD and planned for Phase 2, but no interface specifies how audio evidence maps to RawInputFrame and MusicalFrame fields.\n\n## Why It Matters\n\n- Can't implement audio support without this contract\n- Invariants assume audio adapters produce uncertain musical state\n- Audio is a gating requirement for LLM-mediation (synesthetica-8f4)\n- synesthetica-y7q (Meyda evaluation) needs target contract to evaluate against\n\n## Current State\n\n- IRawSourceAdapter.nextFrame(): RawInputFrame is generic\n- MusicalFrame types support confidence/provenance for uncertainty\n- No spec for pitch-class distribution format from audio\n- No spec for beat detection output or chord inference confidence\n\n## Questions to Answer\n\n1. How are pitch-class distributions represented in RawInputFrame?\n2. What confidence thresholds distinguish \"heard C\" from \"maybe C\"?\n3. How does beat detection produce BeatState in MusicalFrame?\n4. What's the expected latency profile for audio analysis?\n\n## Relates To\n\n- synesthetica-8f4 (Audio gates LLM-mediation)\n- synesthetica-y7q (Meyda evaluation)\n- SPEC_009 (Pipeline frame types)\n\n## Output\n\nNew spec (SPEC_010) defining AudioAdapter contract and RawInputFrame/MusicalFrame output format for audio.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-17T13:04:25.16537Z","created_by":"Nic Young","updated_at":"2026-01-19T10:33:55.599755Z"}
{"id":"synesthetica-5l9","title":"P0: Build-time annotation validation","description":"Validate annotations at build time per SPEC_004.\n\n## Checks\n- Grammar `id` must be unique\n- Grammar `aliases` should not conflict across grammars  \n- `illustrates` values must be valid MusicalConcept\n- `traits` values must be valid VisualTrait\n- Macro annotations must exist for all macros in Preset.macros schema\n\n## Implementation\n- TypeScript compiler plugin, or\n- Build script that validates annotation files\n- CI integration\n\n## On failure\n- Build fails with clear error message identifying the violation","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-17T12:56:08.512782Z","created_by":"Nic Young","updated_at":"2026-01-17T12:56:08.512782Z","dependencies":[{"issue_id":"synesthetica-5l9","depends_on_id":"synesthetica-c79","type":"blocks","created_at":"2026-01-17T12:56:15.559076Z","created_by":"Nic Young"}]}
{"id":"synesthetica-6lf","title":"P0: First grammar (particles on note_on)","description":"First grammar implementation. Spawn particles on note events.\n\n- Spawn particle at note_on\n- Color from PaletteIntent\n- Fade/decay over time\n- Simple physics (gravity or drift)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-17T12:33:32.015124Z","created_by":"Nic Young","updated_at":"2026-01-18T10:50:31.446084Z","closed_at":"2026-01-18T10:50:31.446084Z","close_reason":"Implemented as ParticleGrammar with unit tests. Golden tests deferred.","dependencies":[{"issue_id":"synesthetica-6lf","depends_on_id":"synesthetica-c79","type":"blocks","created_at":"2026-01-17T12:36:59.808993Z","created_by":"Nic Young"},{"issue_id":"synesthetica-6lf","depends_on_id":"synesthetica-901","type":"blocks","created_at":"2026-01-17T12:40:24.178195Z","created_by":"Nic Young"}]}
{"id":"synesthetica-6t2","title":"Define Phase 1 exit criteria and time budget","description":"## Problem\n\nPhase 1 (ruleset/grammar exploration) is where the \"magic\" happens — but it's the least specified part of the plan. Currently just two vague issues: \"Ruleset iteration\" and \"Grammar iteration\".\n\n## Questions to Answer\n\n1. **Time budget**: How long do you want to spend in Phase 1? Weeks? Months?\n\n2. **Exit criteria for rulesets**:\n   - What makes a ruleset \"feel right\"?\n   - How many musical scenarios should it handle well?\n   - What's the golden test coverage target?\n\n3. **Exit criteria for grammars**:\n   - How many grammars constitute a \"vocabulary\"?\n   - What visual diversity is needed?\n   - How do you know when to stop iterating?\n\n4. **Confidence threshold**:\n   - What would make you confident to move to Phase 2?\n   - What discoveries would force a return to specs?\n\n## Why This Matters\n\nDiscovery work without bounds tends to expand indefinitely. Defining \"done\" for exploration keeps it productive.\n\nSource: Session critique — \"budgeting for the 'magic' work\"","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-17T13:17:17.88231Z","created_by":"Nic Young","updated_at":"2026-01-17T13:17:17.88231Z"}
{"id":"synesthetica-6zz","title":"SPEC: Router/stabilizer interaction and per-part state","description":"## The Gap\n\nRFC_003 introduces routing by PartId, SPEC_006 defines stateful stabilizers, but their interaction is ambiguous.\n\n## Why It Matters\n\n- Should stabilizers run before or after routing?\n- Do stabilizers maintain per-part state or global state?\n- Can stabilizers aggregate across parts (ensemble tension)?\n- Some signals (global activity) conceptually span parts\n\n## Current State\n\n- IRouter.route(frame) → Map\u003cPartId, CMSFrame\u003e\n- IStabilizer has init/dispose/apply/reset lifecycle\n- SPEC_008 shows \"for each part, run stabilizers\" but doesn't clarify instantiation\n- CMS events have part: PartId but control signals may be global\n\n## Questions to Answer\n\n1. Are stabilizers instantiated per-part or singleton?\n2. If per-part, when are new stabilizer instances created?\n3. Can a stabilizer read signals from other parts?\n4. What's the ordering: route then stabilize, or stabilize then route?\n\n## Relates To\n\n- RFC_003 (parts and routing)\n- SPEC_006 (stabilizer lifecycle)\n- SPEC_008 (pipeline orchestration)\n\n## Output\n\nAdditions to SPEC_006 or SPEC_008 clarifying stabilizer instantiation and data access scope.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-17T13:03:48.312521Z","created_by":"Nic Young","updated_at":"2026-01-17T13:03:48.312521Z"}
{"id":"synesthetica-723","title":"Rename Intent to VisualIntent throughout codebase","description":"## Summary\n\nRename `Intent` to `VisualIntent` throughout the codebase for clarity. This includes derivative names:\n- `Intent` → `VisualIntent`\n- `IntentFrame` → `VisualIntentFrame`\n- Any other derived names\n\n## Why\n\nThe term \"Intent\" is ambiguous - we have visual intents (what grammars consume) and could have other intent types. Making this explicit improves code clarity and aligns with RFC 005.\n\n## Scope\n\n- packages/contracts/intents/intents.ts\n- All consumers of these types across packages\n- Update specs and RFCs that reference these types\n\n## Related\n\n- RFC 005: Pipeline Frame Types and Musical Abstraction","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-18T15:10:35.39742Z","created_by":"Nic Young","updated_at":"2026-01-19T08:53:20.455624Z","closed_at":"2026-01-19T08:53:20.455624Z","close_reason":"VisualIntent naming is now used throughout codebase."}
{"id":"synesthetica-8do","title":"Define Preset storage and lifecycle","description":"Preset lifecycle is unspecified:\n- How are presets created, saved, edited?\n- Where are they stored? (localStorage, JSON files, DB)\n- Who validates them against the schema?\n- How do built-in vs user presets coexist?\n\nOutput:\n1. Document preset storage format and location\n2. Add validation helpers or schema to packages/contracts\n3. Define the distinction between builtin/user presets\n4. Amend RFC 002 or create SPEC for preset management","status":"closed","priority":2,"issue_type":"feature","owner":"nic@o1labs.org","created_at":"2026-01-14T13:11:23.74087Z","created_by":"Nic Young","updated_at":"2026-01-14T14:06:18.77741Z","closed_at":"2026-01-14T14:06:18.77741Z","close_reason":"Preset storage defined in SPEC_001_preset_storage.md. Contracts added to packages/contracts/config/preset.ts: PresetSource, PresetMeta, ValidationResult, IPresetCatalog. localStorage for v0, interface abstracts for future migration."}
{"id":"synesthetica-8f4","title":"Audio adapter gates LLM-mediation development","description":"## Decision\n\nAudio input is a gating requirement for LLM-mediation development.\n\n## Rationale\n\n1. **Primary use case**: Ear training (learning guitar by ear) requires audio input, not just MIDI\n2. **Architectural validation**: Audio introduces confidence/uncertainty as first-class — the pipeline must handle probabilistic input\n3. **Source diversity**: Proves the RawInputFrame abstraction works for both MIDI and audio\n\n## Implication\n\nLLM-mediation development should not begin until audio adapter is functional and integrated.\n\n## Relates To\n\n- synesthetica-5cq (Audio adapter CMS contract spec)\n- synesthetica-y7q (Evaluate Meyda.js for audio adapter)\n- synesthetica-jes (Phase 2: Full System epic)","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-19T10:27:32.55917Z","created_by":"Nic Young","updated_at":"2026-01-19T10:27:32.55917Z","dependencies":[{"issue_id":"synesthetica-8f4","depends_on_id":"synesthetica-5cq","type":"blocks","created_at":"2026-01-19T10:35:27.04408Z","created_by":"Nic Young"},{"issue_id":"synesthetica-8f4","depends_on_id":"synesthetica-y7q","type":"blocks","created_at":"2026-01-19T10:35:38.279605Z","created_by":"Nic Young"}]}
{"id":"synesthetica-8kf","title":"SPEC: Grammar registration and discovery mechanism","description":"## The Gap\n\nGrammars are referenced by ID in presets, but no contract specifies how grammars are discovered, registered, or validated at runtime.\n\n## Why It Matters\n\n- How does the engine know which grammars are available?\n- What happens when a preset references a non-existent grammar?\n- How do contributors add grammars without modifying core code?\n- Open/closed principle requires a discovery mechanism\n\n## Current State\n\n- Preset.grammars references grammarId strings\n- IGrammar interface exists but no IGrammarRegistry\n- synesthetica-d53 calls for contribution guide but not the registry contract\n- synesthetica-5l9 validates annotations but not grammar existence\n\n## Questions to Answer\n\n1. Is there an IGrammarRegistry interface?\n2. How are grammars discovered (import map? directory scan? explicit registration?)\n3. What validation runs at grammar load time?\n4. What diagnostic is emitted for missing grammar references?\n\n## Relates To\n\n- RFC_002 (grammar API)\n- synesthetica-d53 (contribution guide)\n- synesthetica-5l9 (annotation validation)\n\n## Output\n\nNew interface (IGrammarRegistry) and additions to SPEC_008 or a new spec.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-17T13:03:38.688006Z","created_by":"Nic Young","updated_at":"2026-01-17T13:03:38.688006Z"}
{"id":"synesthetica-901","title":"P0: Golden test infrastructure","description":"Test harness for rulesets and grammars.\n\n- CMS fixtures (JSON) → expected IntentFrame\n- IntentFrame sequences → expected entity snapshots\n- Deterministic via rngSeed\n- Snapshot comparison utilities","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-17T12:33:53.102177Z","created_by":"Nic Young","updated_at":"2026-01-17T12:40:14.442276Z","dependencies":[{"issue_id":"synesthetica-901","depends_on_id":"synesthetica-c79","type":"blocks","created_at":"2026-01-17T12:40:23.954325Z","created_by":"Nic Young"},{"issue_id":"synesthetica-901","depends_on_id":"synesthetica-5l9","type":"blocks","created_at":"2026-01-17T12:56:15.67575Z","created_by":"Nic Young"}]}
{"id":"synesthetica-9eb","title":"Define frame timing and clock semantics","description":"The timing model is underspecified.\n\nQuestions to resolve:\n- What drives the frame clock? Pull-based (renderer requests) or push-based (adapters emit)?\n- What happens when audio and MIDI have different latencies?\n- What epoch are Ms timestamps relative to?\n- How is frame synchronization handled across multiple sources?\n\nOutput: Add timing/clock types to packages/contracts/core. Document frame semantics in a new SPEC or amend RFC 002.","status":"closed","priority":2,"issue_type":"feature","owner":"nic@o1labs.org","created_at":"2026-01-14T13:11:22.799033Z","created_by":"Nic Young","updated_at":"2026-01-15T12:32:57.153332Z","closed_at":"2026-01-15T12:32:57.153332Z","close_reason":"Resolved in SPEC_005_frame_timing_and_clock.md. Decisions: pull-based clock, session-relative timestamps, accept differing latencies for v0, per-part CMS (not consolidated). Ensemble mode deferred to synesthetica-h09."}
{"id":"synesthetica-9f3","title":"Define entity budget and performance constraints","description":"PRD mentions 60fps target / 30fps fallback but no entity limits or constraint system is specified. Need to define what limits entity count and how grammars handle overload.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-16T09:39:03.494771Z","created_by":"Nic Young","updated_at":"2026-01-16T09:39:25.71426Z","dependencies":[{"issue_id":"synesthetica-9f3","depends_on_id":"synesthetica-ray","type":"blocks","created_at":"2026-01-19T10:35:26.646082Z","created_by":"Nic Young"}]}
{"id":"synesthetica-a3q","title":"Clarify Ruleset statefulness requirements","description":"IRuleset.map(frame: CMSFrame): IntentFrame is currently stateless, but some mappings need history:\n- 'Tension' might depend on harmonic trajectory over several beats\n- Beat phase detection might need memory\n- Phrase-level dynamics require lookback\n\nQuestions to resolve:\n- Should rulesets be allowed internal state?\n- Or should history be a stabilizer concern (stabilizers build up state, rulesets remain pure)?\n- If stateful, what's the reset/init contract?\n\nOutput: Amend IRuleset interface in packages/contracts/pipeline/interfaces.ts if needed. Document the decision in RFC 002 or a new ADR.","status":"closed","priority":2,"issue_type":"feature","owner":"nic@o1labs.org","created_at":"2026-01-14T13:11:22.985862Z","created_by":"Nic Young","updated_at":"2026-01-15T14:53:33.491396Z","closed_at":"2026-01-15T14:53:33.491396Z","close_reason":"Resolved in SPEC_006. Decision: Rulesets remain pure/stateless. Stabilizers are explicitly stateful with init/dispose/reset lifecycle. Temporal reasoning (tension, beat phase, phrase position) belongs in stabilizers as derived signals."}
{"id":"synesthetica-b50","title":"SPEC: Ruleset fallback behavior and confidence gating","description":"## The Gap\n\nIRuleset.map(frame: CMSFrame): IntentFrame is minimal. No guidance on how rulesets handle incomplete/uncertain musical data.\n\n## Why It Matters\n\n- What if CMS has no chord info (audio inference failed)?\n- How should ruleset weight intents when signals are missing?\n- Should rulesets emit all intent types every frame, or only meaningful ones?\n- No confidence thresholds or gating rules are specified\n\n## Current State\n\n- CMSFrame has events, controls, distributions — all optional/sparse\n- IntentFrame has intents array and uncertainty scalar\n- Invariant I5: \"Confidence affects rendering stability, not meaning\"\n- But no guidance on how rulesets should implement this\n\n## Questions to Answer\n\n1. What's the fallback behavior when expected CMS signals are absent?\n2. Are there confidence thresholds below which signals are ignored?\n3. Must rulesets emit all four intent types (palette, motion, texture, shape)?\n4. How does the ruleset compute IntentFrame.uncertainty?\n\n## Relates To\n\n- SPEC_003 (invariants I1-I5)\n- RFC_002 (ruleset role)\n- SPEC_007 (graceful degradation)\n\n## Output\n\nAdditions to RFC_002 or a new spec documenting ruleset semantics for edge cases.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-17T13:02:59.418382Z","created_by":"Nic Young","updated_at":"2026-01-17T13:02:59.418382Z"}
{"id":"synesthetica-c79","title":"P0: Project structure and build setup","status":"closed","priority":1,"issue_type":"feature","owner":"nic@o1labs.org","created_at":"2026-01-14T12:13:31.177452Z","created_by":"Nic Young","updated_at":"2026-01-18T10:38:45.135903Z","closed_at":"2026-01-18T10:38:45.135903Z","close_reason":"Project structure established with npm workspaces, TypeScript, and vitest for testing","dependencies":[{"issue_id":"synesthetica-c79","depends_on_id":"synesthetica-589","type":"blocks","created_at":"2026-01-14T13:12:08.083641Z","created_by":"Nic Young"}]}
{"id":"synesthetica-d41","title":"P0: Identity compositor","description":"Single-part compositor that passes through the scene unchanged.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-17T12:33:44.661556Z","created_by":"Nic Young","updated_at":"2026-01-18T10:50:21.994075Z","closed_at":"2026-01-18T10:50:21.994075Z","close_reason":"Implemented as IdentityCompositor in packages/engine/src/stubs","dependencies":[{"issue_id":"synesthetica-d41","depends_on_id":"synesthetica-c79","type":"blocks","created_at":"2026-01-17T12:36:59.914887Z","created_by":"Nic Young"}]}
{"id":"synesthetica-d53","title":"Document grammar contribution guide (open/closed pattern)","description":"Define how contributors (human or LLM) add new grammars to the system while adhering to the open/closed principle.\n\n## Goals\n- Grammars are open for extension (new grammars can be added)\n- Core system is closed for modification (adding a grammar doesn't change pipeline code)\n- Clear contract that guides LLM-driven grammar development\n\n## Should cover\n1. **Grammar contract**: What IGrammar implementations must provide\n2. **Annotation requirements**: Required GrammarAnnotation fields for LLM discoverability\n3. **Registration pattern**: How grammars are discovered/registered without modifying core\n4. **Testing requirements**: What tests a grammar must pass before inclusion\n5. **File/folder conventions**: Where grammar code and annotations live\n6. **Example template**: A minimal grammar that serves as a starting point\n\n## Constraints\n- Grammars MUST NOT compute musical semantics (I4)\n- Grammars MUST NOT read other parts (I7)\n- Grammars receive IntentFrame, emit SceneFrame\n- All entities must be tagged with the grammar's PartId\n\n## Evolution policy\nThis guide may be iterated as we learn. Any changes MUST be back-ported to all existing grammars to maintain consistency. The guide is a living document during Phase 1.\n\n## Output\nA SPEC or guide document that an LLM could follow to implement a new grammar from scratch.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-16T10:01:26.372543Z","created_by":"Nic Young","updated_at":"2026-01-17T12:56:01.758537Z"}
{"id":"synesthetica-dh7","title":"P0: Passthrough stabilizer","description":"Identity stabilizer that returns input unchanged. Placeholder for Phase 2.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-17T12:33:22.162305Z","created_by":"Nic Young","updated_at":"2026-01-18T10:50:21.788658Z","closed_at":"2026-01-18T10:50:21.788658Z","close_reason":"Implemented as PassthroughStabilizer in packages/engine/src/stubs","dependencies":[{"issue_id":"synesthetica-dh7","depends_on_id":"synesthetica-c79","type":"blocks","created_at":"2026-01-17T12:36:59.599242Z","created_by":"Nic Young"}]}
{"id":"synesthetica-dib","title":"Paper prototype: LLM annotation interpretation","description":"## Problem\n\nThe entire speech interface depends on an LLM correctly interpreting annotations and issuing control ops. This is novel and untested.\n\n## Action\n\nBefore Phase 2 (LLM integration), do a paper prototype:\n\n1. Write 20 realistic user utterances:\n   - \"use the starfield style\"\n   - \"emphasise rhythm\"\n   - \"make it linger more\"\n   - \"this is the guitar\" (while playing)\n   - \"save this as jazz practice\"\n   - etc.\n\n2. For each utterance, manually trace:\n   - What annotation lookups are needed?\n   - What control ops should result?\n   - What could go wrong?\n\n3. Evaluate:\n   - Are annotations sufficient for disambiguation?\n   - What's missing from GrammarAnnotation/MacroAnnotation?\n   - Where would the LLM need to guess?\n\n## Deliverable\n\n- Document with 20 utterance → control op mappings\n- List of annotation gaps discovered\n- Confidence assessment: \"LLM mediation is feasible\" or \"needs redesign\"\n\n## Why This Matters\n\nAn hour of paper prototyping could reveal that the annotation model is insufficient — before you build the LLM integration.\n\nSource: Session critique — \"LLM mediation model is high-risk and untested\"","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-17T13:17:08.607633Z","created_by":"Nic Young","updated_at":"2026-01-17T13:17:08.607633Z","dependencies":[{"issue_id":"synesthetica-dib","depends_on_id":"synesthetica-8f4","type":"blocks","created_at":"2026-01-19T10:35:38.658287Z","created_by":"Nic Young"}]}
{"id":"synesthetica-dxb","title":"Rename Registration→Preset and Motif→Style throughout codebase","description":"Registration and Motif are obtuse jargon. Rename to clearer terms:\n\n- Motif → Style (built-in visual effect: stars, comets, rain)\n- Registration → Preset (user-selectable/saveable configuration bundling styles + settings)\n\nUpdate:\n- All contracts in packages/contracts/\n- All RFCs\n- PRD\n- Glossaries\n- Any other docs","status":"closed","priority":1,"issue_type":"task","owner":"nic@o1labs.org","created_at":"2026-01-14T13:38:36.298633Z","created_by":"Nic Young","updated_at":"2026-01-14T13:57:34.343024Z","closed_at":"2026-01-14T13:57:34.343024Z","close_reason":"Renamed Registration→Preset and Motif→Style throughout: contracts, RFCs, PRD, glossaries, and related beads issues."}
{"id":"synesthetica-gyj","title":"Define LLM-mediation threshold criteria","description":"## Purpose\n\nDefine the minimum pipeline sophistication required before LLM-mediation adds value.\n\n## Proposed Threshold\n\nLLM-mediation development begins when ALL of these are met:\n\n### 1. Multiple stabilizers producing different musical elements\n- NoteTrackingStabilizer (notes with phase) ✓ exists\n- At least one of: ChordDetectionStabilizer, BeatDetectionStabilizer, DynamicsStabilizer\n\n### 2. Multiple grammar options\n- VisualParticleGrammar ✓ exists  \n- At least one other (trails, fields, glyphs)\n\n### 3. Configurable ruleset parameters\n- Pitch-hue mapping parameters (reference PC, direction)\n- Phase-stability curve parameters\n- Dynamics-motion mapping parameters\n\n### 4. Basic preset system\n- Named configurations that can be saved/loaded\n- Presets capture: stabilizer config, ruleset params, grammar selection\n\n### 5. Audio adapter functional\n- Audio → RawInputFrame working\n- Confidence/uncertainty propagating through pipeline\n- See synesthetica-8f4\n\n## Why This Matters\n\nLLM-mediation controls parameters and selects components. Without meaningful parameters to adjust and components to select, the LLM has nothing to mediate.\n\n## Relates To\n\n- synesthetica-8f4 (Audio adapter gates LLM-mediation)\n- synesthetica-jes (Phase 2: Full System epic)\n- SPEC_004 (LLM mediation and annotations)","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-19T10:28:01.450774Z","created_by":"Nic Young","updated_at":"2026-01-19T10:28:01.450774Z","dependencies":[{"issue_id":"synesthetica-gyj","depends_on_id":"synesthetica-8f4","type":"blocks","created_at":"2026-01-19T10:35:26.448755Z","created_by":"Nic Young"}]}
{"id":"synesthetica-h09","title":"Ensemble mode: cross-part musical interpretation","description":"## Context\n\nDuring frame timing design (SPEC_005), we identified a tension between:\n- **Per-part interpretation** (current design): Each part gets independent musical interpretation. Essential for ear training where you need to compare reference vs. attempt.\n- **Ensemble interpretation** (deferred): Multiple sources contribute to a single unified musical interpretation (e.g., Part 1's C-E-G + Part 2's E-G-B = Cmaj7).\n\n## Why Deferred\n\nPer-part is correct for v0's ear training focus. Ensemble mode would:\n- Require a fusion step upstream of CMS generation\n- Lose per-part attribution at the CMS level\n- Violate the current I3 invariant if done at the wrong layer\n\n## Architectural Insight\n\nIf implemented, ensemble mode would need:\n1. Adapters emit an intermediate \"raw musical evidence\" format\n2. A fusion step merges evidence from multiple sources\n3. CMS is generated from the fused evidence\n4. A synthetic PartId (e.g., \"ensemble\") for the fused stream\n\nThis is a fundamentally different mode of operation, not something achievable by merging at the compositor level (which can only blend visuals, not re-interpret musical meaning).\n\n## When to Revisit\n\n- When supporting live ensemble performance visualization\n- When users want unified harmonic analysis across multiple players\n- Not needed for single-player ear training scenarios","status":"open","priority":4,"issue_type":"feature","owner":"nic@o1labs.org","created_at":"2026-01-15T12:32:49.371723Z","created_by":"Nic Young","updated_at":"2026-01-15T12:32:49.371723Z"}
{"id":"synesthetica-ise","title":"P0: MIDI adapter (note_on/off only)","description":"Minimal MIDI adapter that produces CMSFrame from note_on/off events.\n\n- Single channel only\n- No CC/sustain pedal handling\n- Produces NoteOn/NoteOff events with pitch, velocity, timestamp\n- Web MIDI API","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-17T12:33:18.62793Z","created_by":"Nic Young","updated_at":"2026-01-18T10:38:49.385176Z","closed_at":"2026-01-18T10:38:49.385176Z","close_reason":"Implemented with DI pattern, 19 unit tests passing","dependencies":[{"issue_id":"synesthetica-ise","depends_on_id":"synesthetica-c79","type":"blocks","created_at":"2026-01-17T12:36:59.509687Z","created_by":"Nic Young"}]}
{"id":"synesthetica-j5y","title":"[EPIC] Phase 0: Playable Sketch","description":"Minimal vertical slice to prove the architecture and provide a test harness for ruleset/grammar iteration.\n\n## Goal\nMIDI in → visuals out. Ugly but playable. This becomes the scaffold for Phase 1 exploration.\n\n## Exit Criteria\n- Can connect a MIDI keyboard and see colored particles\n- Pipeline interfaces are exercised end-to-end\n- Foundation for golden tests exists\n\n## What's NOT in scope\n- Audio input, multiple parts, real stabilizers, LLM integration, polish","status":"closed","priority":1,"issue_type":"feature","created_at":"2026-01-17T12:33:00.812963Z","created_by":"Nic Young","updated_at":"2026-01-18T12:21:32.611731Z","closed_at":"2026-01-18T12:21:32.611731Z","close_reason":"Closed","dependencies":[{"issue_id":"synesthetica-j5y","depends_on_id":"synesthetica-0jg","type":"blocks","created_at":"2026-01-17T12:36:12.24072Z","created_by":"Nic Young"}]}
{"id":"synesthetica-jes","title":"[EPIC] Phase 2: Full System","description":"Expand to full system capabilities once core semantics are proven.\n\n## Scope\n- Audio adapter (MIR pipeline)\n- Real stabilizers (tension, beat phase, etc.)\n- Multiple parts and routing\n- WebGL renderer\n- LLM integration\n- Additional grammars\n\n## Depends on\n- Phase 1 complete (confident in ruleset/grammar patterns)","status":"open","priority":3,"issue_type":"feature","created_at":"2026-01-17T12:33:13.251307Z","created_by":"Nic Young","updated_at":"2026-01-17T12:33:13.251307Z","dependencies":[{"issue_id":"synesthetica-jes","depends_on_id":"synesthetica-zd8","type":"blocks","created_at":"2026-01-17T12:36:30.028501Z","created_by":"Nic Young"},{"issue_id":"synesthetica-jes","depends_on_id":"synesthetica-8f4","type":"blocks","created_at":"2026-01-19T10:35:38.466835Z","created_by":"Nic Young"}]}
{"id":"synesthetica-jxy","title":"Define error and diagnostic model","description":"No error handling contract exists. What happens when:\n- An adapter fails to parse input?\n- A motif throws during update?\n- The LLM produces an invalid ControlOp?\n- A registration references a non-existent motif?\n\nOutput: Add Diagnostic, PipelineError, and ValidationResult types to packages/contracts. Define error propagation semantics (fail-fast vs graceful degradation per component).","status":"closed","priority":2,"issue_type":"feature","owner":"nic@o1labs.org","created_at":"2026-01-14T13:11:23.170264Z","created_by":"Nic Young","updated_at":"2026-01-15T15:03:14.283488Z","closed_at":"2026-01-15T15:03:14.283488Z","close_reason":"Resolved in SPEC_007. Added Diagnostic, ValidationError, ControlOpResult types. Graceful degradation for runtime issues, fail-fast for config/invariant violations. Visual indicator recommended for renderers. All diagnostics logged."}
{"id":"synesthetica-jz4","title":"P1: Ruleset iteration (find what works)","description":"## Purpose\n\nExploratory work on rulesets. This is creative, not mechanical.\n\n## Focus Areas\n\n- Experiment with MusicalFrame → VisualIntentFrame mappings\n- Try different approaches to chord representation via intents\n- Explore dynamics/loudness handling via MotionIntents\n- Leverage intent phase (attack/sustain/release) for visual expression\n- Document what feels right\n- Build golden tests as we go\n\n## Key Contracts\n\nRulesets are pure functions (SPEC_006):\n- Input: MusicalFrame (notes, chords, progression, phrases, beat, dynamics)\n- Output: VisualIntentFrame (palette, motion, texture, shape intents)\n- No internal state\n\nIntents have phase (SPEC_009):\n- attack/sustain/release envelope\n- Grammars interpret phase but manage entity lifecycle independently\n\n## Exit Criteria\n\n- At least one ruleset that feels musically meaningful\n- Confidence in the VisualIntentFrame interface\n- Golden tests covering core mappings\n\nThis task stays open during exploration. Close when we have confidence.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-17T12:33:57.905382Z","created_by":"Nic Young","updated_at":"2026-01-19T10:34:18.320428Z","dependencies":[{"issue_id":"synesthetica-jz4","depends_on_id":"synesthetica-901","type":"blocks","created_at":"2026-01-17T12:36:22.610289Z","created_by":"Nic Young"},{"issue_id":"synesthetica-jz4","depends_on_id":"synesthetica-j5y","type":"blocks","created_at":"2026-01-17T12:40:35.537766Z","created_by":"Nic Young"}]}
{"id":"synesthetica-khj","title":"SPEC: Entity position and canvas coordinate system","description":"## The Gap\n\nEntity.position is Vec2, GrammarContext has canvasSize, but the coordinate system is never defined.\n\n## Why It Matters\n\n- Grammars spawn entities with positions — what's the reference frame?\n- Layout transforms apply to positions — what order? What semantics?\n- Different renderers (Canvas2D, WebGL) have different conventions\n- Multi-part rendering coordination requires shared coordinate semantics\n\n## Current State\n\n- Entity.position?: Vec2 (x, y numbers, no units specified)\n- GrammarContext.canvasSize: { width, height } — pixels? normalized?\n- LayoutPolicy.region: left/right/top/bottom/center/full — transform behavior undefined\n- No origin convention (top-left? center? bottom-left?)\n\n## Questions to Answer\n\n1. What coordinate system do grammars emit positions in? (0–1 normalized? pixels?)\n2. Where is the origin? (canvas top-left? center? part-local?)\n3. How do layout policies transform grammar-generated positions?\n4. How does scaling work for responsive canvas resize?\n\n## Relates To\n\n- RFC_002 (grammar context)\n- RFC_003 (layout policies)\n- SPEC_008 (compositor)\n\n## Output\n\nAdditions to RFC_002 and RFC_003 defining coordinate conventions and transform order.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-17T13:03:29.080479Z","created_by":"Nic Young","updated_at":"2026-01-17T13:03:29.080479Z"}
{"id":"synesthetica-n2o","title":"P1: Grammar iteration (build vocabulary)","description":"Exploratory work on grammars. Build a vocabulary of visual treatments.\n\nTarget: at least 3 distinct grammars with different characters:\n- Something discrete/transient (particles, stars)\n- Something continuous/flowing (trails, fields)\n- Something structural (chords, harmony visualization)\n\nDocument macro responses as we learn them.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-17T12:34:02.821893Z","created_by":"Nic Young","updated_at":"2026-01-17T12:34:02.821893Z","dependencies":[{"issue_id":"synesthetica-n2o","depends_on_id":"synesthetica-901","type":"blocks","created_at":"2026-01-17T12:36:22.715414Z","created_by":"Nic Young"},{"issue_id":"synesthetica-n2o","depends_on_id":"synesthetica-d53","type":"blocks","created_at":"2026-01-17T12:36:40.496889Z","created_by":"Nic Young"},{"issue_id":"synesthetica-n2o","depends_on_id":"synesthetica-j5y","type":"blocks","created_at":"2026-01-17T12:40:35.652492Z","created_by":"Nic Young"},{"issue_id":"synesthetica-n2o","depends_on_id":"synesthetica-n63","type":"blocks","created_at":"2026-01-17T12:56:50.966489Z","created_by":"Nic Young"}]}
{"id":"synesthetica-n63","title":"SPEC: Grammar composition and conflict resolution","description":"## The Problem\n\nMultiple active grammars may respond to the same intents differently. How do we combine their outputs?\n\nCurrent implicit model: grammars are additive (each emits entities, compositor merges).\n\n### Data flow context\n```\nCMS → Ruleset → IntentFrame → Grammar(s) → SceneFrame → Renderer\n```\n\n- Ruleset interprets CMS into musical intents (PaletteIntent, MotionIntent, TextureIntent, ShapeIntent)\n- Each intent carries confidence\n- Multiple grammars receive the SAME IntentFrame\n- Each grammar emits entities to a SceneFrame\n- Compositor merges SceneFrames (concat + layout + blending)\n\n### Where this breaks down\n\n1. **Conflicting motion**: Grammar A interprets MotionIntent.flow as \"drift left\", Grammar B as \"drift right\"\n2. **Macro confusion**: User says \"emphasise rhythm\" — macroResponses guide which grammars to adjust, but they may respond in incompatible ways\n3. **Visual chaos**: Two \"reactive\" grammars both responding to onsets = doubled visual noise\n4. **Coherence**: User expects a unified visual response, not independent layers doing their own thing\n\n### Concrete example\n\nActive grammars: Starfield (discrete, transient) + Rain (continuous, persistent)\n\nUser plays a chord. Both grammars receive the same IntentFrame:\n- Starfield spawns burst of particles\n- Rain increases field density\n\nIs this composition? Or conflict? Depends on the grammars' traits and whether they're designed to complement.\n\n## Questions to answer\n\n1. **Are grammars truly independent?**\n   - Do they share any state or negotiate?\n   - Can one grammar suppress or modify another?\n   - Should grammars be aware of what other grammars are active?\n\n2. **What is the composition model?**\n   - Pure entity concatenation (current)?\n   - Priority/layering with masking?\n   - Domain-based routing (grammar A handles motion, B handles texture)?\n   - Grammars declare \"slots\" they fill?\n\n3. **How do macros interact with multiple grammars?**\n   - Each grammar interprets macros independently via paramsSchema?\n   - macroResponses annotations guide which grammars to adjust?\n   - Some macros are \"global\" vs \"per-grammar\"?\n   - LLM uses macroResponses to make coherent choices?\n\n4. **What happens on conflict?**\n   - Both emit (visual chaos)?\n   - One wins (priority)?\n   - They blend (how?)?\n   - It's a design error (grammars shouldn't conflict)?\n\n5. **Role of presets**\n   - Do presets guarantee coherent grammar combinations?\n   - Is \"these grammars work together\" part of preset design?\n   - Should presets declare grammar relationships?\n\n## Relevant contracts\n\n- `IGrammar.update(input: IntentFrame, previous: SceneFrame | null): SceneFrame`\n- `ICompositor.compose(frames: SceneFrame[]): SceneFrame`\n- `GrammarAnnotation.traits` — could indicate compatibility\n- `GrammarAnnotation.macroResponses` — how grammar responds to macros\n- `Preset.grammars` — list of grammars with enabled/params/priority\n\n## Approaches to evaluate\n\n### 1. Additive (status quo)\n- Document when it works and when it doesn't\n- Rely on preset curation to avoid conflicts\n- Traits annotations help LLM avoid bad combinations\n- Simple, but pushes complexity to users/LLM\n\n### 2. Priority-based layering\n- Grammars have explicit priority in preset\n- Higher-priority grammar's entities render on top\n- Doesn't solve semantic conflict, only visual layering\n\n### 3. Domain declarations\n- Grammar declares which intent channels it consumes\n- `consumes: [\"motion\", \"palette\"]` vs `consumes: [\"texture\"]`\n- Compositor routes accordingly\n- Conflict = build-time warning\n- Limits expressiveness\n\n### 4. Slot-based composition\n- Define visual \"slots\" (background field, mid particles, foreground glyphs)\n- Each grammar fills specific slots\n- Compositor arranges slots\n- More structured, less flexible\n\n### 5. Pre-grammar intent arbitration\n- Intents are merged/arbitrated before reaching grammars\n- Single \"negotiated\" IntentFrame per part\n- Grammars see consistent signals\n- Loses per-grammar character\n\n## Phase 0 avoidance\n\nPhase 0 uses a single grammar, so this is not blocking. But Phase 1 grammar iteration will hit this immediately when combining grammars.\n\n## Output\n\nEither a SPEC or additions to SPEC_004/SPEC_008 clarifying:\n1. Grammar composition semantics\n2. Conflict detection/resolution strategy\n3. How presets encode grammar compatibility\n4. How macroResponses guide multi-grammar adjustment","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-17T12:56:39.738075Z","created_by":"Nic Young","updated_at":"2026-01-17T12:58:26.959429Z"}
{"id":"synesthetica-n6j","title":"Add IntentPhase to PaletteIntent contract","description":"## Context\n\nSPEC_009 now specifies that intents have their own lifecycle phase (attack/sustain/release), but the contract types don't reflect this yet.\n\n## Implementation\n\nUpdate `packages/contracts/intents/intents.ts`:\n\n```ts\nexport type IntentPhase = \"attack\" | \"sustain\" | \"release\";\n\nexport interface PaletteIntent {\n  type: \"palette\";\n  id: VisualIntentId;\n  t: Ms;\n  base: ColorHSVA;\n  stability: number;\n  phase: IntentPhase;  // ADD THIS\n  confidence: Confidence;\n}\n```\n\nAlso update MotionIntent, TextureIntent, ShapeIntent if they should have phase.\n\n## Downstream Changes\n\n- MusicalVisualRuleset: Set intent phase from note phase\n- VisualParticleGrammar: Can use phase to vary visual (optional)\n\n## Relates To\n\n- SPEC_009 (Intent Phase and Entity Lifecycle)\n- synesthetica-ray (Entity lifecycle resolution)","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-19T10:42:43.293109Z","created_by":"Nic Young","updated_at":"2026-01-19T10:42:43.293109Z"}
{"id":"synesthetica-nqx","title":"Define derived signals schema for stabilizers","description":"## The Gap\n\nSPEC_006 and SPEC_008 define the stabilizer DAG and MusicalFrame windowing, but the schema for derived signals is not fully specified.\n\n## What's Now Defined\n\nSPEC_006 now specifies MusicalFrame fields:\n- `notes: Note[]` — Active notes with phase\n- `chords: MusicalChord[]` — Detected chords\n- `progression: ChordId[]` — Recent chord history\n- `phrases: Phrase[]` — Phrase boundaries\n- `beat: BeatState` — Current beat position\n- `dynamics: DynamicsState` — Loudness level and trend\n\n## What's Still Missing\n\nHigher-level derived signals that rulesets might want:\n- `harmonicTension: number` — Computed from progression\n- `phrasePosition: number` — 0-1 position within current phrase\n- `rhythmicDensity: number` — Notes per beat\n- `registralSpread: number` — Range of active pitches\n\n## Questions\n\n1. Should these be part of MusicalFrame, or computed by rulesets?\n2. If part of MusicalFrame, which stabilizer owns each?\n3. Are these signals needed for Phase 1, or can we defer?\n\n## Relates To\n\n- SPEC_006 (MusicalFrame definition)\n- SPEC_008 (Stabilizer DAG, field ownership)\n- synesthetica-s0x (Stabilizer ordering - resolved)","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-16T09:39:03.04577Z","created_by":"Nic Young","updated_at":"2026-01-19T10:34:08.435785Z","dependencies":[{"issue_id":"synesthetica-nqx","depends_on_id":"synesthetica-s0x","type":"blocks","created_at":"2026-01-19T10:35:26.843642Z","created_by":"Nic Young"}]}
{"id":"synesthetica-nrx","title":"SPEC: Control operation validation error format","description":"## The Gap\n\nControlOpResult includes ValidationError with field/reason/hint, but the format and completeness of feedback are undefined.\n\n## Why It Matters\n\n- LLM relies on errors to diagnose and fix bad commands\n- Incomplete error context forces guessing or random retry\n- No examples or error message grammar is provided\n- Recovery quality depends on error quality\n\n## Current State\n\n- ValidationError: { field, reason, hint? }\n- ControlOpResult: { success, errors?, diagnostics? }\n- SPEC_007 defines the types but not content standards\n\n## Questions to Answer\n\n1. What's the format for field paths? (e.g., \"macros.emphasis.rhythm\")\n2. Should reason be machine-readable or prose?\n3. What constitutes a good hint for LLM recovery?\n4. Are there standard error codes or categories?\n\n## Relates To\n\n- SPEC_007 (validation errors)\n- RFC_004 (LLM mediation)\n\n## Output\n\nAdditions to SPEC_007 with examples and format guidelines for validation errors.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-17T13:04:06.145241Z","created_by":"Nic Young","updated_at":"2026-01-17T13:04:06.145241Z"}
{"id":"synesthetica-omz","title":"SPEC: Macro persistence across preset changes","description":"## The Gap\n\nWhen switching presets, it's unclear whether macro values are preserved, reset, or interpolated.\n\n## Why It Matters\n\n- User expectations differ: \"keep my rhythm emphasis\" vs \"reset to preset defaults\"\n- Interaction model doesn't specify user intent for transitions\n- LLM has no guidance on whether to explicitly reset macros\n- Affects speech patterns like \"use jazz mode but keep the rhythm emphasis\"\n\n## Current State\n\n- Preset.macros defines default values\n- ControlOp.applyPreset applies a preset\n- ControlOp.setMacro patches macros independently\n- No spec defines transition semantics\n\n## Questions to Answer\n\n1. Does applyPreset reset all macros to preset defaults?\n2. Can users opt to preserve macro values across preset changes?\n3. Should macro transitions be interpolated (smooth) or instant?\n4. Is this configurable per-preset or global?\n\n## Relates To\n\n- RFC_001 (interaction model)\n- SPEC_004 (macros)\n- synesthetica-30r (macro interpolation)\n\n## Output\n\nAdditions to SPEC_004 or RFC_001 defining preset transition semantics for macros.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-17T13:03:57.125904Z","created_by":"Nic Young","updated_at":"2026-01-17T13:03:57.125904Z"}
{"id":"synesthetica-pt7","title":"Triage: Cull backlog before Phase 0","description":"## Problem\n\nIssue count is growing faster than closure rate (48 total, 38 open, 10 closed). A backlog that grows without bound becomes noise.\n\n## Action\n\nBefore starting Phase 0 implementation:\n\n1. Review all open issues\n2. Mark clearly out-of-scope items as wontfix or post-v1\n3. Merge duplicates\n4. Ensure remaining issues have clear scope and acceptance criteria\n5. Target: \u003c25 open issues for v0\n\n## Triage Categories\n\n- **P0-P1**: Must have for Phase 0/1\n- **P2**: Should have, likely needed\n- **P3**: Nice to have, defer if needed\n- **P4**: Backlog, explicitly post-v1\n- **wontfix**: Out of scope, close with reason\n\n## Why This Matters\n\nA shorter, curated list is more useful than a comprehensive one. Context decays — stale issues become misleading.\n\nSource: Session critique — \"issue count growing faster than closure rate\"","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-17T13:16:47.061892Z","created_by":"Nic Young","updated_at":"2026-01-17T13:16:47.061892Z"}
{"id":"synesthetica-qkx","title":"Implement diagnostic logging infrastructure","description":"## Context\n\nSPEC_007 requires that all diagnostics are logged regardless of visual indication. Need to implement the logging infrastructure.\n\n## Requirements\n\n- All Diagnostic emissions logged to console and/or file\n- Minimum log format: [timestamp] [category] [severity] message\n- Include source and partId when available\n- Support structured logging (JSON) for easier parsing\n- Consider log levels for filtering\n\n## Reference\n\nSee SPEC_007_error_and_diagnostic_model.md \"Logging Requirements\" section.\n\n## Acceptance\n\n- Diagnostics from all categories are logged\n- Log format is consistent and parseable\n- Log output is configurable (console, file, both)","status":"open","priority":3,"issue_type":"task","owner":"nic@o1labs.org","created_at":"2026-01-15T15:10:27.104855Z","created_by":"Nic Young","updated_at":"2026-01-15T15:10:27.104855Z"}
{"id":"synesthetica-qtx","title":"Update PRD to reflect RFC proposals","description":"The PRD is sparse and doesn't reflect the detailed requirements that have emerged from the RFCs.\n\nUpdate PRD to include:\n- Functional requirements from RFC 002 (CMS, intents, motifs, registrations)\n- Interaction model from RFC 001 (postures, commitment verbs, layers)\n- Multi-instrument support from RFC 003 (parts, routing, layout)\n- LLM mediation from RFC 004 (speech control, annotations)\n\nKeep it product-focused (what the system does for users), not implementation-focused (how it works internally).","status":"closed","priority":1,"issue_type":"task","owner":"nic@o1labs.org","created_at":"2026-01-14T13:26:10.228756Z","created_by":"Nic Young","updated_at":"2026-01-14T13:29:47.038819Z","closed_at":"2026-01-14T13:29:47.038819Z","close_reason":"PRD updated with functional requirements from all RFCs: input processing, visual output, parts/routing, registrations, interaction model, speech control, and user journeys."}
{"id":"synesthetica-r0y","title":"Define preset export/import JSON schema","description":"SPEC_001 mentions exportUser()/importUser(json) but no JSON schema is defined for the export format. Low priority for v0.","status":"open","priority":4,"issue_type":"task","created_at":"2026-01-16T09:39:03.643254Z","created_by":"Nic Young","updated_at":"2026-01-16T09:39:25.860302Z"}
{"id":"synesthetica-ray","title":"SPEC: Entity lifecycle and decay semantics","description":"## The Gap (RESOLVED)\n\nEntity has `life?: { ttlMs: Ms; ageMs: Ms }` but decay/removal semantics were unclear.\n\n## Resolution\n\nSPEC_009 now clarifies:\n\n**Entity lifecycle is grammar's domain.** Grammars decide how to respond to intents — they are not obligated to tie entity lifetime to intent lifetime.\n\nKey points:\n- Intent phase (attack/sustain/release) describes the intent's current state, not entity lifespan\n- Grammars may spawn entities that outlive their source intent\n- Grammars decide visual persistence based on their purpose\n- Intent disappearing does NOT require entity removal — grammar decides\n\n## Implementation Tasks\n\n1. Update IVisualGrammar interface documentation to clarify entity lifecycle ownership\n2. Update VisualParticleGrammar to use TTL-based lifecycle (not intent-tracking)\n3. Add entity TTL configuration to grammar options\n4. Update GLOSSARY_FULL.md grammar definition\n\n## Relates To\n\n- SPEC_009 (intent phase and entity lifecycle)\n- SPEC_008 (compositor responsibilities)","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-17T13:03:09.914237Z","created_by":"Nic Young","updated_at":"2026-01-19T10:26:53.511353Z"}
{"id":"synesthetica-s0x","title":"Define stabilizer ordering strategy","description":"## The Gap (RESOLVED)\n\nSPEC_006 deferred stabilizer ordering/composition. When multiple stabilizers run, their order matters.\n\n## Resolution\n\nSPEC_008 now defines Stabilizer DAG:\n\n**Stabilizers form a directed acyclic graph (DAG) based on dependencies.**\n\n### Independent Stabilizers (process RawInputFrame directly)\n- NoteTrackingStabilizer\n- BeatDetectionStabilizer  \n- DynamicsStabilizer\n\n### Derived Stabilizers (require upstream output)\n- ChordDetectionStabilizer (needs notes)\n- PhraseDetectionStabilizer (needs beats + density)\n- ProgressionStabilizer (needs chords over time)\n\n### Execution\n1. Topological sort based on declared dependencies\n2. Run stabilizers in dependency order\n3. Merge outputs into single MusicalFrame\n4. Ownership enforced: one stabilizer per field\n\n## Implementation Tasks\n\n1. Add `dependencies?: string[]` to IMusicalStabilizer interface\n2. Implement topological sort in VisualPipeline\n3. Implement merge logic with ownership enforcement\n4. Update stabilizer factory pattern for DAG support\n\n## Relates To\n\n- SPEC_008 (Stabilizer DAG section)\n- SPEC_006 (MusicalFrame windowing)","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-16T09:39:03.197398Z","created_by":"Nic Young","updated_at":"2026-01-19T10:35:53.143779Z","closed_at":"2026-01-19T10:35:53.143779Z","close_reason":"Closed"}
{"id":"synesthetica-tzc","title":"Specify try/keep/discard lifecycle and session state","description":"RFC 001 introduces commitment verbs (try, keep, discard, queue) but there's no contract surface for this.\n\nQuestions to resolve:\n- What is the representation of a 'trial' state?\n- Can you have nested trials?\n- How does 'discard' know what to revert to?\n- What is a Checkpoint?\n\nOutput: Add SessionState, Checkpoint, and Trial types to packages/contracts. Amend RFC 001 or create a new RFC section specifying the lifecycle semantics.","status":"closed","priority":2,"issue_type":"feature","owner":"nic@o1labs.org","created_at":"2026-01-14T13:11:22.578857Z","created_by":"Nic Young","updated_at":"2026-01-14T19:43:56.410254Z","closed_at":"2026-01-14T19:43:56.410254Z","close_reason":"Deferred to LLM. The engine provides preset CRUD (IPresetCatalog); try/keep/discard semantics are left to the user↔LLM conversation, not specified by the engine.","dependencies":[{"issue_id":"synesthetica-tzc","depends_on_id":"synesthetica-ysk","type":"blocks","created_at":"2026-01-14T13:12:07.892904Z","created_by":"Nic Young"}]}
{"id":"synesthetica-uky","title":"P0: Pipeline orchestrator","description":"Implement IPipeline.requestFrame() - the central coordinator.\n\n- Wire adapter → stabilizer → ruleset → grammar → compositor\n- Single part only (no routing yet)\n- Pull-based frame model per SPEC_005/SPEC_008","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-17T12:33:36.693546Z","created_by":"Nic Young","updated_at":"2026-01-18T10:50:35.121777Z","closed_at":"2026-01-18T10:50:35.121777Z","close_reason":"Pipeline orchestrator complete with 15 tests","dependencies":[{"issue_id":"synesthetica-uky","depends_on_id":"synesthetica-ise","type":"blocks","created_at":"2026-01-17T12:34:43.954334Z","created_by":"Nic Young"},{"issue_id":"synesthetica-uky","depends_on_id":"synesthetica-dh7","type":"blocks","created_at":"2026-01-17T12:34:44.071316Z","created_by":"Nic Young"},{"issue_id":"synesthetica-uky","depends_on_id":"synesthetica-ymc","type":"blocks","created_at":"2026-01-17T12:34:44.180879Z","created_by":"Nic Young"},{"issue_id":"synesthetica-uky","depends_on_id":"synesthetica-6lf","type":"blocks","created_at":"2026-01-17T12:34:44.302812Z","created_by":"Nic Young"},{"issue_id":"synesthetica-uky","depends_on_id":"synesthetica-d41","type":"blocks","created_at":"2026-01-17T12:34:44.406463Z","created_by":"Nic Young"}]}
{"id":"synesthetica-uty","title":"SPEC: PartSelector resolution and error handling","description":"## The Gap\n\nPartSelector supports label/mostActive/all modes, but resolution logic and failure behavior are unspecified.\n\n## Why It Matters\n\n- Control op targeting \"guitar\" fails if no part has that label\n- mostActive returns null when no recent activity\n- LLM has no feedback to disambiguate failed resolution\n- Speech patterns (\"this is the guitar\") depend on reliable deictic resolution\n\n## Current State\n\n- PartSelector: partId | label | mostActive | all\n- IActivityTracker.getMostActive(windowMs) can return null\n- PartRegistry.setLabel() exists but no query for \"does label exist?\"\n- SPEC_007 mentions control diagnostics but not selector resolution\n\n## Questions to Answer\n\n1. What diagnostic is emitted when label resolution fails?\n2. What happens when mostActive returns null? No-op? Error?\n3. Should LLM query available parts/labels before issuing ops?\n4. Is there a \"best effort\" mode vs \"strict\" mode?\n\n## Relates To\n\n- RFC_004 (LLM mediation)\n- SPEC_007 (control diagnostics)\n- RFC_003 (part registry)\n\n## Output\n\nAdditions to SPEC_007 or RFC_003 defining selector resolution semantics and error reporting.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-17T13:03:19.751812Z","created_by":"Nic Young","updated_at":"2026-01-17T13:03:19.751812Z"}
{"id":"synesthetica-w9j","title":"Spike: MIDI-to-canvas throwaway prototype","description":"## Purpose\n\nValidate core architectural assumptions before completing spec work. This is a throwaway prototype — not production code.\n\n## What to Build (2-3 hours max)\n\nMinimal path from MIDI input to visual output:\n- Web MIDI API receiving note_on/off\n- Direct render to Canvas2D (no pipeline abstraction)\n- Colored circles based on pitch (any mapping)\n- Basic fade on note_off\n\n## What to Validate\n\n1. Does Web MIDI's event-driven model work with our pull-based timing assumption?\n2. What's the actual latency from keypress to pixel?\n3. Does requestAnimationFrame give smooth enough updates?\n4. Any browser quirks with MIDI permissions?\n\n## What NOT to Do\n\n- Don't implement contracts/interfaces\n- Don't write tests\n- Don't refactor\n- Don't keep the code\n\n## Exit Criteria\n\n- Successfully see colored response to MIDI input\n- Document any surprises or assumption violations\n- Delete the code (or stash it)\n- **Write a \"What We Learned\" document** capturing:\n  - Assumption validations (confirmed or violated)\n  - Surprising behaviors encountered\n  - Spec amendments needed\n  - Unknowns that remain\n  - This document gets committed even if the code doesn't\n\n## Why This Matters\n\nThe specs assume certain behaviors (pull-based timing, adapter abstraction) that haven't been validated against browser APIs. A 2-hour spike now could save weeks of rework later.\n\nSource: Session critique — \"spec/implementation gap is widening\"\n\n---\n\n## Outcome\n\n**Completed 2026-01-18.** All assumptions validated.\n\nSee: `docs/learnings/2026-01-18-midi-spike.md`\n\nKey findings:\n- MIDI latency: ~0.4ms avg (1-3ms range) — negligible\n- Frame timing: stable 16.7ms (60fps)\n- Push-to-pull reconciliation works via state buffering\n- No dropped events under fast playing\n\nSpec amendment made: SPEC_008 updated with push-to-pull reconciliation pattern.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-17T13:16:37.823384Z","created_by":"Nic Young","updated_at":"2026-01-18T10:22:18.96769Z","closed_at":"2026-01-18T10:22:18.96769Z","close_reason":"Spike complete. All assumptions validated. See docs/learnings/2026-01-18-midi-spike.md"}
{"id":"synesthetica-wf2","title":"Implement diagnostic visual indicator in renderer","description":"## Context\n\nSPEC_007 recommends that renderers display visual indicators for active diagnostics. This is a user experience feature to surface issues without requiring log inspection.\n\n## Requirements\n\n- Display category-specific icons in top-right corner (or configurable location)\n- Categories: input (🔌), stabilizer (⚙️), grammar (🎨), control (🎛️)\n- Transient diagnostics: flash briefly then fade\n- Sticky diagnostics: persist until condition clears\n- Multiple diagnostics: show count badge or stack icons\n\n## Reference\n\nSee SPEC_007_error_and_diagnostic_model.md \"Visual Indicator\" section.\n\n## Acceptance\n\n- Renderer displays appropriate icon when diagnostics are present in SceneFrame\n- Icons decay/persist according to diagnostic persistence mode\n- Implementation is clean and doesn't interfere with main visual content","status":"open","priority":3,"issue_type":"task","owner":"nic@o1labs.org","created_at":"2026-01-15T15:10:20.302069Z","created_by":"Nic Young","updated_at":"2026-01-15T15:10:20.302069Z"}
{"id":"synesthetica-y72","title":"SPEC: Preset versioning and backward compatibility","description":"## The Gap\n\nNo versioning scheme exists for presets — if a grammar's parameter schema changes, existing saved presets break silently.\n\n## Why It Matters\n\n- Users accumulate presets over time\n- Breaking changes orphan saved configurations\n- No migration semantics or compatibility markers exist\n- Imports from other users may reference unknown grammars\n\n## Current State\n\n- PresetMeta has id, name, source, timestamps — no version\n- IPresetCatalog.importUser validates but behavior for unknowns is undefined\n- synesthetica-r0y notes JSON schema gap\n- No deprecation policy for grammars/macros\n\n## Questions to Answer\n\n1. Should presets have version numbers?\n2. What's the migration strategy for incompatible presets?\n3. How are unknown grammar references handled?\n4. Should presets declare minimum engine version?\n\n## Relates To\n\n- SPEC_001 (preset storage)\n- synesthetica-r0y (export/import schema)\n\n## Output\n\nAdditions to SPEC_001 defining preset versioning, compatibility markers, and migration rules.","status":"open","priority":4,"issue_type":"task","created_at":"2026-01-17T13:04:14.518632Z","created_by":"Nic Young","updated_at":"2026-01-17T13:04:14.518632Z"}
{"id":"synesthetica-y7q","title":"P2: Evaluate Meyda.js for audio adapter","description":"Evaluate whether Meyda.js (https://meyda.js.org/) is suitable for the audio MIR pipeline.\n\n## What Meyda provides\n- Real-time audio feature extraction in browser\n- Spectral features (centroid, rolloff, flatness, etc.)\n- Perceptual features (loudness, RMS)\n- Chroma / pitch class distribution\n\n## Questions to answer\n- Does it provide pitch-class distributions with confidence?\n- Can it detect beats/onsets?\n- What's the latency profile?\n- Does it fit our CMSFrame model?\n\n## Alternatives to consider\n- Essentia.js\n- Custom Web Audio API implementation\n- Combination approach\n\nThis is Phase 2 work — we need the pipeline proven with MIDI first.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-17T12:40:43.836112Z","created_by":"Nic Young","updated_at":"2026-01-17T12:40:43.836112Z","dependencies":[{"issue_id":"synesthetica-y7q","depends_on_id":"synesthetica-j5y","type":"blocks","created_at":"2026-01-17T12:40:54.769807Z","created_by":"Nic Young"}]}
{"id":"synesthetica-ymc","title":"P0: Minimal ruleset (pitch→hue, velocity→brightness)","description":"First ruleset implementation. Minimal but real.\n\n- pitch-class → hue (using pcToHue invariant)\n- velocity → brightness\n- Produces PaletteIntent and basic MotionIntent\n- No chord/beat/phrase handling yet","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-17T12:33:27.736655Z","created_by":"Nic Young","updated_at":"2026-01-18T10:50:31.322135Z","closed_at":"2026-01-18T10:50:31.322135Z","close_reason":"Implemented as MinimalRuleset with unit tests. Golden tests deferred.","dependencies":[{"issue_id":"synesthetica-ymc","depends_on_id":"synesthetica-c79","type":"blocks","created_at":"2026-01-17T12:36:59.704563Z","created_by":"Nic Young"},{"issue_id":"synesthetica-ymc","depends_on_id":"synesthetica-901","type":"blocks","created_at":"2026-01-17T12:40:24.068414Z","created_by":"Nic Young"}]}
{"id":"synesthetica-ysk","title":"Design Configuration Service and composite storage","description":"User-authored presets (named configurations like 'matching fireworks') need persistent storage, but the LLM shouldn't own this.\n\nProposed approach:\n- LLM proposes names/checkpoints via bounded ControlOps\n- A Configuration Service owns the catalog and validates all writes\n- User presets stored as first-class catalog entries\n\nNew types needed:\n- UserPreset (snapshot of style selection + macro values + patches)\n- Checkpoint (trial state for undo/discard)\n- IConfigurationService interface\n\nStorage for v0: localStorage in browser\n\nOutput:\n1. Add checkpoint and user preset types to packages/contracts/config/\n2. Extend ControlOps with checkpoint operations\n3. Add IConfigurationService to packages/contracts/pipeline/\n4. Create RFC or SPEC documenting the persistence model","status":"closed","priority":2,"issue_type":"feature","owner":"nic@o1labs.org","created_at":"2026-01-14T13:11:23.551867Z","created_by":"Nic Young","updated_at":"2026-01-14T19:43:51.599972Z","closed_at":"2026-01-14T19:43:51.599972Z","close_reason":"Complete. IPresetCatalog provides CRUD for presets (list, get, save, delete, import/export). Types in packages/contracts/config/preset.ts, documented in SPEC_001.","dependencies":[{"issue_id":"synesthetica-ysk","depends_on_id":"synesthetica-8do","type":"blocks","created_at":"2026-01-14T13:12:07.705103Z","created_by":"Nic Young"}]}
{"id":"synesthetica-zd8","title":"[EPIC] Phase 1: Ruleset \u0026 Grammar Exploration","description":"Deep iteration on rulesets and grammars with the Phase 0 scaffold as test harness.\n\n## Goal\nDiscover what mappings and visual treatments actually work. This is where the \"magic\" happens.\n\n## Approach\n- Freeze adapters/pipeline/renderer from Phase 0\n- Iterate freely on rulesets (CMS → IntentFrame mappings)\n- Iterate freely on grammars (IntentFrame → SceneFrame)\n- Build golden test corpus as we go\n\n## Exit Criteria\n- At least one ruleset that feels musically meaningful\n- At least 3 grammars with distinct characters\n- Golden tests covering core behaviours\n- Confidence in the IntentFrame interface\n\n## Depends on\n- Phase 0 complete","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-17T12:33:07.868512Z","created_by":"Nic Young","updated_at":"2026-01-17T12:33:07.868512Z","dependencies":[{"issue_id":"synesthetica-zd8","depends_on_id":"synesthetica-j5y","type":"blocks","created_at":"2026-01-17T12:36:22.390715Z","created_by":"Nic Young"}]}
{"id":"synesthetica-zmm","title":"DECISION: Auto-start session on MIDI device selection","description":"Document the decision to auto-start sessions on device selection rather than requiring explicit start/stop buttons.\n\n## Context\nDuring Phase 0 web app shell implementation, we clarified the session lifecycle UX.\n\n## Decision\n**Option B: Auto-start on device selection** (chosen)\n\nSession flow:\n1. Page loads → show MIDI device selector\n2. User selects device → session auto-starts\n3. Session runs until page unload or device change\n4. Cleanup in beforeunload handler\n\n## Alternatives Considered\n- Option A: Explicit start/stop buttons (rejected - unnecessary complexity)\n- Option C: Other (not explored)\n\n## Rationale\n- Simpler UX - fewer controls to understand\n- Aligns with session lifecycle model from SPEC_005 (session-relative timestamps)\n- Aligns with stabilizer lifecycle from SPEC_006 (init/reset/dispose)\n- Natural mental model: selecting device = \"I want to use this now\"\n\n## Implementation\nSee packages/web-app/src/main.ts:\n- startSession() called from handleDeviceSelection()\n- No manual start/stop UI elements\n- Session lifecycle managed automatically\n\n## Related\n- SPEC_005: Frame timing and session epochs\n- SPEC_006: Stabilizer lifecycle (init/reset/dispose)\n- packages/web-app/README.md: Documents the UX flow","status":"closed","priority":4,"issue_type":"task","created_at":"2026-01-18T12:24:19.9441Z","created_by":"Nic Young","updated_at":"2026-01-18T12:24:58.716996Z","closed_at":"2026-01-18T12:24:58.716996Z","close_reason":"Closed"}
